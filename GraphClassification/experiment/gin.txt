D:\Program\Anaconda\envs\pyg\python.exe F:/Project/BernNet/GraphClassification/main.py
--
IMDB-MULTI - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 1.1019378360112508, 'val_loss': 1.1702299817403157, 'test_acc': 0.41333333333333333}
{'fold': 9, 'epoch': 2, 'train_loss': 1.0764249022801717, 'val_loss': 1.2907189750671386, 'test_acc': 0.32666666666666666}
{'fold': 9, 'epoch': 3, 'train_loss': 1.0590654007593792, 'val_loss': 1.1354596455891928, 'test_acc': 0.36666666666666664}
{'fold': 9, 'epoch': 4, 'train_loss': 1.031096084912618, 'val_loss': 1.069207598368327, 'test_acc': 0.38666666666666666}
{'fold': 9, 'epoch': 5, 'train_loss': 1.0083677466710408, 'val_loss': 1.0720000203450522, 'test_acc': 0.48}
{'fold': 9, 'epoch': 6, 'train_loss': 1.0384680954615275, 'val_loss': 1.024885762532552, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 7, 'train_loss': 1.032675952911377, 'val_loss': 1.0075672149658204, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 8, 'train_loss': 1.008116368452708, 'val_loss': 0.9990056610107422, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 9, 'train_loss': 1.0086632219950358, 'val_loss': 1.0231631342569987, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 10, 'train_loss': 0.9964300068219503, 'val_loss': 1.401004498799642, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 11, 'train_loss': 1.0081771500905354, 'val_loss': 1.0069501749674479, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 12, 'train_loss': 0.9914911111195882, 'val_loss': 0.9957521057128906, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 13, 'train_loss': 0.9828093377749125, 'val_loss': 0.9998406473795572, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 14, 'train_loss': 1.0059485896428426, 'val_loss': 1.0396240234375, 'test_acc': 0.42}
{'fold': 9, 'epoch': 15, 'train_loss': 0.9978003406524658, 'val_loss': 1.010440305074056, 'test_acc': 0.5}
{'fold': 9, 'epoch': 16, 'train_loss': 1.0129537502924602, 'val_loss': 0.9966534169514975, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 17, 'train_loss': 1.00683158715566, 'val_loss': 1.0299300130208333, 'test_acc': 0.5}
{'fold': 9, 'epoch': 18, 'train_loss': 1.0187832069396974, 'val_loss': 1.0073456446329752, 'test_acc': 0.5}
{'fold': 9, 'epoch': 19, 'train_loss': 1.0494498999913533, 'val_loss': 1.0123079554239909, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 20, 'train_loss': 0.9890760374069214, 'val_loss': 0.9914385096232097, 'test_acc': 0.52}
{'fold': 9, 'epoch': 21, 'train_loss': 0.9990011016527812, 'val_loss': 1.0100743357340496, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 22, 'train_loss': 1.0079612191518148, 'val_loss': 1.242531852722168, 'test_acc': 0.42}
{'fold': 9, 'epoch': 23, 'train_loss': 0.9929738378524781, 'val_loss': 1.022199312845866, 'test_acc': 0.48}
{'fold': 9, 'epoch': 24, 'train_loss': 0.9948521669705709, 'val_loss': 1.0236552174886067, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 25, 'train_loss': 1.0136546262105306, 'val_loss': 0.9905176035563151, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 26, 'train_loss': 0.9911219461758931, 'val_loss': 1.0126974868774414, 'test_acc': 0.5}
{'fold': 9, 'epoch': 27, 'train_loss': 0.9899654324849446, 'val_loss': 1.0205704752604168, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 28, 'train_loss': 1.0095425319671631, 'val_loss': 1.0118179829915364, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 29, 'train_loss': 0.9840397516886393, 'val_loss': 0.998301633199056, 'test_acc': 0.48}
{'fold': 9, 'epoch': 30, 'train_loss': 1.0100110546747842, 'val_loss': 1.061600201924642, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 31, 'train_loss': 0.9745634611447652, 'val_loss': 1.021504275004069, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 32, 'train_loss': 0.9859788123766581, 'val_loss': 1.0047038141886393, 'test_acc': 0.48}
{'fold': 9, 'epoch': 33, 'train_loss': 0.9753415552775065, 'val_loss': 1.0069669087727864, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 34, 'train_loss': 0.9752803945541382, 'val_loss': 1.0072181447347006, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 35, 'train_loss': 0.9535795752207438, 'val_loss': 1.1026050821940103, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 36, 'train_loss': 1.0690259504318238, 'val_loss': 1.4613274637858074, 'test_acc': 0.44666666666666666}
{'fold': 9, 'epoch': 37, 'train_loss': 1.0392024302482605, 'val_loss': 1.075007464090983, 'test_acc': 0.4}
{'fold': 9, 'epoch': 38, 'train_loss': 1.0387778584162395, 'val_loss': 1.0431078084309895, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 39, 'train_loss': 1.0063407762845358, 'val_loss': 1.0067966588338215, 'test_acc': 0.44666666666666666}
{'fold': 9, 'epoch': 40, 'train_loss': 1.002674911816915, 'val_loss': 0.9875567245483399, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 41, 'train_loss': 1.0049745718638101, 'val_loss': 1.015505053202311, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 42, 'train_loss': 1.013332044283549, 'val_loss': 1.0103740692138672, 'test_acc': 0.48}
{'fold': 9, 'epoch': 43, 'train_loss': 1.008882926305135, 'val_loss': 1.0049452082316082, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 44, 'train_loss': 0.9937372843424479, 'val_loss': 0.9870955530802409, 'test_acc': 0.48}
{'fold': 9, 'epoch': 45, 'train_loss': 0.9733459528287252, 'val_loss': 0.9834900665283203, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 46, 'train_loss': 1.0117402036984762, 'val_loss': 1.0035982131958008, 'test_acc': 0.48}
{'fold': 9, 'epoch': 47, 'train_loss': 0.9810085034370423, 'val_loss': 1.0393637212117512, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 48, 'train_loss': 0.972285753885905, 'val_loss': 1.0010072453816732, 'test_acc': 0.52}
{'fold': 9, 'epoch': 49, 'train_loss': 0.9726097456614177, 'val_loss': 0.9860978825887045, 'test_acc': 0.52}
{'fold': 9, 'epoch': 50, 'train_loss': 0.9851716327667236, 'val_loss': 1.046140251159668, 'test_acc': 0.5}
{'fold': 9, 'epoch': 51, 'train_loss': 0.9878952161471048, 'val_loss': 0.9921984227498373, 'test_acc': 0.5333333333333333}
{'fold': 9, 'epoch': 52, 'train_loss': 0.9735022354125976, 'val_loss': 1.0089833704630533, 'test_acc': 0.5}
{'fold': 9, 'epoch': 53, 'train_loss': 0.9648006693522135, 'val_loss': 1.039809710184733, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 54, 'train_loss': 0.9852395709355672, 'val_loss': 0.996033935546875, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 55, 'train_loss': 0.9731411512692769, 'val_loss': 1.062518081665039, 'test_acc': 0.5}
{'fold': 9, 'epoch': 56, 'train_loss': 0.9922127834955852, 'val_loss': 1.0168248367309571, 'test_acc': 0.4}
{'fold': 9, 'epoch': 57, 'train_loss': 0.9985870194435119, 'val_loss': 1.03548521677653, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 58, 'train_loss': 0.9837972180048624, 'val_loss': 1.0519021860758464, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 59, 'train_loss': 0.9631021316846212, 'val_loss': 1.2056074523925782, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 60, 'train_loss': 0.9645137906074523, 'val_loss': 1.1324395497639974, 'test_acc': 0.5}
{'fold': 9, 'epoch': 61, 'train_loss': 0.9871629730860392, 'val_loss': 1.0784055201212566, 'test_acc': 0.5}
{'fold': 9, 'epoch': 62, 'train_loss': 0.9867390298843384, 'val_loss': 1.0575650787353517, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 63, 'train_loss': 0.9757572563489278, 'val_loss': 1.0326248296101888, 'test_acc': 0.52}
{'fold': 9, 'epoch': 64, 'train_loss': 0.971394019126892, 'val_loss': 1.034764912923177, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 65, 'train_loss': 0.991299516359965, 'val_loss': 1.01864626566569, 'test_acc': 0.42}
{'fold': 9, 'epoch': 66, 'train_loss': 0.9815290514628092, 'val_loss': 1.0289494069417318, 'test_acc': 0.46}
{'fold': 9, 'epoch': 67, 'train_loss': 1.0032324504852295, 'val_loss': 1.0061314519246418, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 68, 'train_loss': 0.9689603074391683, 'val_loss': 1.0059007390340169, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 69, 'train_loss': 0.9527154405911763, 'val_loss': 1.0088156000773112, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 70, 'train_loss': 0.9425941570599874, 'val_loss': 1.0676790364583333, 'test_acc': 0.48}
{'fold': 9, 'epoch': 71, 'train_loss': 0.96701553662618, 'val_loss': 1.0539547475179036, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 72, 'train_loss': 0.9668720618883768, 'val_loss': 1.032794507344564, 'test_acc': 0.48}
{'fold': 9, 'epoch': 73, 'train_loss': 0.9604072992006938, 'val_loss': 1.0572602971394858, 'test_acc': 0.5}
{'fold': 9, 'epoch': 74, 'train_loss': 0.950238049030304, 'val_loss': 1.0765113830566406, 'test_acc': 0.46}
{'fold': 9, 'epoch': 75, 'train_loss': 0.9405641182263692, 'val_loss': 1.0014078521728516, 'test_acc': 0.48}
{'fold': 9, 'epoch': 76, 'train_loss': 0.9424103879928589, 'val_loss': 1.0996218999226888, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 77, 'train_loss': 0.9488312911987304, 'val_loss': 1.0365309778849283, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 78, 'train_loss': 0.9316701483726502, 'val_loss': 1.0286339441935222, 'test_acc': 0.5}
{'fold': 9, 'epoch': 79, 'train_loss': 0.9177763740221659, 'val_loss': 1.0259751256306966, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 80, 'train_loss': 0.944908766746521, 'val_loss': 1.0378664525349934, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 81, 'train_loss': 0.9248705848058065, 'val_loss': 1.0279293314615885, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 82, 'train_loss': 0.9491844813028971, 'val_loss': 1.0183293787638346, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 83, 'train_loss': 0.926109991868337, 'val_loss': 1.0365667215983072, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 84, 'train_loss': 0.9213141528765361, 'val_loss': 1.0236105600992838, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 85, 'train_loss': 0.9046753231684367, 'val_loss': 1.0004738744099935, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 86, 'train_loss': 0.9405065178871155, 'val_loss': 0.996265869140625, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 87, 'train_loss': 0.9099311256408691, 'val_loss': 1.0484318288167318, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 88, 'train_loss': 0.951778899828593, 'val_loss': 1.0565108489990234, 'test_acc': 0.5}
{'fold': 9, 'epoch': 89, 'train_loss': 0.9290198707580566, 'val_loss': 1.0215043385823568, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 90, 'train_loss': 0.9151517899831136, 'val_loss': 1.002087885538737, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 91, 'train_loss': 0.9123284244537353, 'val_loss': 1.0025922393798827, 'test_acc': 0.5}
{'fold': 9, 'epoch': 92, 'train_loss': 0.9111487412452698, 'val_loss': 0.9950946553548177, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 93, 'train_loss': 0.9444940869013468, 'val_loss': 1.0773556645711262, 'test_acc': 0.48}
{'fold': 9, 'epoch': 94, 'train_loss': 0.9426880876223246, 'val_loss': 0.9916192372639974, 'test_acc': 0.48}
{'fold': 9, 'epoch': 95, 'train_loss': 0.9410579665501912, 'val_loss': 0.9918584569295248, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 96, 'train_loss': 0.9334915256500245, 'val_loss': 1.0169890594482422, 'test_acc': 0.5}
{'fold': 9, 'epoch': 97, 'train_loss': 0.9138793245951334, 'val_loss': 0.9985126368204753, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 98, 'train_loss': 0.9149214053153991, 'val_loss': 1.0159416580200196, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 99, 'train_loss': 0.9115281120936076, 'val_loss': 1.0008237965901692, 'test_acc': 0.5}
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 100, 'train_loss': 0.9288145025571187, 'val_loss': 1.0223378372192382, 'test_acc': 0.5066666666666667}
Val Loss: 0.9559, Test Accuracy: 0.501 ± 0.036, Duration: 10.026
Best result - 0.501 ± 0.036
--
MUTAG - GIN
{'fold': 9, 'epoch': 1, 'train_loss': 0.6912007237735548, 'val_loss': 0.7625105645921495, 'test_acc': 0.3333333333333333}
{'fold': 9, 'epoch': 2, 'train_loss': 0.5475757247523257, 'val_loss': 0.7412236531575521, 'test_acc': 0.4444444444444444}
{'fold': 9, 'epoch': 3, 'train_loss': 0.4199889521849783, 'val_loss': 3.9315647549099393, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 4, 'train_loss': 0.33968316881280197, 'val_loss': 6.7826122707790795, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 5, 'train_loss': 0.3136585888109709, 'val_loss': 4.306846618652344, 'test_acc': 0.3333333333333333}
{'fold': 9, 'epoch': 6, 'train_loss': 0.33649784640262004, 'val_loss': 8.323806762695312, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 7, 'train_loss': 0.2933580373462878, 'val_loss': 19.861419677734375, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 8, 'train_loss': 0.3093908240920619, 'val_loss': 22.413277520073784, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 9, 'train_loss': 0.34055872026242706, 'val_loss': 25.209964328342014, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 10, 'train_loss': 0.2971434938280206, 'val_loss': 25.05972120496962, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 11, 'train_loss': 0.3287953969679381, 'val_loss': 29.173180474175346, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 12, 'train_loss': 0.27988472110346746, 'val_loss': 28.204600016276043, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 13, 'train_loss': 0.29967868171240153, 'val_loss': 22.387081570095486, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 14, 'train_loss': 0.27689906484202337, 'val_loss': 16.578231811523438, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 15, 'train_loss': 0.26739475601597834, 'val_loss': 12.846032036675346, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 16, 'train_loss': 0.21369955727928563, 'val_loss': 10.97938707139757, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 17, 'train_loss': 0.25915594085266713, 'val_loss': 9.899271647135416, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 18, 'train_loss': 0.29078413702939687, 'val_loss': 8.21659935845269, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 19, 'train_loss': 0.3002811960483852, 'val_loss': 6.029268052842882, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 20, 'train_loss': 0.29622383847048406, 'val_loss': 4.8370484246148004, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 21, 'train_loss': 0.24587830195301458, 'val_loss': 4.294322119818793, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 22, 'train_loss': 0.29697179480602864, 'val_loss': 4.071548885769314, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 23, 'train_loss': 0.2230272340147119, 'val_loss': 4.348578559027778, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 24, 'train_loss': 0.22287729617796445, 'val_loss': 4.820211198594835, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 25, 'train_loss': 0.21780804662328018, 'val_loss': 5.333239237467448, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 26, 'train_loss': 0.25700654638440984, 'val_loss': 5.580279880099827, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 27, 'train_loss': 0.2667468143136878, 'val_loss': 5.2908070882161455, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 28, 'train_loss': 0.329986309534625, 'val_loss': 4.301415337456597, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 29, 'train_loss': 0.2438531016048632, 'val_loss': 4.1150461832682295, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 30, 'train_loss': 0.2573786409277665, 'val_loss': 4.394332038031684, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 31, 'train_loss': 0.23596022160429703, 'val_loss': 4.623623741997613, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 32, 'train_loss': 0.2594021982268283, 'val_loss': 5.3231396145290795, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 33, 'train_loss': 0.33950716257095337, 'val_loss': 6.042235904269749, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 34, 'train_loss': 0.27845777257492665, 'val_loss': 6.153528425428602, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 35, 'train_loss': 0.25429939125713547, 'val_loss': 5.9333169725206165, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 36, 'train_loss': 0.27437985413952876, 'val_loss': 5.59471935696072, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 37, 'train_loss': 0.2879144627796976, 'val_loss': 5.8195851643880205, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 38, 'train_loss': 0.2446172927555285, 'val_loss': 5.895139058430989, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 39, 'train_loss': 0.2457453318332371, 'val_loss': 5.073721567789714, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 40, 'train_loss': 0.23796426622491135, 'val_loss': 3.9997550116644964, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 41, 'train_loss': 0.2859126047084206, 'val_loss': 1.8202548556857638, 'test_acc': 0.8888888888888888}
{'fold': 9, 'epoch': 42, 'train_loss': 0.2547953395467055, 'val_loss': 0.24477238125271267, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 43, 'train_loss': 0.37804320140888814, 'val_loss': 0.32589313719007706, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 44, 'train_loss': 0.31477983531199005, 'val_loss': 0.6168768670823839, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 45, 'train_loss': 0.27038861889588206, 'val_loss': 0.6533742480807834, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 46, 'train_loss': 0.28698371429192393, 'val_loss': 0.19957559638553196, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 47, 'train_loss': 0.2893165185263282, 'val_loss': 0.18135298622979057, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 48, 'train_loss': 0.28804602277906316, 'val_loss': 0.18258497450086805, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 49, 'train_loss': 0.28341424308325114, 'val_loss': 0.463211801317003, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 50, 'train_loss': 0.27874944398277685, 'val_loss': 2.2253714667426214, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 51, 'train_loss': 0.2994698333112817, 'val_loss': 2.1642148759629993, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 52, 'train_loss': 0.24590194852728592, 'val_loss': 1.7369147406684027, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 53, 'train_loss': 0.2192380655752985, 'val_loss': 1.8821290334065754, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 54, 'train_loss': 0.25898466455309016, 'val_loss': 2.651465733846029, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 55, 'train_loss': 0.22814945876598358, 'val_loss': 4.488251156277126, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 56, 'train_loss': 0.2641361387152421, 'val_loss': 5.056388431125217, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 57, 'train_loss': 0.24439748258967148, 'val_loss': 5.241557227240668, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 58, 'train_loss': 0.21296624839305878, 'val_loss': 2.7637030283610025, 'test_acc': 0.8888888888888888}
{'fold': 9, 'epoch': 59, 'train_loss': 0.21847247057839445, 'val_loss': 1.253716680738661, 'test_acc': 0.8888888888888888}
{'fold': 9, 'epoch': 60, 'train_loss': 0.25737523169893967, 'val_loss': 1.5830873913235135, 'test_acc': 1.0}
{'fold': 9, 'epoch': 61, 'train_loss': 0.3254889375285098, 'val_loss': 6.551689147949219, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 62, 'train_loss': 0.2782064989993447, 'val_loss': 6.83196046617296, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 63, 'train_loss': 0.32648937012019913, 'val_loss': 6.2296803792317705, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 64, 'train_loss': 0.25655521922989893, 'val_loss': 5.201655917697483, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 65, 'train_loss': 0.2598608026379033, 'val_loss': 3.448138131035699, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 66, 'train_loss': 0.3040285157529931, 'val_loss': 2.3663463592529297, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 67, 'train_loss': 0.2956504241416329, 'val_loss': 1.6437429851955838, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 68, 'train_loss': 0.26052496386201757, 'val_loss': 1.6753209431966145, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 69, 'train_loss': 0.2839223271922061, 'val_loss': 0.6654485596550835, 'test_acc': 0.9444444444444444}
{'fold': 9, 'epoch': 70, 'train_loss': 0.26685570886260584, 'val_loss': 0.19794612460666233, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 71, 'train_loss': 0.2754722849318856, 'val_loss': 0.22320238749186197, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 72, 'train_loss': 0.2825707212874764, 'val_loss': 0.2032521300845676, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 73, 'train_loss': 0.2578628674933785, 'val_loss': 0.18758769830067953, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 74, 'train_loss': 0.2551532309306295, 'val_loss': 0.1793426407708062, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 75, 'train_loss': 0.25296553890956075, 'val_loss': 0.16922190454271105, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 76, 'train_loss': 0.2403445879095479, 'val_loss': 0.15099732081095377, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 77, 'train_loss': 0.2052934452107078, 'val_loss': 0.974350823296441, 'test_acc': 0.9444444444444444}
{'fold': 9, 'epoch': 78, 'train_loss': 0.21156467614989533, 'val_loss': 2.22357538011339, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 79, 'train_loss': 0.21054320841243393, 'val_loss': 2.4716758728027344, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 80, 'train_loss': 0.20682755583210996, 'val_loss': 2.493570751614041, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 81, 'train_loss': 0.1843322237071238, 'val_loss': 3.479434119330512, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 82, 'train_loss': 0.192280139970152, 'val_loss': 5.681229909261067, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 83, 'train_loss': 0.16713720560073853, 'val_loss': 7.516554090711805, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 84, 'train_loss': 0.1731741820511065, 'val_loss': 7.346053229437934, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 85, 'train_loss': 0.17482510522792213, 'val_loss': 5.38724602593316, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 86, 'train_loss': 0.28157008007953044, 'val_loss': 3.7444975111219616, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 87, 'train_loss': 0.26356284241927297, 'val_loss': 0.2787967258029514, 'test_acc': 0.5}
{'fold': 9, 'epoch': 88, 'train_loss': 0.2908256791139904, 'val_loss': 1.9966905381944444, 'test_acc': 0.3333333333333333}
{'fold': 9, 'epoch': 89, 'train_loss': 0.4871016332977696, 'val_loss': 0.1982884274588691, 'test_acc': 0.5}
{'fold': 9, 'epoch': 90, 'train_loss': 0.3558129370212555, 'val_loss': 8.85789320203993, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 91, 'train_loss': 0.2798893561488704, 'val_loss': 11.988180372450087, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 92, 'train_loss': 0.3127909977185099, 'val_loss': 11.16253916422526, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 93, 'train_loss': 0.3031754838792901, 'val_loss': 9.509307013617622, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 94, 'train_loss': 0.3277333755242197, 'val_loss': 7.843356662326389, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3363222652360013, 'val_loss': 6.724501715766059, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 96, 'train_loss': 0.29685687783517334, 'val_loss': 5.916251712375217, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 97, 'train_loss': 0.2965659742292605, 'val_loss': 5.252575344509548, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 98, 'train_loss': 0.40135635827717026, 'val_loss': 3.7023099263509116, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 99, 'train_loss': 0.3027418287176835, 'val_loss': 1.2173462973700628, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 100, 'train_loss': 0.32759538606593486, 'val_loss': 0.3292098310258653, 'test_acc': 0.6666666666666666}
Val Loss: 0.2635, Test Accuracy: 0.819 ± 0.077, Duration: 1.513
Best result - 0.819 ± 0.077
--
IMDB-BINARY - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6518581604957581, 'val_loss': 4.0668792724609375, 'test_acc': 0.5}
{'fold': 9, 'epoch': 2, 'train_loss': 0.5854653573036194, 'val_loss': 0.615820426940918, 'test_acc': 0.67}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5739084005355835, 'val_loss': 0.5988140106201172, 'test_acc': 0.66}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5319014108180999, 'val_loss': 0.566057243347168, 'test_acc': 0.7}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5331307864189148, 'val_loss': 0.47864830017089843, 'test_acc': 0.71}
{'fold': 9, 'epoch': 6, 'train_loss': 0.508820788860321, 'val_loss': 0.5673170852661132, 'test_acc': 0.67}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5467612409591674, 'val_loss': 0.5146893692016602, 'test_acc': 0.76}
{'fold': 9, 'epoch': 8, 'train_loss': 0.504183111190796, 'val_loss': 0.5545886611938476, 'test_acc': 0.71}
{'fold': 9, 'epoch': 9, 'train_loss': 0.48941951751708984, 'val_loss': 0.4983130645751953, 'test_acc': 0.72}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5257582235336303, 'val_loss': 0.593120994567871, 'test_acc': 0.71}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5296752023696899, 'val_loss': 0.54631103515625, 'test_acc': 0.72}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5123182940483093, 'val_loss': 0.49951953887939454, 'test_acc': 0.74}
{'fold': 9, 'epoch': 13, 'train_loss': 0.49559998750686646, 'val_loss': 0.46802936553955077, 'test_acc': 0.77}
{'fold': 9, 'epoch': 14, 'train_loss': 0.512695814371109, 'val_loss': 0.6691792297363282, 'test_acc': 0.73}
{'fold': 9, 'epoch': 15, 'train_loss': 0.49744129180908203, 'val_loss': 0.5261302566528321, 'test_acc': 0.7}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5008926844596863, 'val_loss': 0.4877434158325195, 'test_acc': 0.72}
{'fold': 9, 'epoch': 17, 'train_loss': 0.48038066387176515, 'val_loss': 0.5514288330078125, 'test_acc': 0.68}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5156816005706787, 'val_loss': 0.518073844909668, 'test_acc': 0.75}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5534974813461304, 'val_loss': 0.5266541290283203, 'test_acc': 0.67}
{'fold': 9, 'epoch': 20, 'train_loss': 0.49777000308036806, 'val_loss': 0.5108491897583007, 'test_acc': 0.66}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5128666651248932, 'val_loss': 0.5382107543945313, 'test_acc': 0.68}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5070961427688598, 'val_loss': 0.564730567932129, 'test_acc': 0.62}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5206834268569946, 'val_loss': 0.6002505111694336, 'test_acc': 0.72}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5560300707817077, 'val_loss': 0.6877452087402344, 'test_acc': 0.7}
{'fold': 9, 'epoch': 25, 'train_loss': 0.4909286761283875, 'val_loss': 0.5726177215576171, 'test_acc': 0.67}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5152702367305756, 'val_loss': 0.5121743774414063, 'test_acc': 0.67}
{'fold': 9, 'epoch': 27, 'train_loss': 0.4520903515815735, 'val_loss': 0.5492230224609375, 'test_acc': 0.7}
{'fold': 9, 'epoch': 28, 'train_loss': 0.4774146914482117, 'val_loss': 0.49180255889892577, 'test_acc': 0.67}
{'fold': 9, 'epoch': 29, 'train_loss': 0.4667784821987152, 'val_loss': 0.5844352340698242, 'test_acc': 0.67}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5556604146957398, 'val_loss': 0.4852298355102539, 'test_acc': 0.77}
{'fold': 9, 'epoch': 31, 'train_loss': 0.46347487449645997, 'val_loss': 0.5319556808471679, 'test_acc': 0.71}
{'fold': 9, 'epoch': 32, 'train_loss': 0.47523468136787417, 'val_loss': 0.49055755615234375, 'test_acc': 0.76}
{'fold': 9, 'epoch': 33, 'train_loss': 0.48444356441497805, 'val_loss': 0.5164354324340821, 'test_acc': 0.69}
{'fold': 9, 'epoch': 34, 'train_loss': 0.4776266479492188, 'val_loss': 0.5287491607666016, 'test_acc': 0.69}
{'fold': 9, 'epoch': 35, 'train_loss': 0.4471850335597992, 'val_loss': 0.6750801849365234, 'test_acc': 0.69}
{'fold': 9, 'epoch': 36, 'train_loss': 0.4540541446208954, 'val_loss': 0.6208929824829101, 'test_acc': 0.72}
{'fold': 9, 'epoch': 37, 'train_loss': 0.4210888946056366, 'val_loss': 0.5645164489746094, 'test_acc': 0.71}
{'fold': 9, 'epoch': 38, 'train_loss': 0.4147860896587372, 'val_loss': 0.5303830337524414, 'test_acc': 0.7}
{'fold': 9, 'epoch': 39, 'train_loss': 0.43350504398345946, 'val_loss': 0.5092524337768555, 'test_acc': 0.74}
{'fold': 9, 'epoch': 40, 'train_loss': 0.41853508472442624, 'val_loss': 0.6247827911376953, 'test_acc': 0.71}
{'fold': 9, 'epoch': 41, 'train_loss': 0.4315036427974701, 'val_loss': 0.6973949432373047, 'test_acc': 0.78}
{'fold': 9, 'epoch': 42, 'train_loss': 0.4236617588996887, 'val_loss': 0.5370703125, 'test_acc': 0.74}
{'fold': 9, 'epoch': 43, 'train_loss': 0.45848013877868654, 'val_loss': 0.5547594833374023, 'test_acc': 0.68}
{'fold': 9, 'epoch': 44, 'train_loss': 0.4461043763160706, 'val_loss': 0.4928213882446289, 'test_acc': 0.71}
{'fold': 9, 'epoch': 45, 'train_loss': 0.4393296921253204, 'val_loss': 0.5194823074340821, 'test_acc': 0.74}
{'fold': 9, 'epoch': 46, 'train_loss': 0.41556456208229064, 'val_loss': 0.5273342514038086, 'test_acc': 0.74}
{'fold': 9, 'epoch': 47, 'train_loss': 0.4262258303165436, 'val_loss': 0.4881649398803711, 'test_acc': 0.67}
{'fold': 9, 'epoch': 48, 'train_loss': 0.4219161796569824, 'val_loss': 0.5484149932861329, 'test_acc': 0.74}
{'fold': 9, 'epoch': 49, 'train_loss': 0.4265245318412781, 'val_loss': 0.5128782653808593, 'test_acc': 0.8}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3991116642951965, 'val_loss': 0.5448655700683593, 'test_acc': 0.76}
{'fold': 9, 'epoch': 51, 'train_loss': 0.40249587774276735, 'val_loss': 0.7538414764404296, 'test_acc': 0.72}
{'fold': 9, 'epoch': 52, 'train_loss': 0.3997122895717621, 'val_loss': 0.7036973571777344, 'test_acc': 0.71}
{'fold': 9, 'epoch': 53, 'train_loss': 0.39342745423316955, 'val_loss': 0.6700927734375, 'test_acc': 0.71}
{'fold': 9, 'epoch': 54, 'train_loss': 0.39890408992767334, 'val_loss': 0.5477036666870118, 'test_acc': 0.67}
{'fold': 9, 'epoch': 55, 'train_loss': 0.4642530870437622, 'val_loss': 0.5124575805664062, 'test_acc': 0.72}
{'fold': 9, 'epoch': 56, 'train_loss': 0.41345097541809084, 'val_loss': 0.7033245086669921, 'test_acc': 0.68}
{'fold': 9, 'epoch': 57, 'train_loss': 0.43416145086288455, 'val_loss': 0.7182693481445312, 'test_acc': 0.71}
{'fold': 9, 'epoch': 58, 'train_loss': 0.43328014612197874, 'val_loss': 0.6300676727294922, 'test_acc': 0.71}
{'fold': 9, 'epoch': 59, 'train_loss': 0.4401851725578308, 'val_loss': 0.5696632766723633, 'test_acc': 0.69}
{'fold': 9, 'epoch': 60, 'train_loss': 0.40599907636642457, 'val_loss': 0.6541234588623047, 'test_acc': 0.7}
{'fold': 9, 'epoch': 61, 'train_loss': 0.3789013767242432, 'val_loss': 0.7136495208740234, 'test_acc': 0.72}
{'fold': 9, 'epoch': 62, 'train_loss': 0.379260687828064, 'val_loss': 0.626212272644043, 'test_acc': 0.73}
{'fold': 9, 'epoch': 63, 'train_loss': 0.3801864004135132, 'val_loss': 0.6314311981201172, 'test_acc': 0.72}
{'fold': 9, 'epoch': 64, 'train_loss': 0.42350727438926694, 'val_loss': 0.6077125930786133, 'test_acc': 0.64}
{'fold': 9, 'epoch': 65, 'train_loss': 0.43695395708084106, 'val_loss': 0.5591204452514649, 'test_acc': 0.67}
{'fold': 9, 'epoch': 66, 'train_loss': 0.42395456075668336, 'val_loss': 0.6187057876586914, 'test_acc': 0.71}
{'fold': 9, 'epoch': 67, 'train_loss': 0.41935681700706484, 'val_loss': 0.8227841186523438, 'test_acc': 0.69}
{'fold': 9, 'epoch': 68, 'train_loss': 0.4393023920059204, 'val_loss': 0.5931304931640625, 'test_acc': 0.7}
{'fold': 9, 'epoch': 69, 'train_loss': 0.4194097054004669, 'val_loss': 0.49262874603271484, 'test_acc': 0.71}
{'fold': 9, 'epoch': 70, 'train_loss': 0.425588915348053, 'val_loss': 0.5138589096069336, 'test_acc': 0.66}
{'fold': 9, 'epoch': 71, 'train_loss': 0.42978652715682986, 'val_loss': 0.43868724822998045, 'test_acc': 0.72}
{'fold': 9, 'epoch': 72, 'train_loss': 0.414510155916214, 'val_loss': 0.4489128875732422, 'test_acc': 0.72}
{'fold': 9, 'epoch': 73, 'train_loss': 0.4586600112915039, 'val_loss': 0.5714663696289063, 'test_acc': 0.63}
{'fold': 9, 'epoch': 74, 'train_loss': 0.4660084283351898, 'val_loss': 0.5025391387939453, 'test_acc': 0.69}
{'fold': 9, 'epoch': 75, 'train_loss': 0.4549088501930237, 'val_loss': 0.4697154998779297, 'test_acc': 0.71}
{'fold': 9, 'epoch': 76, 'train_loss': 0.4569332933425903, 'val_loss': 0.48151371002197263, 'test_acc': 0.68}
{'fold': 9, 'epoch': 77, 'train_loss': 0.42936296463012696, 'val_loss': 0.47822128295898436, 'test_acc': 0.73}
{'fold': 9, 'epoch': 78, 'train_loss': 0.4338354694843292, 'val_loss': 0.521012077331543, 'test_acc': 0.7}
{'fold': 9, 'epoch': 79, 'train_loss': 0.4177487432956696, 'val_loss': 0.5366044616699219, 'test_acc': 0.7}
{'fold': 9, 'epoch': 80, 'train_loss': 0.4145936715602875, 'val_loss': 0.494571533203125, 'test_acc': 0.78}
{'fold': 9, 'epoch': 81, 'train_loss': 0.41872931122779844, 'val_loss': 0.49180011749267577, 'test_acc': 0.72}
{'fold': 9, 'epoch': 82, 'train_loss': 0.39795822262763975, 'val_loss': 0.5516998672485351, 'test_acc': 0.74}
{'fold': 9, 'epoch': 83, 'train_loss': 0.38082890152931215, 'val_loss': 0.5714526748657227, 'test_acc': 0.69}
{'fold': 9, 'epoch': 84, 'train_loss': 0.39684775829315183, 'val_loss': 0.5527640914916992, 'test_acc': 0.71}
{'fold': 9, 'epoch': 85, 'train_loss': 0.4166515350341797, 'val_loss': 0.4916135025024414, 'test_acc': 0.73}
{'fold': 9, 'epoch': 86, 'train_loss': 0.4033161401748657, 'val_loss': 0.5110298538208008, 'test_acc': 0.74}
{'fold': 9, 'epoch': 87, 'train_loss': 0.38281474232673646, 'val_loss': 0.546729850769043, 'test_acc': 0.72}
{'fold': 9, 'epoch': 88, 'train_loss': 0.42773793697357176, 'val_loss': 0.5172423553466797, 'test_acc': 0.7}
{'fold': 9, 'epoch': 89, 'train_loss': 0.3905387568473816, 'val_loss': 0.6620274353027343, 'test_acc': 0.7}
{'fold': 9, 'epoch': 90, 'train_loss': 0.37166350841522217, 'val_loss': 0.7031401062011718, 'test_acc': 0.68}
{'fold': 9, 'epoch': 91, 'train_loss': 0.38090369701385496, 'val_loss': 0.5493577194213867, 'test_acc': 0.78}
{'fold': 9, 'epoch': 92, 'train_loss': 0.3685352563858032, 'val_loss': 0.562559814453125, 'test_acc': 0.74}
{'fold': 9, 'epoch': 93, 'train_loss': 0.3640995514392853, 'val_loss': 0.6009929656982422, 'test_acc': 0.73}
{'fold': 9, 'epoch': 94, 'train_loss': 0.3683066701889038, 'val_loss': 0.7127941131591797, 'test_acc': 0.73}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3613805603981018, 'val_loss': 0.6634000396728515, 'test_acc': 0.7}
{'fold': 9, 'epoch': 96, 'train_loss': 0.3700631809234619, 'val_loss': 0.9194368743896484, 'test_acc': 0.72}
{'fold': 9, 'epoch': 97, 'train_loss': 0.4015680885314941, 'val_loss': 0.5902502822875977, 'test_acc': 0.77}
{'fold': 9, 'epoch': 98, 'train_loss': 0.37308906197547914, 'val_loss': 0.5597379302978516, 'test_acc': 0.73}
{'fold': 9, 'epoch': 99, 'train_loss': 0.40317760229110716, 'val_loss': 0.5407275772094726, 'test_acc': 0.73}
{'fold': 9, 'epoch': 100, 'train_loss': 0.37348058104515075, 'val_loss': 0.5736420440673828, 'test_acc': 0.71}
Val Loss: 0.4538, Test Accuracy: 0.733 ± 0.049, Duration: 7.125
Best result - 0.733 ± 0.049
--
REDDIT-BINARY - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6013802051544189, 'val_loss': 0.8592889022827148, 'test_acc': 0.5}
{'fold': 9, 'epoch': 2, 'train_loss': 0.5397858786582946, 'val_loss': 0.6138352298736572, 'test_acc': 0.67}
{'fold': 9, 'epoch': 3, 'train_loss': 0.49005704402923583, 'val_loss': 0.5594917297363281, 'test_acc': 0.73}
{'fold': 9, 'epoch': 4, 'train_loss': 0.45223206520080567, 'val_loss': 0.42958717346191405, 'test_acc': 0.77}
{'fold': 9, 'epoch': 5, 'train_loss': 0.4829839158058167, 'val_loss': 0.5210797119140625, 'test_acc': 0.71}
{'fold': 9, 'epoch': 6, 'train_loss': 0.4721142029762268, 'val_loss': 0.5044553375244141, 'test_acc': 0.74}
{'fold': 9, 'epoch': 7, 'train_loss': 0.47395925283432006, 'val_loss': 0.4526145648956299, 'test_acc': 0.775}
{'fold': 9, 'epoch': 8, 'train_loss': 0.48130139589309695, 'val_loss': 0.47042874336242674, 'test_acc': 0.75}
{'fold': 9, 'epoch': 9, 'train_loss': 0.46845960736274717, 'val_loss': 0.5968284511566162, 'test_acc': 0.68}
{'fold': 9, 'epoch': 10, 'train_loss': 0.44211152553558347, 'val_loss': 0.49535326957702636, 'test_acc': 0.76}
{'fold': 9, 'epoch': 11, 'train_loss': 0.45707309007644653, 'val_loss': 0.43126471519470216, 'test_acc': 0.79}
{'fold': 9, 'epoch': 12, 'train_loss': 0.43542526006698606, 'val_loss': 0.4584196949005127, 'test_acc': 0.735}
{'fold': 9, 'epoch': 13, 'train_loss': 0.4017801630496979, 'val_loss': 0.42907224655151366, 'test_acc': 0.81}
{'fold': 9, 'epoch': 14, 'train_loss': 0.4034247553348541, 'val_loss': 0.4151346778869629, 'test_acc': 0.845}
{'fold': 9, 'epoch': 15, 'train_loss': 0.4122057843208313, 'val_loss': 0.430215950012207, 'test_acc': 0.835}
{'fold': 9, 'epoch': 16, 'train_loss': 0.3967191612720489, 'val_loss': 0.39056848526000976, 'test_acc': 0.795}
{'fold': 9, 'epoch': 17, 'train_loss': 0.3853175377845764, 'val_loss': 0.39600022315979005, 'test_acc': 0.835}
{'fold': 9, 'epoch': 18, 'train_loss': 0.4001319360733032, 'val_loss': 0.49283321380615236, 'test_acc': 0.755}
{'fold': 9, 'epoch': 19, 'train_loss': 0.39590728521347046, 'val_loss': 0.3742861270904541, 'test_acc': 0.83}
{'fold': 9, 'epoch': 20, 'train_loss': 0.4314051377773285, 'val_loss': 0.4109621429443359, 'test_acc': 0.845}
{'fold': 9, 'epoch': 21, 'train_loss': 0.3815308976173401, 'val_loss': 0.4508566188812256, 'test_acc': 0.805}
{'fold': 9, 'epoch': 22, 'train_loss': 0.3798793721199036, 'val_loss': 0.37430644035339355, 'test_acc': 0.865}
{'fold': 9, 'epoch': 23, 'train_loss': 0.3883119595050812, 'val_loss': 0.4461442184448242, 'test_acc': 0.835}
{'fold': 9, 'epoch': 24, 'train_loss': 0.3688341343402863, 'val_loss': 0.36112032890319823, 'test_acc': 0.87}
{'fold': 9, 'epoch': 25, 'train_loss': 0.3673219966888428, 'val_loss': 0.3561615562438965, 'test_acc': 0.85}
{'fold': 9, 'epoch': 26, 'train_loss': 0.37451722025871276, 'val_loss': 0.30351470947265624, 'test_acc': 0.865}
{'fold': 9, 'epoch': 27, 'train_loss': 0.3748019242286682, 'val_loss': 0.3918004035949707, 'test_acc': 0.795}
{'fold': 9, 'epoch': 28, 'train_loss': 0.35050501108169557, 'val_loss': 0.3309522819519043, 'test_acc': 0.87}
{'fold': 9, 'epoch': 29, 'train_loss': 0.33556192278862, 'val_loss': 0.5844112205505371, 'test_acc': 0.795}
{'fold': 9, 'epoch': 30, 'train_loss': 0.3481556928157806, 'val_loss': 0.3678097152709961, 'test_acc': 0.845}
{'fold': 9, 'epoch': 31, 'train_loss': 0.3325992250442505, 'val_loss': 0.3287131881713867, 'test_acc': 0.825}
{'fold': 9, 'epoch': 32, 'train_loss': 0.3467827546596527, 'val_loss': 0.31657354354858397, 'test_acc': 0.87}
{'fold': 9, 'epoch': 33, 'train_loss': 0.3180793571472168, 'val_loss': 0.4529207420349121, 'test_acc': 0.795}
{'fold': 9, 'epoch': 34, 'train_loss': 0.349271057844162, 'val_loss': 0.3622141742706299, 'test_acc': 0.83}
{'fold': 9, 'epoch': 35, 'train_loss': 0.3634627890586853, 'val_loss': 0.3362241554260254, 'test_acc': 0.855}
{'fold': 9, 'epoch': 36, 'train_loss': 0.3341788923740387, 'val_loss': 0.5799307727813721, 'test_acc': 0.74}
{'fold': 9, 'epoch': 37, 'train_loss': 0.33223263382911683, 'val_loss': 0.3471609401702881, 'test_acc': 0.855}
{'fold': 9, 'epoch': 38, 'train_loss': 0.32657528400421143, 'val_loss': 0.32423038482666017, 'test_acc': 0.875}
{'fold': 9, 'epoch': 39, 'train_loss': 0.32927990317344663, 'val_loss': 0.2894206237792969, 'test_acc': 0.91}
{'fold': 9, 'epoch': 40, 'train_loss': 0.3159774279594421, 'val_loss': 0.27030650615692137, 'test_acc': 0.885}
{'fold': 9, 'epoch': 41, 'train_loss': 0.33012490928173066, 'val_loss': 0.3706369972229004, 'test_acc': 0.83}
{'fold': 9, 'epoch': 42, 'train_loss': 0.31046265482902524, 'val_loss': 0.39601847648620603, 'test_acc': 0.825}
{'fold': 9, 'epoch': 43, 'train_loss': 0.31478477001190186, 'val_loss': 0.2691122770309448, 'test_acc': 0.895}
{'fold': 9, 'epoch': 44, 'train_loss': 0.3091783213615418, 'val_loss': 0.28180149078369143, 'test_acc': 0.865}
{'fold': 9, 'epoch': 45, 'train_loss': 0.3050778818130493, 'val_loss': 0.4569657135009766, 'test_acc': 0.83}
{'fold': 9, 'epoch': 46, 'train_loss': 0.32188490152359006, 'val_loss': 0.3137077236175537, 'test_acc': 0.88}
{'fold': 9, 'epoch': 47, 'train_loss': 0.30035493075847625, 'val_loss': 0.2766213798522949, 'test_acc': 0.865}
{'fold': 9, 'epoch': 48, 'train_loss': 0.31040349006652834, 'val_loss': 0.3195044422149658, 'test_acc': 0.855}
{'fold': 9, 'epoch': 49, 'train_loss': 0.3035808777809143, 'val_loss': 0.47261775970458986, 'test_acc': 0.78}
{'fold': 9, 'epoch': 50, 'train_loss': 0.29497863292694093, 'val_loss': 0.3255048370361328, 'test_acc': 0.855}
{'fold': 9, 'epoch': 51, 'train_loss': 0.31825772285461423, 'val_loss': 0.2814276123046875, 'test_acc': 0.9}
{'fold': 9, 'epoch': 52, 'train_loss': 0.2880743956565857, 'val_loss': 0.3113703441619873, 'test_acc': 0.88}
{'fold': 9, 'epoch': 53, 'train_loss': 0.3049993360042572, 'val_loss': 0.4512792205810547, 'test_acc': 0.82}
{'fold': 9, 'epoch': 54, 'train_loss': 0.2890243291854858, 'val_loss': 0.2646720170974731, 'test_acc': 0.87}
{'fold': 9, 'epoch': 55, 'train_loss': 0.2781209850311279, 'val_loss': 0.3031810855865478, 'test_acc': 0.86}
{'fold': 9, 'epoch': 56, 'train_loss': 0.29986919403076173, 'val_loss': 0.3301692962646484, 'test_acc': 0.845}
{'fold': 9, 'epoch': 57, 'train_loss': 0.3184197175502777, 'val_loss': 0.48638235092163085, 'test_acc': 0.725}
{'fold': 9, 'epoch': 58, 'train_loss': 0.3225347936153412, 'val_loss': 0.37869091987609865, 'test_acc': 0.825}
{'fold': 9, 'epoch': 59, 'train_loss': 0.31750948786735533, 'val_loss': 0.5097623252868653, 'test_acc': 0.8}
{'fold': 9, 'epoch': 60, 'train_loss': 0.2977740168571472, 'val_loss': 0.30065794467926027, 'test_acc': 0.87}
{'fold': 9, 'epoch': 61, 'train_loss': 0.30517384290695193, 'val_loss': 0.32796828269958495, 'test_acc': 0.855}
{'fold': 9, 'epoch': 62, 'train_loss': 0.3054349994659424, 'val_loss': 0.28685632705688474, 'test_acc': 0.855}
{'fold': 9, 'epoch': 63, 'train_loss': 0.3100851118564606, 'val_loss': 0.4200584602355957, 'test_acc': 0.835}
{'fold': 9, 'epoch': 64, 'train_loss': 0.33275058269500735, 'val_loss': 0.2984748649597168, 'test_acc': 0.86}
{'fold': 9, 'epoch': 65, 'train_loss': 0.30633807063102725, 'val_loss': 0.3360214900970459, 'test_acc': 0.84}
{'fold': 9, 'epoch': 66, 'train_loss': 0.30894838750362397, 'val_loss': 0.29845348358154294, 'test_acc': 0.885}
{'fold': 9, 'epoch': 67, 'train_loss': 0.29633785486221315, 'val_loss': 0.2949806213378906, 'test_acc': 0.87}
{'fold': 9, 'epoch': 68, 'train_loss': 0.28848361134529116, 'val_loss': 0.2994484329223633, 'test_acc': 0.835}
{'fold': 9, 'epoch': 69, 'train_loss': 0.28202369511127473, 'val_loss': 0.23237161636352538, 'test_acc': 0.905}
{'fold': 9, 'epoch': 70, 'train_loss': 0.2594910848140717, 'val_loss': 0.21851731300354005, 'test_acc': 0.9}
{'fold': 9, 'epoch': 71, 'train_loss': 0.2664023208618164, 'val_loss': 0.2168484401702881, 'test_acc': 0.915}
{'fold': 9, 'epoch': 72, 'train_loss': 0.27633469700813296, 'val_loss': 0.35120258331298826, 'test_acc': 0.83}
{'fold': 9, 'epoch': 73, 'train_loss': 0.2560612142086029, 'val_loss': 0.2205996799468994, 'test_acc': 0.91}
{'fold': 9, 'epoch': 74, 'train_loss': 0.25311801373958587, 'val_loss': 0.2336874771118164, 'test_acc': 0.885}
{'fold': 9, 'epoch': 75, 'train_loss': 0.2713651692867279, 'val_loss': 0.19889212131500245, 'test_acc': 0.9}
{'fold': 9, 'epoch': 76, 'train_loss': 0.2537789559364319, 'val_loss': 0.20681338787078857, 'test_acc': 0.915}
{'fold': 9, 'epoch': 77, 'train_loss': 0.2579457998275757, 'val_loss': 0.2868106937408447, 'test_acc': 0.875}
{'fold': 9, 'epoch': 78, 'train_loss': 0.30184386372566224, 'val_loss': 0.31403783321380613, 'test_acc': 0.815}
{'fold': 9, 'epoch': 79, 'train_loss': 0.2966845542192459, 'val_loss': 0.29250518798828123, 'test_acc': 0.875}
{'fold': 9, 'epoch': 80, 'train_loss': 0.2777309411764145, 'val_loss': 0.5704311943054199, 'test_acc': 0.715}
{'fold': 9, 'epoch': 81, 'train_loss': 0.2787394988536835, 'val_loss': 0.3581955814361572, 'test_acc': 0.87}
{'fold': 9, 'epoch': 82, 'train_loss': 0.264946893453598, 'val_loss': 0.251035680770874, 'test_acc': 0.865}
{'fold': 9, 'epoch': 83, 'train_loss': 0.25243319988250734, 'val_loss': 0.2142917251586914, 'test_acc': 0.9}
{'fold': 9, 'epoch': 84, 'train_loss': 0.2517917048931122, 'val_loss': 0.22549898147583008, 'test_acc': 0.905}
{'fold': 9, 'epoch': 85, 'train_loss': 0.2513278967142105, 'val_loss': 0.21775556564331056, 'test_acc': 0.895}
{'fold': 9, 'epoch': 86, 'train_loss': 0.2545451998710632, 'val_loss': 0.20502674102783203, 'test_acc': 0.905}
{'fold': 9, 'epoch': 87, 'train_loss': 0.24459227323532104, 'val_loss': 0.2696449995040894, 'test_acc': 0.86}
{'fold': 9, 'epoch': 88, 'train_loss': 0.22878522515296937, 'val_loss': 0.22002158641815187, 'test_acc': 0.895}
{'fold': 9, 'epoch': 89, 'train_loss': 0.25350542783737184, 'val_loss': 0.22356726169586183, 'test_acc': 0.9}
{'fold': 9, 'epoch': 90, 'train_loss': 0.25427196860313417, 'val_loss': 0.3227203845977783, 'test_acc': 0.85}
{'fold': 9, 'epoch': 91, 'train_loss': 0.23002800822257996, 'val_loss': 0.26606509685516355, 'test_acc': 0.88}
{'fold': 9, 'epoch': 92, 'train_loss': 0.2412198841571808, 'val_loss': 0.36888503074645995, 'test_acc': 0.845}
{'fold': 9, 'epoch': 93, 'train_loss': 0.23193185329437255, 'val_loss': 0.21277185440063476, 'test_acc': 0.925}
{'fold': 9, 'epoch': 94, 'train_loss': 0.22521634697914122, 'val_loss': 0.20448161125183106, 'test_acc': 0.92}
{'fold': 9, 'epoch': 95, 'train_loss': 0.24737311482429505, 'val_loss': 0.2908023929595947, 'test_acc': 0.87}
{'fold': 9, 'epoch': 96, 'train_loss': 0.24799248814582825, 'val_loss': 0.2721714496612549, 'test_acc': 0.895}
{'fold': 9, 'epoch': 97, 'train_loss': 0.2558970409631729, 'val_loss': 0.22441811084747315, 'test_acc': 0.905}
{'fold': 9, 'epoch': 98, 'train_loss': 0.25403001308441164, 'val_loss': 0.21598366260528565, 'test_acc': 0.92}
{'fold': 9, 'epoch': 99, 'train_loss': 0.2297426688671112, 'val_loss': 0.22620755195617676, 'test_acc': 0.91}
{'fold': 9, 'epoch': 100, 'train_loss': 0.23898885190486907, 'val_loss': 0.2147558307647705, 'test_acc': 0.93}
Val Loss: 0.2272, Test Accuracy: 0.894 ± 0.029, Duration: 23.313
Best result - 0.894 ± 0.029
--
DD - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6511767254037372, 'val_loss': 7.400257599659455, 'test_acc': 0.41025641025641024}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6061508594933203, 'val_loss': 1.1973704802684295, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6181762945854058, 'val_loss': 0.6565389388646835, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5249600304385363, 'val_loss': 1.066551990998097, 'test_acc': 0.47863247863247865}
{'fold': 9, 'epoch': 5, 'train_loss': 0.4655179664240045, 'val_loss': 0.6460223727756076, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 6, 'train_loss': 0.49831744826446145, 'val_loss': 0.6174504206730769, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 7, 'train_loss': 0.49112197756767273, 'val_loss': 0.7612748757386819, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 8, 'train_loss': 0.4634900679022579, 'val_loss': 0.6228009085369925, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 9, 'train_loss': 0.47812317084457917, 'val_loss': 0.5544715294471154, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 10, 'train_loss': 0.4271827431048377, 'val_loss': 0.7427854619474492, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 11, 'train_loss': 0.39772491838972446, 'val_loss': 0.5700947688176081, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4029620991925062, 'val_loss': 0.8537036211062701, 'test_acc': 0.5982905982905983}
{'fold': 9, 'epoch': 13, 'train_loss': 0.39478296445587935, 'val_loss': 2.3874363043369393, 'test_acc': 0.452991452991453}
{'fold': 9, 'epoch': 14, 'train_loss': 0.37079001230708625, 'val_loss': 0.702141851441473, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 15, 'train_loss': 0.3261051859896062, 'val_loss': 1.1340208135099492, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 16, 'train_loss': 0.3262777497707787, 'val_loss': 1.0825247479300213, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 17, 'train_loss': 0.33725261385157956, 'val_loss': 0.7560088328826122, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 18, 'train_loss': 0.32328073655144646, 'val_loss': 1.0745408147828193, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 19, 'train_loss': 0.3344995879520804, 'val_loss': 1.2508364946414263, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 20, 'train_loss': 0.32872837655625103, 'val_loss': 1.3672727927183495, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 21, 'train_loss': 0.2828619144225525, 'val_loss': 0.9168978308001136, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 22, 'train_loss': 0.27360507441779314, 'val_loss': 0.979736328125, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 23, 'train_loss': 0.24632874257483725, 'val_loss': 1.0091182350093484, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 24, 'train_loss': 0.30948750649468376, 'val_loss': 1.6595848931206598, 'test_acc': 0.49572649572649574}
{'fold': 9, 'epoch': 25, 'train_loss': 0.34271624280234514, 'val_loss': 0.8326006506243323, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 26, 'train_loss': 0.28192051032842214, 'val_loss': 1.0925101907844217, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 27, 'train_loss': 0.23532863491672582, 'val_loss': 1.419234838241186, 'test_acc': 0.5042735042735043}
{'fold': 9, 'epoch': 28, 'train_loss': 0.20623841262974982, 'val_loss': 1.2941485021868322, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 29, 'train_loss': 0.17261915666572117, 'val_loss': 0.946060050247062, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 30, 'train_loss': 0.15281732380390167, 'val_loss': 1.5750408987713675, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 31, 'train_loss': 0.16523924368922993, 'val_loss': 1.2720550797943375, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 32, 'train_loss': 0.22333960411912304, 'val_loss': 1.3509752322465947, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 33, 'train_loss': 0.32149203753067274, 'val_loss': 0.7546910995092148, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 34, 'train_loss': 0.27733716520212465, 'val_loss': 1.0073089599609375, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 35, 'train_loss': 0.23301035973985315, 'val_loss': 1.2330576578776042, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 36, 'train_loss': 0.19102408724316097, 'val_loss': 2.1381426428118324, 'test_acc': 0.49572649572649574}
{'fold': 9, 'epoch': 37, 'train_loss': 0.15590173208107383, 'val_loss': 1.412935566698384, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 38, 'train_loss': 0.12780840132953758, 'val_loss': 1.8975651406834269, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 39, 'train_loss': 0.08841612190008163, 'val_loss': 2.1387952494825053, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 40, 'train_loss': 0.08072677021056919, 'val_loss': 1.8952841473440838, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 41, 'train_loss': 0.06134493383815733, 'val_loss': 2.1212319920205664, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 42, 'train_loss': 0.10324917910462719, 'val_loss': 2.742501283303285, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 43, 'train_loss': 0.14954184715525579, 'val_loss': 2.414913079677484, 'test_acc': 0.5042735042735043}
{'fold': 9, 'epoch': 44, 'train_loss': 0.2129894929417109, 'val_loss': 2.003283508822449, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 45, 'train_loss': 0.16472298803470903, 'val_loss': 2.163675031091413, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 46, 'train_loss': 0.11751536923950001, 'val_loss': 2.6775486611912394, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 47, 'train_loss': 0.0630137609096907, 'val_loss': 1.6490826729016426, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 48, 'train_loss': 0.036975498942626736, 'val_loss': 2.298392271384215, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 49, 'train_loss': 0.04220599573010863, 'val_loss': 2.483055440788595, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 50, 'train_loss': 0.04923147139912945, 'val_loss': 2.876984425080128, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 51, 'train_loss': 0.0847831799380355, 'val_loss': 2.035911886101095, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 52, 'train_loss': 0.12691421813126338, 'val_loss': 3.404254098223825, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 53, 'train_loss': 0.10795050442723905, 'val_loss': 2.1579173813518295, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 54, 'train_loss': 0.09737582428980682, 'val_loss': 1.7508895743606436, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 55, 'train_loss': 0.06669771191427264, 'val_loss': 1.9914147792718349, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 56, 'train_loss': 0.05943320869957491, 'val_loss': 2.4137054182525373, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 57, 'train_loss': 0.039914291004760794, 'val_loss': 2.6492990347055287, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 58, 'train_loss': 0.029839907536062145, 'val_loss': 2.3332409980969553, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 59, 'train_loss': 0.016014618704379615, 'val_loss': 2.2038026467347755, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 60, 'train_loss': 0.011832761846609035, 'val_loss': 2.0477966569427752, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 61, 'train_loss': 0.015681347951798114, 'val_loss': 2.3611645820813303, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 62, 'train_loss': 0.07905210472517095, 'val_loss': 3.6618031558827457, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 63, 'train_loss': 0.055871420113717096, 'val_loss': 3.2478922004373665, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 64, 'train_loss': 0.10113440131989576, 'val_loss': 4.476160293970352, 'test_acc': 0.5384615384615384}
{'fold': 9, 'epoch': 65, 'train_loss': 0.11417737015980785, 'val_loss': 3.0538807404346957, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 66, 'train_loss': 0.13423821380582907, 'val_loss': 2.2832305125701122, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 67, 'train_loss': 0.10996124842914484, 'val_loss': 1.6630996312850561, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 68, 'train_loss': 0.04242630429187064, 'val_loss': 1.4229761107355101, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 69, 'train_loss': 0.024405189995038306, 'val_loss': 1.6371300852196848, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 70, 'train_loss': 0.0329270260566372, 'val_loss': 1.8878692887787125, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 71, 'train_loss': 0.033160850153131, 'val_loss': 2.8032886472522702, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 72, 'train_loss': 0.056252596647305, 'val_loss': 2.5711949014256144, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 73, 'train_loss': 0.054476357475554536, 'val_loss': 1.954942621736445, 'test_acc': 0.5982905982905983}
{'fold': 9, 'epoch': 74, 'train_loss': 0.02895595916246964, 'val_loss': 2.1113150832999468, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 75, 'train_loss': 0.07694929566676334, 'val_loss': 2.4573074732071314, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 76, 'train_loss': 0.0687271172212342, 'val_loss': 2.500575660640358, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 77, 'train_loss': 0.1279594418355974, 'val_loss': 2.459332066723424, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 78, 'train_loss': 0.12653596194113714, 'val_loss': 1.717925764556624, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 79, 'train_loss': 0.08769605674986113, 'val_loss': 1.1632393078926282, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 80, 'train_loss': 0.07911907881498337, 'val_loss': 1.350667969793336, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 81, 'train_loss': 0.044427527304170496, 'val_loss': 1.7649302686381543, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 82, 'train_loss': 0.028174396730580573, 'val_loss': 2.0145982269547944, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 83, 'train_loss': 0.029219268316055758, 'val_loss': 2.1397295568743324, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 84, 'train_loss': 0.011128112610618947, 'val_loss': 2.2598329201722755, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 85, 'train_loss': 0.006173350793009592, 'val_loss': 2.805026584201389, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 86, 'train_loss': 0.009523945928144789, 'val_loss': 2.8290640024038463, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 87, 'train_loss': 0.008958145099991963, 'val_loss': 2.8962639702690973, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 88, 'train_loss': 0.00715133328517599, 'val_loss': 3.0917637490818644, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 89, 'train_loss': 0.005464542223539172, 'val_loss': 3.1074998643663196, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 90, 'train_loss': 0.006848370372238806, 'val_loss': 3.431557940621661, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 91, 'train_loss': 0.041303595922634766, 'val_loss': 3.2355281471187234, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 92, 'train_loss': 0.09029083282260572, 'val_loss': 2.68710692316039, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 93, 'train_loss': 0.09595257403739428, 'val_loss': 2.172601813943977, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 94, 'train_loss': 0.08515232473106707, 'val_loss': 1.5437387319711537, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 95, 'train_loss': 0.06261667836520632, 'val_loss': 2.103023692073985, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 96, 'train_loss': 0.03509067036842896, 'val_loss': 2.6606090578258548, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 97, 'train_loss': 0.028922103945229014, 'val_loss': 2.7082115238548345, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 98, 'train_loss': 0.00759988107671172, 'val_loss': 2.79974365234375, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 99, 'train_loss': 0.004244523043981043, 'val_loss': 3.0159325232872596, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 100, 'train_loss': 0.007549594929915363, 'val_loss': 3.116289709368323, 'test_acc': 0.6752136752136753}
Val Loss: 0.5888, Test Accuracy: 0.671 ± 0.032, Duration: 14.078
Best result - 0.671 ± 0.032
--
NCI1 - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6713100629711383, 'val_loss': 1.0944973279669916, 'test_acc': 0.5085158150851582}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6099691305427366, 'val_loss': 0.8724221324688617, 'test_acc': 0.6228710462287105}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6179394191198976, 'val_loss': 0.7182290942709522, 'test_acc': 0.5790754257907542}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6094417196410706, 'val_loss': 0.5793127445118851, 'test_acc': 0.6545012165450121}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6016029975130031, 'val_loss': 0.6013338618034864, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5889921182553554, 'val_loss': 0.6618762375954584, 'test_acc': 0.6082725060827251}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5940517658444797, 'val_loss': 0.792345478586907, 'test_acc': 0.5790754257907542}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5689545965542758, 'val_loss': 0.621561085220671, 'test_acc': 0.6058394160583942}
{'fold': 9, 'epoch': 9, 'train_loss': 0.5606713149959444, 'val_loss': 0.7275837227665884, 'test_acc': 0.6228710462287105}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5661914924345457, 'val_loss': 0.7484170723425501, 'test_acc': 0.5815085158150851}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5662664317156567, 'val_loss': 0.6651190922498122, 'test_acc': 0.6447688564476886}
{'fold': 9, 'epoch': 12, 'train_loss': 0.54584617292794, 'val_loss': 0.64410380435396, 'test_acc': 0.6447688564476886}
{'fold': 9, 'epoch': 13, 'train_loss': 0.5629664025747573, 'val_loss': 0.6497723006273999, 'test_acc': 0.6180048661800487}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5473113438508806, 'val_loss': 0.6262661616007487, 'test_acc': 0.6399026763990268}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5313383951384366, 'val_loss': 0.7457513507555291, 'test_acc': 0.6034063260340633}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5507254206061073, 'val_loss': 0.588297572449176, 'test_acc': 0.681265206812652}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5400706251172254, 'val_loss': 0.8901049574506253, 'test_acc': 0.5693430656934306}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5342589757448275, 'val_loss': 0.693969457398946, 'test_acc': 0.6204379562043796}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5367144881373774, 'val_loss': 0.6013384259820275, 'test_acc': 0.6618004866180048}
{'fold': 9, 'epoch': 20, 'train_loss': 0.527205736967769, 'val_loss': 0.937478216315128, 'test_acc': 0.6472019464720195}
{'fold': 9, 'epoch': 21, 'train_loss': 0.543108872616088, 'val_loss': 0.6358496487285679, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5394969362122009, 'val_loss': 0.6303279440478397, 'test_acc': 0.6326034063260341}
{'fold': 9, 'epoch': 23, 'train_loss': 0.523082697768571, 'val_loss': 0.583991076244345, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5249243612127003, 'val_loss': 0.5555756469132547, 'test_acc': 0.6909975669099757}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5184082413531858, 'val_loss': 0.9109045177190553, 'test_acc': 0.5571776155717761}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5172991930278258, 'val_loss': 0.5986264129044656, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 27, 'train_loss': 0.4986753668228205, 'val_loss': 0.5353282826370276, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5055132714936333, 'val_loss': 0.5431216952284467, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5024242699871388, 'val_loss': 0.6609783404644969, 'test_acc': 0.6326034063260341}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5061591771542301, 'val_loss': 0.6988472114804307, 'test_acc': 0.6618004866180048}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5063380691836931, 'val_loss': 0.6281225130215758, 'test_acc': 0.6788321167883211}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5098767097849045, 'val_loss': 0.5909369438524084, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 33, 'train_loss': 0.49526648727356665, 'val_loss': 0.598636464770983, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 34, 'train_loss': 0.478565599724034, 'val_loss': 0.5769144601195398, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 35, 'train_loss': 0.49187852213852595, 'val_loss': 0.565159159565204, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 36, 'train_loss': 0.4900744963446383, 'val_loss': 0.6695674051623565, 'test_acc': 0.656934306569343}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5019342905848566, 'val_loss': 0.5557868266047642, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 38, 'train_loss': 0.49145826849624186, 'val_loss': 0.6379889409327449, 'test_acc': 0.6593673965936739}
{'fold': 9, 'epoch': 39, 'train_loss': 0.4754023789779403, 'val_loss': 0.5786050624801005, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 40, 'train_loss': 0.47320814158794655, 'val_loss': 0.6274653293210515, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 41, 'train_loss': 0.49220154247724807, 'val_loss': 0.6099298945888696, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 42, 'train_loss': 0.4905127049797643, 'val_loss': 0.574324712266017, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 43, 'train_loss': 0.4989134370555553, 'val_loss': 0.6353063560170269, 'test_acc': 0.6788321167883211}
{'fold': 9, 'epoch': 44, 'train_loss': 0.48020978681652504, 'val_loss': 0.5981682594095123, 'test_acc': 0.6934306569343066}
{'fold': 9, 'epoch': 45, 'train_loss': 0.46948631082428055, 'val_loss': 0.5912483869677913, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 46, 'train_loss': 0.46251839892417557, 'val_loss': 0.5864712606091279, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 47, 'train_loss': 0.4918501359702897, 'val_loss': 0.5513315316824438, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 48, 'train_loss': 0.4809504265912838, 'val_loss': 0.6222146468150934, 'test_acc': 0.6763990267639902}
{'fold': 9, 'epoch': 49, 'train_loss': 0.4607615634762748, 'val_loss': 0.5378068566612374, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 50, 'train_loss': 0.46190131102165166, 'val_loss': 0.6575853853620172, 'test_acc': 0.6861313868613139}
{'fold': 9, 'epoch': 51, 'train_loss': 0.46815007475460824, 'val_loss': 0.5484387427930995, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 52, 'train_loss': 0.45254916322492333, 'val_loss': 0.6240113669068273, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 53, 'train_loss': 0.4578334951632794, 'val_loss': 0.616065046212969, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 54, 'train_loss': 0.45575534869574574, 'val_loss': 0.49535927459271284, 'test_acc': 0.7615571776155717}
{'fold': 9, 'epoch': 55, 'train_loss': 0.4494314013896487, 'val_loss': 0.5129386201102079, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 56, 'train_loss': 0.44102329436299864, 'val_loss': 0.5991489939445996, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 57, 'train_loss': 0.4801508064977734, 'val_loss': 1.2191899849550567, 'test_acc': 0.5109489051094891}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5541389165423503, 'val_loss': 0.5770384099361671, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 59, 'train_loss': 0.5057004256550123, 'val_loss': 0.6483798989994393, 'test_acc': 0.6545012165450121}
{'fold': 9, 'epoch': 60, 'train_loss': 0.47851575827656584, 'val_loss': 0.6568022818460951, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 61, 'train_loss': 0.4755876991000489, 'val_loss': 0.5130632358745937, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 62, 'train_loss': 0.46073589323500935, 'val_loss': 0.7866286697758955, 'test_acc': 0.6472019464720195}
{'fold': 9, 'epoch': 63, 'train_loss': 0.4681310568847796, 'val_loss': 0.5803751748263691, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 64, 'train_loss': 0.4660391691537379, 'val_loss': 0.5367352376599092, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 65, 'train_loss': 0.4606340775524613, 'val_loss': 0.5736847898385821, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 66, 'train_loss': 0.4566596715989774, 'val_loss': 0.5217572418732654, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 67, 'train_loss': 0.42882758074433264, 'val_loss': 0.5837497247106548, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 68, 'train_loss': 0.4545836318873431, 'val_loss': 1.601081744887823, 'test_acc': 0.5669099756690997}
{'fold': 9, 'epoch': 69, 'train_loss': 0.5011907061086084, 'val_loss': 0.8734456454460349, 'test_acc': 0.6326034063260341}
{'fold': 9, 'epoch': 70, 'train_loss': 0.45659427094633565, 'val_loss': 0.5505625638938588, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 71, 'train_loss': 0.44020343261913664, 'val_loss': 0.6036015183386141, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 72, 'train_loss': 0.44342553376281346, 'val_loss': 0.6341473168700281, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 73, 'train_loss': 0.43218218424604465, 'val_loss': 0.6670821716605602, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 74, 'train_loss': 0.46466554277134636, 'val_loss': 0.5487212392245476, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 75, 'train_loss': 0.42362831899139425, 'val_loss': 0.7170218516440288, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 76, 'train_loss': 0.4311238950766496, 'val_loss': 0.5446291642757518, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 77, 'train_loss': 0.43258057755855456, 'val_loss': 0.5580475614598778, 'test_acc': 0.7639902676399026}
{'fold': 9, 'epoch': 78, 'train_loss': 0.4250612721535991, 'val_loss': 0.5669268192746053, 'test_acc': 0.6861313868613139}
{'fold': 9, 'epoch': 79, 'train_loss': 0.42793118351857445, 'val_loss': 0.5483073677749819, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 80, 'train_loss': 0.4261575233907305, 'val_loss': 0.66020388266756, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 81, 'train_loss': 0.43377856079969385, 'val_loss': 0.6110057181105416, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 82, 'train_loss': 0.4265270821224454, 'val_loss': 0.5330632806114327, 'test_acc': 0.7761557177615572}
{'fold': 9, 'epoch': 83, 'train_loss': 0.41378178967756657, 'val_loss': 0.6118768009826214, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 84, 'train_loss': 0.41969584251262265, 'val_loss': 0.5735344666344115, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 85, 'train_loss': 0.4262465697570439, 'val_loss': 0.6169185638427734, 'test_acc': 0.6788321167883211}
{'fold': 9, 'epoch': 86, 'train_loss': 0.4119091743100299, 'val_loss': 0.5834449712377395, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 87, 'train_loss': 0.4072739419565874, 'val_loss': 0.5784602107212782, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 88, 'train_loss': 0.4098967950419498, 'val_loss': 0.5370473792083073, 'test_acc': 0.7688564476885644}
{'fold': 9, 'epoch': 89, 'train_loss': 0.4087644154137939, 'val_loss': 0.5212828851964352, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 90, 'train_loss': 0.40256395841747017, 'val_loss': 0.692744893169171, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 91, 'train_loss': 0.40869082608362184, 'val_loss': 0.5493061733941962, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 92, 'train_loss': 0.39130706849469465, 'val_loss': 0.5971506865935314, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 93, 'train_loss': 0.41512081135798545, 'val_loss': 0.6650373175776498, 'test_acc': 0.656934306569343}
{'fold': 9, 'epoch': 94, 'train_loss': 0.4029772575319248, 'val_loss': 0.5619015751673937, 'test_acc': 0.7688564476885644}
{'fold': 9, 'epoch': 95, 'train_loss': 0.39502265781091656, 'val_loss': 0.6251964986759381, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 96, 'train_loss': 0.40496947433246605, 'val_loss': 0.5374838859205409, 'test_acc': 0.7518248175182481}
{'fold': 9, 'epoch': 97, 'train_loss': 0.3952142536060073, 'val_loss': 0.5447056276084733, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 98, 'train_loss': 0.4025655059628823, 'val_loss': 0.6044843260679221, 'test_acc': 0.7007299270072993}
{'fold': 9, 'epoch': 99, 'train_loss': 0.3958990659446902, 'val_loss': 0.5954476655834783, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 100, 'train_loss': 0.4001609969458151, 'val_loss': 0.5140271662505583, 'test_acc': 0.7737226277372263}
Val Loss: 0.4948, Test Accuracy: 0.768 ± 0.035, Duration: 20.386
Best result - 0.768 ± 0.035
--
PROTEINS - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.7045529959712901, 'val_loss': 3.1229517481348537, 'test_acc': 0.42342342342342343}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6432628248944695, 'val_loss': 1.6428398613457207, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6333047342220139, 'val_loss': 1.074041005727407, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6215731066084068, 'val_loss': 0.6419037827500352, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 5, 'train_loss': 0.654828554318275, 'val_loss': 0.679256129909206, 'test_acc': 0.6576576576576577}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6230422646375885, 'val_loss': 0.6748230392868454, 'test_acc': 0.6396396396396397}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6062713125605642, 'val_loss': 0.6475148243947072, 'test_acc': 0.6126126126126126}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6135955899786601, 'val_loss': 0.5868347442901887, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 9, 'train_loss': 0.5909358303153555, 'val_loss': 0.6097196974195875, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5790634673720123, 'val_loss': 0.5962947811092343, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5861908439567729, 'val_loss': 0.5898421691344665, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5750767446795163, 'val_loss': 0.5665296949781813, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 13, 'train_loss': 0.56841962720141, 'val_loss': 0.6497265240093609, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5807202725967039, 'val_loss': 0.5798893146686726, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5697846976594892, 'val_loss': 0.5687869303935283, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5737955483255697, 'val_loss': 0.5369556530101879, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5881417615111294, 'val_loss': 0.6046484182546804, 'test_acc': 0.6396396396396397}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5834357901052996, 'val_loss': 0.5362966039159276, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5564510970806031, 'val_loss': 0.5655673602679828, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 20, 'train_loss': 0.5991719924373391, 'val_loss': 0.5480610959164731, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 21, 'train_loss': 0.588949191516765, 'val_loss': 0.5574726414036106, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 22, 'train_loss': 0.576197884232642, 'val_loss': 0.5450095099371832, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5823740961843334, 'val_loss': 0.5744614128593926, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5674826241904236, 'val_loss': 0.551630415357985, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5655874595230008, 'val_loss': 0.5771153080570806, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5516154163346682, 'val_loss': 0.5863933391399212, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5523885329965791, 'val_loss': 0.521225491085568, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5564609474338399, 'val_loss': 0.5276431521853885, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5735735934056283, 'val_loss': 0.5269392889899176, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5749358866618807, 'val_loss': 0.5636345459534241, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5985166957616539, 'val_loss': 0.6251753386076506, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5695413429327686, 'val_loss': 0.656504725550746, 'test_acc': 0.6306306306306306}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5767882915190709, 'val_loss': 0.5316546672099346, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5935027796009975, 'val_loss': 0.5989025906399563, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 35, 'train_loss': 0.5587408102455096, 'val_loss': 0.6327097437403224, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5854538979487521, 'val_loss': 0.5892994511234868, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5423402905999343, 'val_loss': 0.5528445888209987, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5845911700182357, 'val_loss': 0.5283313785587345, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 39, 'train_loss': 0.5685276365708288, 'val_loss': 0.6011784184086431, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5725054668657708, 'val_loss': 0.5836443514437288, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 41, 'train_loss': 0.5584112527528329, 'val_loss': 0.6723852071676168, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5798078349276157, 'val_loss': 0.5869279466233812, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 43, 'train_loss': 0.5729335732465374, 'val_loss': 0.566577877010311, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 44, 'train_loss': 0.5662373674972825, 'val_loss': 0.5269065032134185, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 45, 'train_loss': 0.5560005618934546, 'val_loss': 0.5435455253532341, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 46, 'train_loss': 0.5381262155895683, 'val_loss': 0.5313211045823656, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 47, 'train_loss': 0.5426089743572453, 'val_loss': 0.4857137869070242, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 48, 'train_loss': 0.5310946027638535, 'val_loss': 0.5280750377758129, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 49, 'train_loss': 0.5234305761612358, 'val_loss': 0.5651702880859375, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 50, 'train_loss': 0.5386759549814175, 'val_loss': 0.6217393617372255, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 51, 'train_loss': 0.5221707184708079, 'val_loss': 0.5533137278513865, 'test_acc': 0.6396396396396397}
{'fold': 9, 'epoch': 52, 'train_loss': 0.5300884392325725, 'val_loss': 0.5839925542608038, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 53, 'train_loss': 0.5448029691522772, 'val_loss': 0.6191945118947072, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 54, 'train_loss': 0.5382396505871739, 'val_loss': 0.5561371880608637, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 55, 'train_loss': 0.5264039765437176, 'val_loss': 0.5521867081925675, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 56, 'train_loss': 0.5311582523296712, 'val_loss': 0.5523767900896502, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 57, 'train_loss': 0.5449880110695707, 'val_loss': 0.5063398550222585, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5312889409653935, 'val_loss': 0.5836471695083756, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 59, 'train_loss': 0.51935693538015, 'val_loss': 0.5218383514129363, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 60, 'train_loss': 0.53239833947384, 'val_loss': 0.5388432064571896, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 61, 'train_loss': 0.5331871542331211, 'val_loss': 0.5630076296694644, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 62, 'train_loss': 0.5136891178009084, 'val_loss': 0.4738714544622748, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 63, 'train_loss': 0.5162128246191776, 'val_loss': 0.5150642738685952, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 64, 'train_loss': 0.5291331421780399, 'val_loss': 0.5156236253343187, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 65, 'train_loss': 0.5333415981963293, 'val_loss': 0.4877857173885311, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 66, 'train_loss': 0.5044303571201201, 'val_loss': 0.5095536859185846, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 67, 'train_loss': 0.5011468401260247, 'val_loss': 0.574482926377305, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 68, 'train_loss': 0.5259117257983061, 'val_loss': 0.5691755140149916, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 69, 'train_loss': 0.5231086129759565, 'val_loss': 0.5368312113993877, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 70, 'train_loss': 0.520505654189723, 'val_loss': 0.5392691809851844, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 71, 'train_loss': 0.5209906635394134, 'val_loss': 0.5372584574931377, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 72, 'train_loss': 0.5256559553103549, 'val_loss': 0.587361309979413, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 73, 'train_loss': 0.5342853870054688, 'val_loss': 0.5320502272597304, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 74, 'train_loss': 0.5211945342361994, 'val_loss': 0.572859136907904, 'test_acc': 0.6036036036036037}
{'fold': 9, 'epoch': 75, 'train_loss': 0.49962721030853946, 'val_loss': 0.5709129883362366, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 76, 'train_loss': 0.5318452290412954, 'val_loss': 0.5585912068684896, 'test_acc': 0.6576576576576577}
{'fold': 9, 'epoch': 77, 'train_loss': 0.541831467221214, 'val_loss': 0.5590890420449747, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 78, 'train_loss': 0.5552051932991019, 'val_loss': 0.5445154207246797, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 79, 'train_loss': 0.5210435364048355, 'val_loss': 0.5004813048216674, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 80, 'train_loss': 0.5164612575813576, 'val_loss': 0.5429776509602865, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 81, 'train_loss': 0.5238989540757287, 'val_loss': 0.6097369494738879, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 82, 'train_loss': 0.5265698528584138, 'val_loss': 0.5047056180936796, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 83, 'train_loss': 0.5372305596048716, 'val_loss': 0.5174346442695137, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 84, 'train_loss': 0.5072773562537299, 'val_loss': 0.5474273750373909, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 85, 'train_loss': 0.4983166078258176, 'val_loss': 0.5397640262638126, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 86, 'train_loss': 0.47894748463373793, 'val_loss': 0.5480586558848888, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 87, 'train_loss': 0.4981313189272126, 'val_loss': 0.5027827357386684, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 88, 'train_loss': 0.5038779446840553, 'val_loss': 0.5392484235333966, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 89, 'train_loss': 0.5048203570005201, 'val_loss': 0.6299824757618947, 'test_acc': 0.6576576576576577}
{'fold': 9, 'epoch': 90, 'train_loss': 0.509381849958439, 'val_loss': 0.5494935662896784, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 91, 'train_loss': 0.5264607780977799, 'val_loss': 0.552837406192814, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 92, 'train_loss': 0.4888020201296651, 'val_loss': 0.5097981014767209, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 93, 'train_loss': 0.4828495109322095, 'val_loss': 0.497756442508182, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 94, 'train_loss': 0.5012781013275771, 'val_loss': 0.5990030099679758, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 95, 'train_loss': 0.4987081999061619, 'val_loss': 0.5383250949619053, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 96, 'train_loss': 0.48856897627063073, 'val_loss': 0.5279409391386015, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 97, 'train_loss': 0.5111027974739888, 'val_loss': 0.5395251437350437, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 98, 'train_loss': 0.4979482950720054, 'val_loss': 0.5588373407587275, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 99, 'train_loss': 0.48001877955180894, 'val_loss': 0.5458767521488774, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 100, 'train_loss': 0.47127903618261335, 'val_loss': 0.5354376096983213, 'test_acc': 0.7567567567567568}
Val Loss: 0.5089, Test Accuracy: 0.717 ± 0.036, Duration: 5.467
Best result - 0.717 ± 0.036
--
COLLAB - GIN
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.7682827801704407, 'val_loss': 0.6765325164794922, 'test_acc': 0.678}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6555971317291259, 'val_loss': 0.6398432846069336, 'test_acc': 0.726}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6133946895599365, 'val_loss': 0.589376693725586, 'test_acc': 0.706}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6379943385124206, 'val_loss': 0.6221880416870117, 'test_acc': 0.724}
{'fold': 9, 'epoch': 5, 'train_loss': 0.597866044998169, 'val_loss': 0.648443618774414, 'test_acc': 0.708}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6025357663631439, 'val_loss': 0.7909100952148438, 'test_acc': 0.77}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5930251750946045, 'val_loss': 10.872993774414063, 'test_acc': 0.71}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5604045600891113, 'val_loss': 0.5146403884887696, 'test_acc': 0.756}
{'fold': 9, 'epoch': 9, 'train_loss': 0.5729253787994385, 'val_loss': 0.5609917755126953, 'test_acc': 0.772}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5598818283081055, 'val_loss': 0.5165175857543945, 'test_acc': 0.752}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5602179689407348, 'val_loss': 0.5484763031005859, 'test_acc': 0.764}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5861031341552735, 'val_loss': 0.5153576354980469, 'test_acc': 0.734}
{'fold': 9, 'epoch': 13, 'train_loss': 0.5407348484992981, 'val_loss': 0.5111172790527344, 'test_acc': 0.776}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5269543561935425, 'val_loss': 0.5122350082397461, 'test_acc': 0.772}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5245069787502289, 'val_loss': 0.5518046340942383, 'test_acc': 0.752}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5043756430149078, 'val_loss': 0.4827781295776367, 'test_acc': 0.784}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5026825425624848, 'val_loss': 11.791411773681642, 'test_acc': 0.782}
{'fold': 9, 'epoch': 18, 'train_loss': 0.511855280160904, 'val_loss': 0.5731625022888184, 'test_acc': 0.76}
{'fold': 9, 'epoch': 19, 'train_loss': 0.49765150022506716, 'val_loss': 3.8397181701660155, 'test_acc': 0.714}
{'fold': 9, 'epoch': 20, 'train_loss': 0.4904377212524414, 'val_loss': 0.4863426856994629, 'test_acc': 0.774}
{'fold': 9, 'epoch': 21, 'train_loss': 0.520450466632843, 'val_loss': 0.5322065811157226, 'test_acc': 0.754}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5581758651733398, 'val_loss': 0.50652783203125, 'test_acc': 0.76}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5392621479034424, 'val_loss': 0.47491045379638674, 'test_acc': 0.798}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5093729195594787, 'val_loss': 0.5133831481933594, 'test_acc': 0.798}
{'fold': 9, 'epoch': 25, 'train_loss': 0.4613220233917236, 'val_loss': 0.4860990219116211, 'test_acc': 0.798}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5107900257110596, 'val_loss': 0.49997482299804685, 'test_acc': 0.758}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5086334977149963, 'val_loss': 0.48595130920410157, 'test_acc': 0.762}
{'fold': 9, 'epoch': 28, 'train_loss': 0.4784491500854492, 'val_loss': 0.49477337646484376, 'test_acc': 0.74}
{'fold': 9, 'epoch': 29, 'train_loss': 0.46072237205505373, 'val_loss': 0.512678840637207, 'test_acc': 0.76}
{'fold': 9, 'epoch': 30, 'train_loss': 0.6460076761245728, 'val_loss': 0.5062264785766601, 'test_acc': 0.77}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5327725834846496, 'val_loss': 0.5041955947875977, 'test_acc': 0.784}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5181421806812286, 'val_loss': 0.5030332412719727, 'test_acc': 0.778}
{'fold': 9, 'epoch': 33, 'train_loss': 0.4693322002887726, 'val_loss': 0.46223854064941405, 'test_acc': 0.788}
{'fold': 9, 'epoch': 34, 'train_loss': 0.44580183005332946, 'val_loss': 0.42943953704833987, 'test_acc': 0.796}
{'fold': 9, 'epoch': 35, 'train_loss': 0.45176217007637026, 'val_loss': 0.6010255813598633, 'test_acc': 0.784}
{'fold': 9, 'epoch': 36, 'train_loss': 0.4667530767917633, 'val_loss': 0.5552143669128418, 'test_acc': 0.768}
{'fold': 9, 'epoch': 37, 'train_loss': 0.4352891464233398, 'val_loss': 0.43742646026611326, 'test_acc': 0.8}
{'fold': 9, 'epoch': 38, 'train_loss': 0.43529563236236574, 'val_loss': 2.099968536376953, 'test_acc': 0.774}
{'fold': 9, 'epoch': 39, 'train_loss': 0.41559971141815183, 'val_loss': 0.5833795909881592, 'test_acc': 0.812}
{'fold': 9, 'epoch': 40, 'train_loss': 0.4583637800216675, 'val_loss': 0.5117697830200195, 'test_acc': 0.78}
{'fold': 9, 'epoch': 41, 'train_loss': 0.43704135417938234, 'val_loss': 0.517567440032959, 'test_acc': 0.786}
{'fold': 9, 'epoch': 42, 'train_loss': 0.39246173310279847, 'val_loss': 0.5198604774475097, 'test_acc': 0.802}
{'fold': 9, 'epoch': 43, 'train_loss': 0.388062600851059, 'val_loss': 0.40978401947021487, 'test_acc': 0.786}
{'fold': 9, 'epoch': 44, 'train_loss': 0.38149978828430176, 'val_loss': 0.4607365570068359, 'test_acc': 0.8}
{'fold': 9, 'epoch': 45, 'train_loss': 0.3756528391838074, 'val_loss': 0.4884580535888672, 'test_acc': 0.816}
{'fold': 9, 'epoch': 46, 'train_loss': 0.3772274262905121, 'val_loss': 0.5655798568725586, 'test_acc': 0.796}
{'fold': 9, 'epoch': 47, 'train_loss': 0.37066074323654175, 'val_loss': 0.5107275619506836, 'test_acc': 0.782}
{'fold': 9, 'epoch': 48, 'train_loss': 0.405710780620575, 'val_loss': 0.5116686744689941, 'test_acc': 0.794}
{'fold': 9, 'epoch': 49, 'train_loss': 0.3487591009140015, 'val_loss': 0.41343112564086915, 'test_acc': 0.794}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3304503593444824, 'val_loss': 0.44804766845703126, 'test_acc': 0.788}
{'fold': 9, 'epoch': 51, 'train_loss': 0.33677972269058226, 'val_loss': 0.4806090393066406, 'test_acc': 0.768}
{'fold': 9, 'epoch': 52, 'train_loss': 0.3549288909435272, 'val_loss': 0.40283673095703126, 'test_acc': 0.802}
{'fold': 9, 'epoch': 53, 'train_loss': 0.3474710328578949, 'val_loss': 0.4971694450378418, 'test_acc': 0.804}
{'fold': 9, 'epoch': 54, 'train_loss': 0.3595777072906494, 'val_loss': 12.5390590133667, 'test_acc': 0.608}
{'fold': 9, 'epoch': 55, 'train_loss': 0.3724765205383301, 'val_loss': 0.4697038803100586, 'test_acc': 0.752}
{'fold': 9, 'epoch': 56, 'train_loss': 0.36006830644607546, 'val_loss': 0.4965585823059082, 'test_acc': 0.792}
{'fold': 9, 'epoch': 57, 'train_loss': 0.3288114566802979, 'val_loss': 0.45164657974243166, 'test_acc': 0.792}
{'fold': 9, 'epoch': 58, 'train_loss': 0.3150604124069214, 'val_loss': 0.5212942962646484, 'test_acc': 0.78}
{'fold': 9, 'epoch': 59, 'train_loss': 0.3230947906970978, 'val_loss': 0.48342927169799804, 'test_acc': 0.758}
{'fold': 9, 'epoch': 60, 'train_loss': 0.30227279949188235, 'val_loss': 0.4794998779296875, 'test_acc': 0.778}
{'fold': 9, 'epoch': 61, 'train_loss': 0.29908781170845034, 'val_loss': 0.4586479644775391, 'test_acc': 0.766}
{'fold': 9, 'epoch': 62, 'train_loss': 0.3108800759315491, 'val_loss': 0.6020808944702148, 'test_acc': 0.758}
{'fold': 9, 'epoch': 63, 'train_loss': 0.3082699675559998, 'val_loss': 0.4811833419799805, 'test_acc': 0.79}
{'fold': 9, 'epoch': 64, 'train_loss': 0.35941475224494934, 'val_loss': 0.4680425338745117, 'test_acc': 0.772}
{'fold': 9, 'epoch': 65, 'train_loss': 0.3200325417518616, 'val_loss': 0.48113075256347654, 'test_acc': 0.792}
{'fold': 9, 'epoch': 66, 'train_loss': 0.30607384848594665, 'val_loss': 0.5220497245788575, 'test_acc': 0.764}
{'fold': 9, 'epoch': 67, 'train_loss': 0.3201045632362366, 'val_loss': 0.5556741485595703, 'test_acc': 0.792}
{'fold': 9, 'epoch': 68, 'train_loss': 0.33215013337135313, 'val_loss': 0.462460636138916, 'test_acc': 0.796}
{'fold': 9, 'epoch': 69, 'train_loss': 0.2958481087684631, 'val_loss': 0.6240107460021973, 'test_acc': 0.802}
{'fold': 9, 'epoch': 70, 'train_loss': 0.2900987491607666, 'val_loss': 0.5934139938354492, 'test_acc': 0.806}
{'fold': 9, 'epoch': 71, 'train_loss': 0.2835061378479004, 'val_loss': 0.506337116241455, 'test_acc': 0.786}
{'fold': 9, 'epoch': 72, 'train_loss': 0.28158269143104553, 'val_loss': 15.042561027526855, 'test_acc': 0.598}
{'fold': 9, 'epoch': 73, 'train_loss': 0.2770644396543503, 'val_loss': 0.5391089096069336, 'test_acc': 0.788}
{'fold': 9, 'epoch': 74, 'train_loss': 0.2665674152374268, 'val_loss': 0.538676383972168, 'test_acc': 0.79}
{'fold': 9, 'epoch': 75, 'train_loss': 0.2694292249679565, 'val_loss': 0.5631857757568359, 'test_acc': 0.792}
{'fold': 9, 'epoch': 76, 'train_loss': 0.2666739182472229, 'val_loss': 0.6130104942321777, 'test_acc': 0.794}
{'fold': 9, 'epoch': 77, 'train_loss': 0.33639588665962217, 'val_loss': 0.5504225006103516, 'test_acc': 0.786}
{'fold': 9, 'epoch': 78, 'train_loss': 0.27814072132110595, 'val_loss': 0.641116813659668, 'test_acc': 0.8}
{'fold': 9, 'epoch': 79, 'train_loss': 0.2729096772670746, 'val_loss': 0.5383358535766601, 'test_acc': 0.784}
{'fold': 9, 'epoch': 80, 'train_loss': 0.2491644961833954, 'val_loss': 0.5799317932128907, 'test_acc': 0.786}
{'fold': 9, 'epoch': 81, 'train_loss': 0.25885981166362765, 'val_loss': 0.5060965576171875, 'test_acc': 0.792}
{'fold': 9, 'epoch': 82, 'train_loss': 0.24152377676963807, 'val_loss': 0.7124349517822266, 'test_acc': 0.778}
{'fold': 9, 'epoch': 83, 'train_loss': 0.26551829290390017, 'val_loss': 0.6501982727050781, 'test_acc': 0.784}
{'fold': 9, 'epoch': 84, 'train_loss': 0.2862019777297974, 'val_loss': 0.5587698974609375, 'test_acc': 0.754}
{'fold': 9, 'epoch': 85, 'train_loss': 0.5128642745018005, 'val_loss': 0.5732092819213868, 'test_acc': 0.76}
{'fold': 9, 'epoch': 86, 'train_loss': 0.45384400081634524, 'val_loss': 0.6007861251831055, 'test_acc': 0.762}
{'fold': 9, 'epoch': 87, 'train_loss': 0.35417493391036986, 'val_loss': 0.5013045196533203, 'test_acc': 0.758}
{'fold': 9, 'epoch': 88, 'train_loss': 0.3324889206886292, 'val_loss': 0.6549386749267578, 'test_acc': 0.77}
{'fold': 9, 'epoch': 89, 'train_loss': 0.3366442519426346, 'val_loss': 0.630882453918457, 'test_acc': 0.776}
{'fold': 9, 'epoch': 90, 'train_loss': 0.30745672607421876, 'val_loss': 3.0752377700805664, 'test_acc': 0.776}
{'fold': 9, 'epoch': 91, 'train_loss': 0.3149237489700317, 'val_loss': 0.4917980499267578, 'test_acc': 0.79}
{'fold': 9, 'epoch': 92, 'train_loss': 0.2746002025604248, 'val_loss': 0.6668126716613769, 'test_acc': 0.806}
{'fold': 9, 'epoch': 93, 'train_loss': 0.26683288943767547, 'val_loss': 0.6446927299499512, 'test_acc': 0.812}
{'fold': 9, 'epoch': 94, 'train_loss': 0.26665951299667356, 'val_loss': 0.603192153930664, 'test_acc': 0.802}
{'fold': 9, 'epoch': 95, 'train_loss': 0.25294750738143923, 'val_loss': 0.6096764450073242, 'test_acc': 0.798}
{'fold': 9, 'epoch': 96, 'train_loss': 0.29581562769412995, 'val_loss': 0.5210113296508789, 'test_acc': 0.792}
{'fold': 9, 'epoch': 97, 'train_loss': 0.3090306346416473, 'val_loss': 0.4981506576538086, 'test_acc': 0.802}
{'fold': 9, 'epoch': 98, 'train_loss': 0.2664398559331894, 'val_loss': 0.7145368919372559, 'test_acc': 0.798}
{'fold': 9, 'epoch': 99, 'train_loss': 0.24200217056274415, 'val_loss': 0.5768275947570801, 'test_acc': 0.814}
{'fold': 9, 'epoch': 100, 'train_loss': 0.2427972786426544, 'val_loss': 0.6099046630859375, 'test_acc': 0.804}
Val Loss: 0.4388, Test Accuracy: 0.813 ± 0.014, Duration: 118.985
Best result - 0.813 ± 0.014
--
IMDB-MULTI - GIN: 0.501 ± 0.036
MUTAG - GIN: 0.819 ± 0.077
IMDB-BINARY - GIN: 0.733 ± 0.049
REDDIT-BINARY - GIN: 0.894 ± 0.029
DD - GIN: 0.671 ± 0.032
NCI1 - GIN: 0.768 ± 0.035
PROTEINS - GIN: 0.717 ± 0.036
COLLAB - GIN: 0.813 ± 0.014

Process finished with exit code 0
