D:\Program\Anaconda\envs\pyg\python.exe F:/Project/BernNet/GraphClassification/main.py
--
IMDB-MULTI - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 1.097345635096232, 'val_loss': 1.0576922861735025, 'test_acc': 0.48}
{'fold': 9, 'epoch': 2, 'train_loss': 1.057566819190979, 'val_loss': 1.0425988515218099, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 3, 'train_loss': 1.0183601784706116, 'val_loss': 1.0129817326863606, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 4, 'train_loss': 1.0162278850873312, 'val_loss': 1.03288756052653, 'test_acc': 0.43333333333333335}
{'fold': 9, 'epoch': 5, 'train_loss': 1.0251492834091187, 'val_loss': 1.0195263926188152, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 6, 'train_loss': 1.0091544977823894, 'val_loss': 1.0376259867350262, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 7, 'train_loss': 1.000876088142395, 'val_loss': 1.020924186706543, 'test_acc': 0.52}
{'fold': 9, 'epoch': 8, 'train_loss': 1.0118368768692017, 'val_loss': 1.039413070678711, 'test_acc': 0.46}
{'fold': 9, 'epoch': 9, 'train_loss': 1.003407645225525, 'val_loss': 1.0088935724894206, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 10, 'train_loss': 1.0050855684280395, 'val_loss': 1.0237838490804037, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 11, 'train_loss': 1.0084724521636963, 'val_loss': 1.0185203425089517, 'test_acc': 0.43333333333333335}
{'fold': 9, 'epoch': 12, 'train_loss': 0.9954522927602132, 'val_loss': 1.0058820978800456, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 13, 'train_loss': 0.9838260928789775, 'val_loss': 1.0136166254679362, 'test_acc': 0.48}
{'fold': 9, 'epoch': 14, 'train_loss': 0.984468830426534, 'val_loss': 1.0230791346232095, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 15, 'train_loss': 0.9811989831924438, 'val_loss': 1.046597048441569, 'test_acc': 0.5}
{'fold': 9, 'epoch': 16, 'train_loss': 0.9687978267669678, 'val_loss': 1.0435903040568033, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 17, 'train_loss': 0.9700108599662781, 'val_loss': 1.0705272165934245, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 18, 'train_loss': 0.9703947440783183, 'val_loss': 1.036406644185384, 'test_acc': 0.48}
{'fold': 9, 'epoch': 19, 'train_loss': 0.9587217386563619, 'val_loss': 1.0928149032592773, 'test_acc': 0.46}
{'fold': 9, 'epoch': 20, 'train_loss': 0.9686635494232178, 'val_loss': 1.077922732035319, 'test_acc': 0.46}
{'fold': 9, 'epoch': 21, 'train_loss': 0.9668366797765096, 'val_loss': 1.0767636108398437, 'test_acc': 0.42}
{'fold': 9, 'epoch': 22, 'train_loss': 0.9620750610033671, 'val_loss': 1.0365416590372722, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 23, 'train_loss': 0.9701867349942526, 'val_loss': 1.151835962931315, 'test_acc': 0.46}
{'fold': 9, 'epoch': 24, 'train_loss': 0.9560024992624918, 'val_loss': 1.1035654830932617, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 25, 'train_loss': 0.9462012298901876, 'val_loss': 1.1201687622070313, 'test_acc': 0.46}
{'fold': 9, 'epoch': 26, 'train_loss': 0.9497162954012552, 'val_loss': 1.1254375076293945, 'test_acc': 0.48}
{'fold': 9, 'epoch': 27, 'train_loss': 0.9508521262804667, 'val_loss': 1.2280586751302083, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 28, 'train_loss': 0.9377632864316304, 'val_loss': 1.1854987589518229, 'test_acc': 0.48}
{'fold': 9, 'epoch': 29, 'train_loss': 0.9312501629193624, 'val_loss': 1.5668290201822916, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 30, 'train_loss': 0.9360103980700175, 'val_loss': 1.2615571339925131, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 31, 'train_loss': 0.9383333945274352, 'val_loss': 1.2649590301513671, 'test_acc': 0.5}
{'fold': 9, 'epoch': 32, 'train_loss': 0.9386769898732503, 'val_loss': 1.331493886311849, 'test_acc': 0.5}
{'fold': 9, 'epoch': 33, 'train_loss': 0.9330924121538798, 'val_loss': 1.2463033930460612, 'test_acc': 0.41333333333333333}
{'fold': 9, 'epoch': 34, 'train_loss': 0.9404970788955689, 'val_loss': 1.1598589452107748, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 35, 'train_loss': 0.9188223751386007, 'val_loss': 1.568450673421224, 'test_acc': 0.46}
{'fold': 9, 'epoch': 36, 'train_loss': 0.919503964583079, 'val_loss': 1.3304678980509441, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 37, 'train_loss': 0.9092156990369161, 'val_loss': 1.8046239471435548, 'test_acc': 0.44}
{'fold': 9, 'epoch': 38, 'train_loss': 0.9247358830769857, 'val_loss': 1.8058680343627929, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 39, 'train_loss': 0.912874146302541, 'val_loss': 1.4652731959025065, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 40, 'train_loss': 0.9023272037506104, 'val_loss': 1.6320185343424478, 'test_acc': 0.48}
{'fold': 9, 'epoch': 41, 'train_loss': 0.8974544795354208, 'val_loss': 1.5239571380615233, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 42, 'train_loss': 0.8873570156097412, 'val_loss': 1.4570714060465495, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 43, 'train_loss': 0.8954803705215454, 'val_loss': 1.8263280741373698, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 44, 'train_loss': 0.9006452854474386, 'val_loss': 1.827687733968099, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 45, 'train_loss': 0.8732591954867045, 'val_loss': 1.5234299468994141, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 46, 'train_loss': 0.9143921502431234, 'val_loss': 1.9588946278889974, 'test_acc': 0.5}
{'fold': 9, 'epoch': 47, 'train_loss': 0.8738955124219259, 'val_loss': 2.0964252853393557, 'test_acc': 0.48}
{'fold': 9, 'epoch': 48, 'train_loss': 0.8610899980862935, 'val_loss': 1.910186424255371, 'test_acc': 0.5}
{'fold': 9, 'epoch': 49, 'train_loss': 0.8700633772214253, 'val_loss': 1.783598607381185, 'test_acc': 0.48}
{'fold': 9, 'epoch': 50, 'train_loss': 0.8688996156056722, 'val_loss': 1.7495118459065755, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 51, 'train_loss': 0.8338783264160157, 'val_loss': 2.1164235432942706, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 52, 'train_loss': 0.8560032145182291, 'val_loss': 1.7510093307495118, 'test_acc': 0.46}
{'fold': 9, 'epoch': 53, 'train_loss': 0.8545541548728943, 'val_loss': 1.7265198644002278, 'test_acc': 0.5333333333333333}
{'fold': 9, 'epoch': 54, 'train_loss': 0.860148773988088, 'val_loss': 2.318409271240234, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 55, 'train_loss': 0.8577454129854838, 'val_loss': 2.0500150044759113, 'test_acc': 0.52}
{'fold': 9, 'epoch': 56, 'train_loss': 0.8757661946614583, 'val_loss': 1.7600948842366537, 'test_acc': 0.52}
{'fold': 9, 'epoch': 57, 'train_loss': 0.8914650503794352, 'val_loss': 2.244632085164388, 'test_acc': 0.48}
{'fold': 9, 'epoch': 58, 'train_loss': 0.8715372347831726, 'val_loss': 1.8949550374348958, 'test_acc': 0.5}
{'fold': 9, 'epoch': 59, 'train_loss': 0.8555989305178324, 'val_loss': 1.8232565307617188, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 60, 'train_loss': 0.8868675820032755, 'val_loss': 2.096801249186198, 'test_acc': 0.52}
{'fold': 9, 'epoch': 61, 'train_loss': 0.8795818400382995, 'val_loss': 1.5309187571207683, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 62, 'train_loss': 0.8511445339520772, 'val_loss': 2.5393621826171877, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 63, 'train_loss': 0.8468861444791158, 'val_loss': 1.6530265299479168, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 64, 'train_loss': 0.8474183710416158, 'val_loss': 2.3018861389160157, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 65, 'train_loss': 0.8449246080716452, 'val_loss': 2.4587039438883465, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 66, 'train_loss': 0.8578093759218852, 'val_loss': 2.2949927266438803, 'test_acc': 0.5}
{'fold': 9, 'epoch': 67, 'train_loss': 0.8284011514981587, 'val_loss': 2.729600321451823, 'test_acc': 0.52}
{'fold': 9, 'epoch': 68, 'train_loss': 0.850748914082845, 'val_loss': 2.4179576619466148, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 69, 'train_loss': 0.8322445901234945, 'val_loss': 2.193333206176758, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 70, 'train_loss': 0.8220611421267191, 'val_loss': 2.636219940185547, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 71, 'train_loss': 0.8364781419436137, 'val_loss': 2.6559766642252605, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 72, 'train_loss': 0.8296651450792948, 'val_loss': 2.6776776123046875, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 73, 'train_loss': 0.8215470584233602, 'val_loss': 3.199683507283529, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 74, 'train_loss': 0.8144527498881022, 'val_loss': 2.7596661376953127, 'test_acc': 0.52}
{'fold': 9, 'epoch': 75, 'train_loss': 0.8080580401420593, 'val_loss': 3.125502624511719, 'test_acc': 0.5}
{'fold': 9, 'epoch': 76, 'train_loss': 0.8000953014691671, 'val_loss': 2.523229420979818, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 77, 'train_loss': 0.840542307694753, 'val_loss': 1.9505933125813801, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 78, 'train_loss': 0.8199321031570435, 'val_loss': 3.3249085489908854, 'test_acc': 0.52}
{'fold': 9, 'epoch': 79, 'train_loss': 0.8189268247286479, 'val_loss': 3.6131189473470053, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 80, 'train_loss': 0.8530465563138326, 'val_loss': 3.410737635294596, 'test_acc': 0.52}
{'fold': 9, 'epoch': 81, 'train_loss': 0.8342690181732177, 'val_loss': 4.240398254394531, 'test_acc': 0.5}
{'fold': 9, 'epoch': 82, 'train_loss': 0.8412223553657532, 'val_loss': 4.899773661295573, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 83, 'train_loss': 0.845612211227417, 'val_loss': 2.9159857177734376, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 84, 'train_loss': 0.8399310859044393, 'val_loss': 3.5323455810546873, 'test_acc': 0.48}
{'fold': 9, 'epoch': 85, 'train_loss': 0.8764702224731445, 'val_loss': 3.085221862792969, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 86, 'train_loss': 1.014952974319458, 'val_loss': 2.1695161946614583, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 87, 'train_loss': 0.9056652522087097, 'val_loss': 2.8784202575683593, 'test_acc': 0.44666666666666666}
{'fold': 9, 'epoch': 88, 'train_loss': 0.8789480725924174, 'val_loss': 2.785245310465495, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 89, 'train_loss': 0.8826328102747599, 'val_loss': 3.162180430094401, 'test_acc': 0.48}
{'fold': 9, 'epoch': 90, 'train_loss': 0.866789722442627, 'val_loss': 5.341962305704753, 'test_acc': 0.4066666666666667}
{'fold': 9, 'epoch': 91, 'train_loss': 0.8645121645927429, 'val_loss': 3.765004170735677, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 92, 'train_loss': 0.837905965646108, 'val_loss': 4.422866617838542, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 93, 'train_loss': 0.8407653260231018, 'val_loss': 5.145642700195313, 'test_acc': 0.5}
{'fold': 9, 'epoch': 94, 'train_loss': 0.8273270567258199, 'val_loss': 5.627039184570313, 'test_acc': 0.44}
{'fold': 9, 'epoch': 95, 'train_loss': 0.8159135619799296, 'val_loss': 5.49200449625651, 'test_acc': 0.5}
{'fold': 9, 'epoch': 96, 'train_loss': 0.8221629691123963, 'val_loss': 6.865890299479167, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 97, 'train_loss': 0.8163302675882975, 'val_loss': 6.152119445800781, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 98, 'train_loss': 0.8179350701967875, 'val_loss': 4.804201965332031, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 99, 'train_loss': 0.8207628194491069, 'val_loss': 4.286118570963541, 'test_acc': 0.49333333333333335}
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 100, 'train_loss': 0.8192640439669291, 'val_loss': 5.3852978515625, 'test_acc': 0.46}
Val Loss: 0.9857, Test Accuracy: 0.489 ± 0.030, Duration: 8.574
Best result - 0.489 ± 0.030
--
MUTAG - GraphSAGE
{'fold': 9, 'epoch': 1, 'train_loss': 0.6939759191713835, 'val_loss': 0.6385753949483236, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6587979762177718, 'val_loss': 0.6537019411722819, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6544410429502788, 'val_loss': 0.6326297654045953, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6467333185045343, 'val_loss': 0.6324499977959527, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6398483640269229, 'val_loss': 0.6435544225904677, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 6, 'train_loss': 0.644497203199487, 'val_loss': 0.635944578382704, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6419212912258349, 'val_loss': 0.6235547065734863, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6222366094589233, 'val_loss': 0.6188425487942166, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6120812877228385, 'val_loss': 0.6144492361280653, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6396336304514032, 'val_loss': 0.5820973184373643, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5874501215784174, 'val_loss': 0.5602084795633951, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5684758393388045, 'val_loss': 0.5539433161417643, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 13, 'train_loss': 0.573791177649247, 'val_loss': 0.5391853120591905, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5285738534048984, 'val_loss': 0.578149848514133, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5771632649396595, 'val_loss': 0.5628075069851346, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5471411347389221, 'val_loss': 0.5467872619628906, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5454914350258676, 'val_loss': 0.5762442482842339, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5590213960722873, 'val_loss': 0.523101912604438, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5078555643558502, 'val_loss': 0.5897392166985406, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 20, 'train_loss': 0.5779106052298295, 'val_loss': 0.5184230274624295, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5420495742245725, 'val_loss': 0.5172150929768881, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 22, 'train_loss': 0.4994787589499825, 'val_loss': 0.5447488360934787, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 23, 'train_loss': 0.514628507589039, 'val_loss': 0.5486061308119032, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5245538291178251, 'val_loss': 0.5168363783094618, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5191691078637776, 'val_loss': 0.5394012133280436, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5447403286632738, 'val_loss': 0.5144210921393501, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5192381927841588, 'val_loss': 0.5235307481553819, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5209944279570329, 'val_loss': 0.5277566909790039, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5120821108943537, 'val_loss': 0.5054776403639052, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5023228745711478, 'val_loss': 0.5085391998291016, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5113506191655209, 'val_loss': 0.516765382554796, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5209083619870638, 'val_loss': 0.518515427907308, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5167340997018313, 'val_loss': 0.5015294286939833, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 34, 'train_loss': 0.49558866024017334, 'val_loss': 0.502107302347819, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 35, 'train_loss': 0.4737796077602788, 'val_loss': 0.5217467943827311, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5255065858364105, 'val_loss': 0.5128448274400499, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 37, 'train_loss': 0.49998024106025696, 'val_loss': 0.4982912805345323, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5046263290079016, 'val_loss': 0.48128059175279403, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 39, 'train_loss': 0.4851929984594646, 'val_loss': 0.4790787696838379, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5050843373725289, 'val_loss': 0.4717249340481228, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 41, 'train_loss': 0.481612912918392, 'val_loss': 0.5080875820583768, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5009524712437078, 'val_loss': 0.5432905091179742, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 43, 'train_loss': 0.5068540777030744, 'val_loss': 0.4990539020962185, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 44, 'train_loss': 0.5015609060463152, 'val_loss': 0.45618391036987305, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 45, 'train_loss': 0.4788984405366998, 'val_loss': 0.44261757532755536, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 46, 'train_loss': 0.4869423445902373, 'val_loss': 0.43852562374538845, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 47, 'train_loss': 0.533478131419734, 'val_loss': 0.4536370171440972, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 48, 'train_loss': 0.4814435573000657, 'val_loss': 0.4824512799580892, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 49, 'train_loss': 0.48885605994023773, 'val_loss': 0.4770592583550347, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 50, 'train_loss': 0.48986770761640447, 'val_loss': 0.47163735495673287, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 51, 'train_loss': 0.4804695703481373, 'val_loss': 0.46032306883070206, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 52, 'train_loss': 0.46815380767772075, 'val_loss': 0.44431834750705296, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 53, 'train_loss': 0.46331628059086044, 'val_loss': 0.4496055179172092, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 54, 'train_loss': 0.5118842846468875, 'val_loss': 0.4405425124698215, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 55, 'train_loss': 0.4881536819432911, 'val_loss': 0.45106739468044704, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 56, 'train_loss': 0.49186083203867864, 'val_loss': 0.4419950644175212, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 57, 'train_loss': 0.4555317853626452, 'val_loss': 0.4578527874416775, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5031574242993405, 'val_loss': 0.4322938654157851, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 59, 'train_loss': 0.46083237466059235, 'val_loss': 0.4517827563815647, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 60, 'train_loss': 0.5199615971038216, 'val_loss': 0.4401988983154297, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 61, 'train_loss': 0.49772847012469645, 'val_loss': 0.43605369991726345, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 62, 'train_loss': 0.47536203892607437, 'val_loss': 0.49549855126274955, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 63, 'train_loss': 0.5161969206835094, 'val_loss': 0.5009122954474555, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 64, 'train_loss': 0.5071616925691304, 'val_loss': 0.46227635277642143, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 65, 'train_loss': 0.4679747866956811, 'val_loss': 0.45988665686713326, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 66, 'train_loss': 0.47554734506105123, 'val_loss': 0.44655222362942165, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 67, 'train_loss': 0.4860233664512634, 'val_loss': 0.46937455071343315, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 68, 'train_loss': 0.4829328844421788, 'val_loss': 0.4883091184828017, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 69, 'train_loss': 0.47780782768600866, 'val_loss': 0.4833026991950141, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 70, 'train_loss': 0.4910073405817935, 'val_loss': 0.4858303599887424, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 71, 'train_loss': 0.4933493325584813, 'val_loss': 0.478943665822347, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 72, 'train_loss': 0.4751062204963283, 'val_loss': 0.4657657941182454, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 73, 'train_loss': 0.47789689114219264, 'val_loss': 0.46959516737196183, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 74, 'train_loss': 0.4703899684705232, 'val_loss': 0.4799811575147841, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 75, 'train_loss': 0.477308147831967, 'val_loss': 0.4699936972724067, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 76, 'train_loss': 0.4574057867652492, 'val_loss': 0.4600098927815755, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 77, 'train_loss': 0.4533606689227255, 'val_loss': 0.463915401034885, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 78, 'train_loss': 0.45402670690887853, 'val_loss': 0.49347660276624894, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 79, 'train_loss': 0.47033710856186717, 'val_loss': 0.498171329498291, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 80, 'train_loss': 0.4710577318542882, 'val_loss': 0.47081677118937176, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 81, 'train_loss': 0.469672187378532, 'val_loss': 0.4806433783637153, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 82, 'train_loss': 0.500166256176798, 'val_loss': 0.47400214936998153, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 83, 'train_loss': 0.5044074325185073, 'val_loss': 0.45674377017551, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 84, 'train_loss': 0.4780251023016478, 'val_loss': 0.45467620425754124, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 85, 'train_loss': 0.45946390064139114, 'val_loss': 0.4668859905666775, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 86, 'train_loss': 0.44624072627017375, 'val_loss': 0.4426382647620307, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 87, 'train_loss': 0.4503920141019319, 'val_loss': 0.44378142886691624, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 88, 'train_loss': 0.4405283504410794, 'val_loss': 0.4617202017042372, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 89, 'train_loss': 0.45364786135522944, 'val_loss': 0.4525039990743001, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 90, 'train_loss': 0.45196671391788285, 'val_loss': 0.4349206288655599, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 91, 'train_loss': 0.46434913026659114, 'val_loss': 0.44418711132473415, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 92, 'train_loss': 0.4731403808844717, 'val_loss': 0.4624960687425401, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 93, 'train_loss': 0.4491932674458152, 'val_loss': 0.4548318121168349, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 94, 'train_loss': 0.4435456724543321, 'val_loss': 0.46561527252197266, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 95, 'train_loss': 0.45695897623112325, 'val_loss': 0.47759697172376847, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 96, 'train_loss': 0.4672148133579053, 'val_loss': 0.4636346499125163, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 97, 'train_loss': 0.4468831357203032, 'val_loss': 0.42126239670647514, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 98, 'train_loss': 0.4674245464174371, 'val_loss': 0.4196876419915093, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 99, 'train_loss': 0.4379816949367523, 'val_loss': 0.4515671200222439, 'test_acc': 0.7777777777777778}
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
{'fold': 9, 'epoch': 100, 'train_loss': 0.4243046829574986, 'val_loss': 0.4552265273200141, 'test_acc': 0.7777777777777778}
Val Loss: 0.4711, Test Accuracy: 0.730 ± 0.111, Duration: 1.195
Best result - 0.730 ± 0.111
--
IMDB-BINARY - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6980670094490051, 'val_loss': 0.6879650115966797, 'test_acc': 0.5}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6719440245628356, 'val_loss': 0.5856303787231445, 'test_acc': 0.59}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5869760751724243, 'val_loss': 0.5412322235107422, 'test_acc': 0.67}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5367662930488586, 'val_loss': 0.5092512512207031, 'test_acc': 0.7}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5215312123298645, 'val_loss': 0.531200065612793, 'test_acc': 0.64}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5092752242088318, 'val_loss': 0.4455007553100586, 'test_acc': 0.65}
{'fold': 9, 'epoch': 7, 'train_loss': 0.4713607907295227, 'val_loss': 0.4856122970581055, 'test_acc': 0.69}
{'fold': 9, 'epoch': 8, 'train_loss': 0.47523337364196777, 'val_loss': 0.4597146987915039, 'test_acc': 0.67}
{'fold': 9, 'epoch': 9, 'train_loss': 0.4734645295143127, 'val_loss': 0.4570319747924805, 'test_acc': 0.69}
{'fold': 9, 'epoch': 10, 'train_loss': 0.45956214427948, 'val_loss': 0.4772214889526367, 'test_acc': 0.71}
{'fold': 9, 'epoch': 11, 'train_loss': 0.45280959606170657, 'val_loss': 0.4585506820678711, 'test_acc': 0.67}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4409193730354309, 'val_loss': 0.46826072692871096, 'test_acc': 0.7}
{'fold': 9, 'epoch': 13, 'train_loss': 0.4352430844306946, 'val_loss': 0.467894287109375, 'test_acc': 0.75}
{'fold': 9, 'epoch': 14, 'train_loss': 0.4451213788986206, 'val_loss': 0.4919536590576172, 'test_acc': 0.66}
{'fold': 9, 'epoch': 15, 'train_loss': 0.4180382192134857, 'val_loss': 0.48822521209716796, 'test_acc': 0.72}
{'fold': 9, 'epoch': 16, 'train_loss': 0.3958423709869385, 'val_loss': 0.5414452362060547, 'test_acc': 0.71}
{'fold': 9, 'epoch': 17, 'train_loss': 0.3700077033042908, 'val_loss': 0.4815457153320313, 'test_acc': 0.72}
{'fold': 9, 'epoch': 18, 'train_loss': 0.36886501908302305, 'val_loss': 0.536445083618164, 'test_acc': 0.7}
{'fold': 9, 'epoch': 19, 'train_loss': 0.3660880970954895, 'val_loss': 0.635565299987793, 'test_acc': 0.76}
{'fold': 9, 'epoch': 20, 'train_loss': 0.3430090916156769, 'val_loss': 0.6294975662231446, 'test_acc': 0.71}
{'fold': 9, 'epoch': 21, 'train_loss': 0.3457497239112854, 'val_loss': 0.7364824676513672, 'test_acc': 0.66}
{'fold': 9, 'epoch': 22, 'train_loss': 0.371664502620697, 'val_loss': 0.6111908340454102, 'test_acc': 0.71}
{'fold': 9, 'epoch': 23, 'train_loss': 0.364638032913208, 'val_loss': 0.6148844909667969, 'test_acc': 0.72}
{'fold': 9, 'epoch': 24, 'train_loss': 0.36611417651176453, 'val_loss': 0.7031719970703125, 'test_acc': 0.7}
{'fold': 9, 'epoch': 25, 'train_loss': 0.36919620394706726, 'val_loss': 0.728823471069336, 'test_acc': 0.66}
{'fold': 9, 'epoch': 26, 'train_loss': 0.33473862409591676, 'val_loss': 0.9541888427734375, 'test_acc': 0.73}
{'fold': 9, 'epoch': 27, 'train_loss': 0.3377985227108002, 'val_loss': 0.8299504089355468, 'test_acc': 0.63}
{'fold': 9, 'epoch': 28, 'train_loss': 0.32131914258003236, 'val_loss': 1.2465518188476563, 'test_acc': 0.68}
{'fold': 9, 'epoch': 29, 'train_loss': 0.31680222988128665, 'val_loss': 0.9273601531982422, 'test_acc': 0.67}
{'fold': 9, 'epoch': 30, 'train_loss': 0.2997120308876038, 'val_loss': 1.318466033935547, 'test_acc': 0.7}
{'fold': 9, 'epoch': 31, 'train_loss': 0.281511195898056, 'val_loss': 1.340132293701172, 'test_acc': 0.65}
{'fold': 9, 'epoch': 32, 'train_loss': 0.27802939295768736, 'val_loss': 1.96011962890625, 'test_acc': 0.72}
{'fold': 9, 'epoch': 33, 'train_loss': 0.30522944033145905, 'val_loss': 0.8189080047607422, 'test_acc': 0.67}
{'fold': 9, 'epoch': 34, 'train_loss': 0.2948976385593414, 'val_loss': 1.0311502075195313, 'test_acc': 0.7}
{'fold': 9, 'epoch': 35, 'train_loss': 0.3136075937747955, 'val_loss': 0.7244205474853516, 'test_acc': 0.68}
{'fold': 9, 'epoch': 36, 'train_loss': 0.30699204206466674, 'val_loss': 0.5852241134643554, 'test_acc': 0.74}
{'fold': 9, 'epoch': 37, 'train_loss': 0.316378675699234, 'val_loss': 0.5176084518432618, 'test_acc': 0.73}
{'fold': 9, 'epoch': 38, 'train_loss': 0.29449439644813535, 'val_loss': 0.66895751953125, 'test_acc': 0.7}
{'fold': 9, 'epoch': 39, 'train_loss': 0.2848596441745758, 'val_loss': 1.093972396850586, 'test_acc': 0.7}
{'fold': 9, 'epoch': 40, 'train_loss': 0.29531226634979246, 'val_loss': 0.7861882781982422, 'test_acc': 0.75}
{'fold': 9, 'epoch': 41, 'train_loss': 0.26614760875701904, 'val_loss': 1.276043930053711, 'test_acc': 0.68}
{'fold': 9, 'epoch': 42, 'train_loss': 0.2745431733131409, 'val_loss': 0.9696586608886719, 'test_acc': 0.68}
{'fold': 9, 'epoch': 43, 'train_loss': 0.2648898255825043, 'val_loss': 1.126459197998047, 'test_acc': 0.7}
{'fold': 9, 'epoch': 44, 'train_loss': 0.2558406913280487, 'val_loss': 1.9586686706542968, 'test_acc': 0.68}
{'fold': 9, 'epoch': 45, 'train_loss': 0.3717786371707916, 'val_loss': 0.8464145660400391, 'test_acc': 0.72}
{'fold': 9, 'epoch': 46, 'train_loss': 0.2980757188796997, 'val_loss': 1.2587220001220703, 'test_acc': 0.69}
{'fold': 9, 'epoch': 47, 'train_loss': 0.2789294159412384, 'val_loss': 1.0370872497558594, 'test_acc': 0.69}
{'fold': 9, 'epoch': 48, 'train_loss': 0.27306864857673646, 'val_loss': 1.50262939453125, 'test_acc': 0.67}
{'fold': 9, 'epoch': 49, 'train_loss': 0.25207213044166565, 'val_loss': 1.6373384094238281, 'test_acc': 0.66}
{'fold': 9, 'epoch': 50, 'train_loss': 0.23974734485149385, 'val_loss': 1.8494281005859374, 'test_acc': 0.67}
{'fold': 9, 'epoch': 51, 'train_loss': 0.24297248125076293, 'val_loss': 1.5198353576660155, 'test_acc': 0.68}
{'fold': 9, 'epoch': 52, 'train_loss': 0.23747780203819274, 'val_loss': 1.6624638366699218, 'test_acc': 0.68}
{'fold': 9, 'epoch': 53, 'train_loss': 0.2806555163860321, 'val_loss': 2.2661383056640627, 'test_acc': 0.63}
{'fold': 9, 'epoch': 54, 'train_loss': 0.26027821481227875, 'val_loss': 1.2386346435546876, 'test_acc': 0.7}
{'fold': 9, 'epoch': 55, 'train_loss': 0.26651123285293576, 'val_loss': 0.9145198822021484, 'test_acc': 0.66}
{'fold': 9, 'epoch': 56, 'train_loss': 0.24631492853164672, 'val_loss': 1.245640411376953, 'test_acc': 0.7}
{'fold': 9, 'epoch': 57, 'train_loss': 0.24568786084651947, 'val_loss': 1.4898541259765625, 'test_acc': 0.69}
{'fold': 9, 'epoch': 58, 'train_loss': 0.23541368067264556, 'val_loss': 2.2710812377929686, 'test_acc': 0.68}
{'fold': 9, 'epoch': 59, 'train_loss': 0.23015192568302154, 'val_loss': 2.5567033386230467, 'test_acc': 0.67}
{'fold': 9, 'epoch': 60, 'train_loss': 0.23241413474082948, 'val_loss': 2.7762796020507814, 'test_acc': 0.66}
{'fold': 9, 'epoch': 61, 'train_loss': 0.2261611032485962, 'val_loss': 1.9219525146484375, 'test_acc': 0.71}
{'fold': 9, 'epoch': 62, 'train_loss': 0.25504761457443237, 'val_loss': 1.8903477478027344, 'test_acc': 0.66}
{'fold': 9, 'epoch': 63, 'train_loss': 0.26522586643695834, 'val_loss': 1.1092269897460938, 'test_acc': 0.72}
{'fold': 9, 'epoch': 64, 'train_loss': 0.2588387578725815, 'val_loss': 2.2276068115234375, 'test_acc': 0.66}
{'fold': 9, 'epoch': 65, 'train_loss': 0.25774060368537904, 'val_loss': 1.2197706604003906, 'test_acc': 0.7}
{'fold': 9, 'epoch': 66, 'train_loss': 0.2322354182600975, 'val_loss': 1.7710604858398438, 'test_acc': 0.68}
{'fold': 9, 'epoch': 67, 'train_loss': 0.3841955953836441, 'val_loss': 0.7058375549316406, 'test_acc': 0.7}
{'fold': 9, 'epoch': 68, 'train_loss': 0.24515829265117645, 'val_loss': 1.2113724517822266, 'test_acc': 0.72}
{'fold': 9, 'epoch': 69, 'train_loss': 0.23780357003211974, 'val_loss': 1.3631597900390624, 'test_acc': 0.79}
{'fold': 9, 'epoch': 70, 'train_loss': 0.2267438268661499, 'val_loss': 1.6349813842773437, 'test_acc': 0.72}
{'fold': 9, 'epoch': 71, 'train_loss': 0.22514779031276702, 'val_loss': 2.105616455078125, 'test_acc': 0.7}
{'fold': 9, 'epoch': 72, 'train_loss': 0.21702662885189056, 'val_loss': 4.307905578613282, 'test_acc': 0.71}
{'fold': 9, 'epoch': 73, 'train_loss': 0.21122344791889192, 'val_loss': 4.0755398559570315, 'test_acc': 0.71}
{'fold': 9, 'epoch': 74, 'train_loss': 0.21289998054504394, 'val_loss': 3.057213134765625, 'test_acc': 0.68}
{'fold': 9, 'epoch': 75, 'train_loss': 0.303453586101532, 'val_loss': 2.4911067199707033, 'test_acc': 0.64}
{'fold': 9, 'epoch': 76, 'train_loss': 0.45024813175201417, 'val_loss': 0.5299161529541015, 'test_acc': 0.66}
{'fold': 9, 'epoch': 77, 'train_loss': 0.4144317269325256, 'val_loss': 0.4373143005371094, 'test_acc': 0.73}
{'fold': 9, 'epoch': 78, 'train_loss': 0.3419529461860657, 'val_loss': 0.48753742218017576, 'test_acc': 0.73}
{'fold': 9, 'epoch': 79, 'train_loss': 0.3094403624534607, 'val_loss': 0.7187924957275391, 'test_acc': 0.69}
{'fold': 9, 'epoch': 80, 'train_loss': 0.3081189453601837, 'val_loss': 0.5851280975341797, 'test_acc': 0.69}
{'fold': 9, 'epoch': 81, 'train_loss': 0.2892006850242615, 'val_loss': 0.7282078552246094, 'test_acc': 0.69}
{'fold': 9, 'epoch': 82, 'train_loss': 0.2605534505844116, 'val_loss': 0.6634309387207031, 'test_acc': 0.73}
{'fold': 9, 'epoch': 83, 'train_loss': 0.2589551877975464, 'val_loss': 0.7609091949462891, 'test_acc': 0.72}
{'fold': 9, 'epoch': 84, 'train_loss': 0.23984602928161622, 'val_loss': 0.9672856903076172, 'test_acc': 0.73}
{'fold': 9, 'epoch': 85, 'train_loss': 0.23504692137241365, 'val_loss': 1.74342529296875, 'test_acc': 0.68}
{'fold': 9, 'epoch': 86, 'train_loss': 0.28172505021095273, 'val_loss': 0.7648618316650391, 'test_acc': 0.71}
{'fold': 9, 'epoch': 87, 'train_loss': 0.23345040202140807, 'val_loss': 1.1244820404052733, 'test_acc': 0.67}
{'fold': 9, 'epoch': 88, 'train_loss': 0.23747357070446015, 'val_loss': 1.0103485870361328, 'test_acc': 0.7}
{'fold': 9, 'epoch': 89, 'train_loss': 0.23664264559745787, 'val_loss': 1.0955107879638672, 'test_acc': 0.69}
{'fold': 9, 'epoch': 90, 'train_loss': 0.23052749037742615, 'val_loss': 0.987139663696289, 'test_acc': 0.67}
{'fold': 9, 'epoch': 91, 'train_loss': 0.22501821756362916, 'val_loss': 1.5759684753417968, 'test_acc': 0.7}
{'fold': 9, 'epoch': 92, 'train_loss': 0.21503516912460327, 'val_loss': 1.7017631530761719, 'test_acc': 0.72}
{'fold': 9, 'epoch': 93, 'train_loss': 0.21957854866981508, 'val_loss': 2.0352432250976564, 'test_acc': 0.7}
{'fold': 9, 'epoch': 94, 'train_loss': 0.24189407408237457, 'val_loss': 1.5201014709472656, 'test_acc': 0.67}
{'fold': 9, 'epoch': 95, 'train_loss': 0.22175271987915038, 'val_loss': 2.089781494140625, 'test_acc': 0.71}
{'fold': 9, 'epoch': 96, 'train_loss': 0.2203504478931427, 'val_loss': 2.230615997314453, 'test_acc': 0.71}
{'fold': 9, 'epoch': 97, 'train_loss': 0.2181638675928116, 'val_loss': 2.2307339477539063, 'test_acc': 0.7}
{'fold': 9, 'epoch': 98, 'train_loss': 0.2267465317249298, 'val_loss': 2.6662606811523437, 'test_acc': 0.69}
{'fold': 9, 'epoch': 99, 'train_loss': 0.2214503687620163, 'val_loss': 2.65134521484375, 'test_acc': 0.68}
{'fold': 9, 'epoch': 100, 'train_loss': 0.23441802024841307, 'val_loss': 2.035451202392578, 'test_acc': 0.7}
Val Loss: 0.4858, Test Accuracy: 0.744 ± 0.057, Duration: 6.051
Best result - 0.744 ± 0.057
--
REDDIT-BINARY - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.7504402422904968, 'val_loss': 0.6733656883239746, 'test_acc': 0.605}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6074345445632935, 'val_loss': 0.606087064743042, 'test_acc': 0.69}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5645779061317444, 'val_loss': 0.5922159957885742, 'test_acc': 0.675}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5670677852630616, 'val_loss': 0.5610041236877441, 'test_acc': 0.69}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5523377585411072, 'val_loss': 0.5434323215484619, 'test_acc': 0.71}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5311859440803528, 'val_loss': 0.5803178215026855, 'test_acc': 0.67}
{'fold': 9, 'epoch': 7, 'train_loss': 0.531192557811737, 'val_loss': 0.497642879486084, 'test_acc': 0.715}
{'fold': 9, 'epoch': 8, 'train_loss': 0.49826584815979, 'val_loss': 0.5000201320648193, 'test_acc': 0.695}
{'fold': 9, 'epoch': 9, 'train_loss': 0.49067522168159483, 'val_loss': 0.46325149536132815, 'test_acc': 0.735}
{'fold': 9, 'epoch': 10, 'train_loss': 0.47141263842582704, 'val_loss': 0.4391698551177978, 'test_acc': 0.775}
{'fold': 9, 'epoch': 11, 'train_loss': 0.45022070050239565, 'val_loss': 0.42803852081298827, 'test_acc': 0.755}
{'fold': 9, 'epoch': 12, 'train_loss': 0.44787943601608277, 'val_loss': 0.4393336296081543, 'test_acc': 0.74}
{'fold': 9, 'epoch': 13, 'train_loss': 0.44190197944641113, 'val_loss': 0.4038750648498535, 'test_acc': 0.805}
{'fold': 9, 'epoch': 14, 'train_loss': 0.4343970060348511, 'val_loss': 0.39785343170166015, 'test_acc': 0.77}
{'fold': 9, 'epoch': 15, 'train_loss': 0.45543841242790223, 'val_loss': 0.4199335765838623, 'test_acc': 0.775}
{'fold': 9, 'epoch': 16, 'train_loss': 0.46839978694915774, 'val_loss': 0.42077275276184084, 'test_acc': 0.785}
{'fold': 9, 'epoch': 17, 'train_loss': 0.43381426215171814, 'val_loss': 0.40555047035217284, 'test_acc': 0.755}
{'fold': 9, 'epoch': 18, 'train_loss': 0.4243189263343811, 'val_loss': 0.41450947761535645, 'test_acc': 0.765}
{'fold': 9, 'epoch': 19, 'train_loss': 0.4232874429225922, 'val_loss': 0.4001039600372314, 'test_acc': 0.77}
{'fold': 9, 'epoch': 20, 'train_loss': 0.4206939911842346, 'val_loss': 0.3620421314239502, 'test_acc': 0.815}
{'fold': 9, 'epoch': 21, 'train_loss': 0.40039388060569764, 'val_loss': 0.3627540874481201, 'test_acc': 0.8}
{'fold': 9, 'epoch': 22, 'train_loss': 0.3934582793712616, 'val_loss': 0.3434541082382202, 'test_acc': 0.825}
{'fold': 9, 'epoch': 23, 'train_loss': 0.38584838271141053, 'val_loss': 0.3279048681259155, 'test_acc': 0.83}
{'fold': 9, 'epoch': 24, 'train_loss': 0.3955282425880432, 'val_loss': 0.3675751495361328, 'test_acc': 0.8}
{'fold': 9, 'epoch': 25, 'train_loss': 0.3778014850616455, 'val_loss': 0.36209954261779786, 'test_acc': 0.82}
{'fold': 9, 'epoch': 26, 'train_loss': 0.3719314527511597, 'val_loss': 0.30946179389953615, 'test_acc': 0.85}
{'fold': 9, 'epoch': 27, 'train_loss': 0.35756002068519593, 'val_loss': 0.2788758659362793, 'test_acc': 0.86}
{'fold': 9, 'epoch': 28, 'train_loss': 0.32702172219753267, 'val_loss': 0.3273157548904419, 'test_acc': 0.84}
{'fold': 9, 'epoch': 29, 'train_loss': 0.357856433391571, 'val_loss': 0.30237626552581787, 'test_acc': 0.86}
{'fold': 9, 'epoch': 30, 'train_loss': 0.3494388782978058, 'val_loss': 0.33560357093811033, 'test_acc': 0.795}
{'fold': 9, 'epoch': 31, 'train_loss': 0.3441996741294861, 'val_loss': 0.32058960914611817, 'test_acc': 0.815}
{'fold': 9, 'epoch': 32, 'train_loss': 0.3297473293542862, 'val_loss': 0.292159218788147, 'test_acc': 0.875}
{'fold': 9, 'epoch': 33, 'train_loss': 0.34619584918022156, 'val_loss': 0.2749831867218018, 'test_acc': 0.86}
{'fold': 9, 'epoch': 34, 'train_loss': 0.32684234380722044, 'val_loss': 0.26469768047332765, 'test_acc': 0.85}
{'fold': 9, 'epoch': 35, 'train_loss': 0.32232080817222597, 'val_loss': 0.26541852951049805, 'test_acc': 0.875}
{'fold': 9, 'epoch': 36, 'train_loss': 0.3284573256969452, 'val_loss': 0.2861713695526123, 'test_acc': 0.82}
{'fold': 9, 'epoch': 37, 'train_loss': 0.3195826232433319, 'val_loss': 0.24171956062316893, 'test_acc': 0.865}
{'fold': 9, 'epoch': 38, 'train_loss': 0.31212645649909976, 'val_loss': 0.2550652837753296, 'test_acc': 0.85}
{'fold': 9, 'epoch': 39, 'train_loss': 0.3021102678775787, 'val_loss': 0.25177736282348634, 'test_acc': 0.86}
{'fold': 9, 'epoch': 40, 'train_loss': 0.3496818149089813, 'val_loss': 0.2500423002243042, 'test_acc': 0.87}
{'fold': 9, 'epoch': 41, 'train_loss': 0.29348193526268007, 'val_loss': 0.2527971792221069, 'test_acc': 0.885}
{'fold': 9, 'epoch': 42, 'train_loss': 0.3093905067443848, 'val_loss': 0.2398237991333008, 'test_acc': 0.865}
{'fold': 9, 'epoch': 43, 'train_loss': 0.3262139308452606, 'val_loss': 0.29411629676818846, 'test_acc': 0.85}
{'fold': 9, 'epoch': 44, 'train_loss': 0.3253385090827942, 'val_loss': 0.2734430980682373, 'test_acc': 0.845}
{'fold': 9, 'epoch': 45, 'train_loss': 0.2914024698734283, 'val_loss': 0.2621244812011719, 'test_acc': 0.86}
{'fold': 9, 'epoch': 46, 'train_loss': 0.3134303146600723, 'val_loss': 0.288744535446167, 'test_acc': 0.885}
{'fold': 9, 'epoch': 47, 'train_loss': 0.3001295053958893, 'val_loss': 0.2544519281387329, 'test_acc': 0.86}
{'fold': 9, 'epoch': 48, 'train_loss': 0.2945737731456757, 'val_loss': 0.23113426208496093, 'test_acc': 0.895}
{'fold': 9, 'epoch': 49, 'train_loss': 0.29963159799575806, 'val_loss': 0.24784661769866945, 'test_acc': 0.88}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3137847077846527, 'val_loss': 0.3072769832611084, 'test_acc': 0.81}
{'fold': 9, 'epoch': 51, 'train_loss': 0.30276562452316286, 'val_loss': 0.23006767749786378, 'test_acc': 0.88}
{'fold': 9, 'epoch': 52, 'train_loss': 0.29282415568828585, 'val_loss': 0.2355861759185791, 'test_acc': 0.885}
{'fold': 9, 'epoch': 53, 'train_loss': 0.26996287345886233, 'val_loss': 0.21255064010620117, 'test_acc': 0.895}
{'fold': 9, 'epoch': 54, 'train_loss': 0.2807403540611267, 'val_loss': 0.23441548824310302, 'test_acc': 0.865}
{'fold': 9, 'epoch': 55, 'train_loss': 0.285694015622139, 'val_loss': 0.26547476291656497, 'test_acc': 0.865}
{'fold': 9, 'epoch': 56, 'train_loss': 0.28649364948272704, 'val_loss': 0.2705925178527832, 'test_acc': 0.845}
{'fold': 9, 'epoch': 57, 'train_loss': 0.28937169790267947, 'val_loss': 0.2439003801345825, 'test_acc': 0.86}
{'fold': 9, 'epoch': 58, 'train_loss': 0.26605847358703616, 'val_loss': 0.20718714714050293, 'test_acc': 0.88}
{'fold': 9, 'epoch': 59, 'train_loss': 0.2916072797775269, 'val_loss': 0.2586341190338135, 'test_acc': 0.89}
{'fold': 9, 'epoch': 60, 'train_loss': 0.2739742684364319, 'val_loss': 0.23478986263275148, 'test_acc': 0.915}
{'fold': 9, 'epoch': 61, 'train_loss': 0.302019492983818, 'val_loss': 0.2664640998840332, 'test_acc': 0.855}
{'fold': 9, 'epoch': 62, 'train_loss': 0.2766775524616241, 'val_loss': 0.22417253017425537, 'test_acc': 0.86}
{'fold': 9, 'epoch': 63, 'train_loss': 0.26923149049282075, 'val_loss': 0.2280276298522949, 'test_acc': 0.88}
{'fold': 9, 'epoch': 64, 'train_loss': 0.2808863580226898, 'val_loss': 0.2504529619216919, 'test_acc': 0.855}
{'fold': 9, 'epoch': 65, 'train_loss': 0.27361618280410765, 'val_loss': 0.21462148666381836, 'test_acc': 0.885}
{'fold': 9, 'epoch': 66, 'train_loss': 0.2703397786617279, 'val_loss': 0.23468373775482176, 'test_acc': 0.88}
{'fold': 9, 'epoch': 67, 'train_loss': 0.2759393900632858, 'val_loss': 0.24858238697052001, 'test_acc': 0.865}
{'fold': 9, 'epoch': 68, 'train_loss': 0.27352911472320557, 'val_loss': 0.2253621530532837, 'test_acc': 0.895}
{'fold': 9, 'epoch': 69, 'train_loss': 0.26847763180732725, 'val_loss': 0.2172512435913086, 'test_acc': 0.885}
{'fold': 9, 'epoch': 70, 'train_loss': 0.27756715297698975, 'val_loss': 0.19459867000579834, 'test_acc': 0.885}
{'fold': 9, 'epoch': 71, 'train_loss': 0.26465164303779604, 'val_loss': 0.20940300464630127, 'test_acc': 0.895}
{'fold': 9, 'epoch': 72, 'train_loss': 0.24490881204605103, 'val_loss': 0.21150129318237304, 'test_acc': 0.89}
{'fold': 9, 'epoch': 73, 'train_loss': 0.22872598648071288, 'val_loss': 0.2111279249191284, 'test_acc': 0.875}
{'fold': 9, 'epoch': 74, 'train_loss': 0.2748384928703308, 'val_loss': 0.23313100814819335, 'test_acc': 0.87}
{'fold': 9, 'epoch': 75, 'train_loss': 0.30589528679847716, 'val_loss': 0.2582970142364502, 'test_acc': 0.88}
{'fold': 9, 'epoch': 76, 'train_loss': 0.31983366250991824, 'val_loss': 0.270467963218689, 'test_acc': 0.815}
{'fold': 9, 'epoch': 77, 'train_loss': 0.29917280316352846, 'val_loss': 0.23390985012054444, 'test_acc': 0.875}
{'fold': 9, 'epoch': 78, 'train_loss': 0.28521051466465, 'val_loss': 0.22816903114318848, 'test_acc': 0.88}
{'fold': 9, 'epoch': 79, 'train_loss': 0.29271690726280214, 'val_loss': 0.2589880466461182, 'test_acc': 0.845}
{'fold': 9, 'epoch': 80, 'train_loss': 0.2845488691329956, 'val_loss': 0.28550569534301756, 'test_acc': 0.825}
{'fold': 9, 'epoch': 81, 'train_loss': 0.26436550974845885, 'val_loss': 0.2165580129623413, 'test_acc': 0.885}
{'fold': 9, 'epoch': 82, 'train_loss': 0.2608563780784607, 'val_loss': 0.2311127281188965, 'test_acc': 0.885}
{'fold': 9, 'epoch': 83, 'train_loss': 0.24338121354579925, 'val_loss': 0.20702566623687743, 'test_acc': 0.875}
{'fold': 9, 'epoch': 84, 'train_loss': 0.23687132835388183, 'val_loss': 0.2091609287261963, 'test_acc': 0.855}
{'fold': 9, 'epoch': 85, 'train_loss': 0.2637703740596771, 'val_loss': 0.21103848457336427, 'test_acc': 0.89}
{'fold': 9, 'epoch': 86, 'train_loss': 0.24811562538146972, 'val_loss': 0.262447304725647, 'test_acc': 0.835}
{'fold': 9, 'epoch': 87, 'train_loss': 0.26327769696712494, 'val_loss': 0.21049225807189942, 'test_acc': 0.925}
{'fold': 9, 'epoch': 88, 'train_loss': 0.263188544511795, 'val_loss': 0.3073772430419922, 'test_acc': 0.825}
{'fold': 9, 'epoch': 89, 'train_loss': 0.2949286353588104, 'val_loss': 0.2663923358917236, 'test_acc': 0.83}
{'fold': 9, 'epoch': 90, 'train_loss': 0.277867728471756, 'val_loss': 0.23080384254455566, 'test_acc': 0.865}
{'fold': 9, 'epoch': 91, 'train_loss': 0.271759330034256, 'val_loss': 0.21227004051208495, 'test_acc': 0.895}
{'fold': 9, 'epoch': 92, 'train_loss': 0.24812958836555482, 'val_loss': 0.21715874671936036, 'test_acc': 0.87}
{'fold': 9, 'epoch': 93, 'train_loss': 0.2518248474597931, 'val_loss': 0.18223932266235351, 'test_acc': 0.905}
{'fold': 9, 'epoch': 94, 'train_loss': 0.2538269400596619, 'val_loss': 0.2864888858795166, 'test_acc': 0.84}
{'fold': 9, 'epoch': 95, 'train_loss': 0.2755074614286423, 'val_loss': 0.20136455059051514, 'test_acc': 0.88}
{'fold': 9, 'epoch': 96, 'train_loss': 0.26911855936050416, 'val_loss': 0.19897500514984132, 'test_acc': 0.89}
{'fold': 9, 'epoch': 97, 'train_loss': 0.24822677910327912, 'val_loss': 0.21375957489013672, 'test_acc': 0.91}
{'fold': 9, 'epoch': 98, 'train_loss': 0.2377205914258957, 'val_loss': 0.1987648582458496, 'test_acc': 0.91}
{'fold': 9, 'epoch': 99, 'train_loss': 0.25014898002147673, 'val_loss': 0.21568921566009522, 'test_acc': 0.895}
{'fold': 9, 'epoch': 100, 'train_loss': 0.22476784586906434, 'val_loss': 0.22072450637817384, 'test_acc': 0.87}
Val Loss: 0.2491, Test Accuracy: 0.898 ± 0.022, Duration: 19.654
Best result - 0.898 ± 0.022
--
DD - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6873136900239072, 'val_loss': 0.6798826690412995, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6805754839363745, 'val_loss': 0.6769544813368056, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6783898048481699, 'val_loss': 0.6769568940513154, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6793730612528526, 'val_loss': 0.6768179347372463, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6801825660770222, 'val_loss': 0.6749656872871594, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6678556284662021, 'val_loss': 0.6528671134231437, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 7, 'train_loss': 0.674791217860529, 'val_loss': 0.690513415214343, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6619841769590216, 'val_loss': 0.6727788550222021, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6654843051554793, 'val_loss': 0.6687879643888555, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6504615848347292, 'val_loss': 0.6709522345127203, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6373199497239065, 'val_loss': 0.6542215591821915, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 12, 'train_loss': 0.6064466995708013, 'val_loss': 0.6418590708675548, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 13, 'train_loss': 0.6007192811723483, 'val_loss': 0.6460945585854033, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5806904899871955, 'val_loss': 0.6467912462022569, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5933142415547775, 'val_loss': 0.7067573090903779, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 16, 'train_loss': 0.7121997536238978, 'val_loss': 0.6685502141968817, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 17, 'train_loss': 0.6054713726043701, 'val_loss': 0.6503603682558761, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5981955528259277, 'val_loss': 0.6356526562291333, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5791764158313557, 'val_loss': 0.6267543694911859, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 20, 'train_loss': 0.5646280999911033, 'val_loss': 0.6117787809453459, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5453130895808592, 'val_loss': 0.6151653191982172, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5546210044521397, 'val_loss': 0.6196399264865451, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5542935890666509, 'val_loss': 0.6165744748889891, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5256660161382061, 'val_loss': 0.6200013772035257, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 25, 'train_loss': 0.49950434696876395, 'val_loss': 0.6971614218165731, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 26, 'train_loss': 0.502035505185693, 'val_loss': 0.6298685970469418, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 27, 'train_loss': 0.48053956941022713, 'val_loss': 0.6457691029605702, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 28, 'train_loss': 0.529020910545931, 'val_loss': 0.6266311906341814, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 29, 'train_loss': 0.48119414004228883, 'val_loss': 0.6229503664196047, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 30, 'train_loss': 0.4590614518876803, 'val_loss': 0.649724846212273, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5474974159467019, 'val_loss': 0.64055418356871, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 32, 'train_loss': 0.4986787221189273, 'val_loss': 0.6819549299712874, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 33, 'train_loss': 0.44980552388449846, 'val_loss': 0.7388141338641827, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 34, 'train_loss': 0.43506656713404895, 'val_loss': 0.7103746202256944, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 35, 'train_loss': 0.4010599982940545, 'val_loss': 0.7951995327941372, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 36, 'train_loss': 0.39157140709586064, 'val_loss': 0.7163031814444778, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 37, 'train_loss': 0.38030091837301094, 'val_loss': 1.179205087515024, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 38, 'train_loss': 0.48445587036973337, 'val_loss': 0.6351490509815705, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 39, 'train_loss': 0.38585069068407607, 'val_loss': 0.6850781563000802, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 40, 'train_loss': 0.3657826864618366, 'val_loss': 0.6840470142853565, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 41, 'train_loss': 0.34762877276388265, 'val_loss': 1.0774369851136818, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 42, 'train_loss': 0.43551835922871607, 'val_loss': 0.6788684812366453, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 43, 'train_loss': 0.4016415204031993, 'val_loss': 0.6715278951530783, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 44, 'train_loss': 0.3602902954917843, 'val_loss': 0.782468746869992, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 45, 'train_loss': 0.32924957447132824, 'val_loss': 0.7854202140090812, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 46, 'train_loss': 0.3470118414547484, 'val_loss': 1.0954617231320112, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 47, 'train_loss': 0.3936661229295246, 'val_loss': 0.7204273582523705, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 48, 'train_loss': 0.3434788266480979, 'val_loss': 0.7058427598741319, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 49, 'train_loss': 0.33523216540530576, 'val_loss': 0.8098604251176883, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3032727579949266, 'val_loss': 1.2632075904780984, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 51, 'train_loss': 0.30274271409390335, 'val_loss': 0.8377823136810564, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 52, 'train_loss': 0.27037217960519305, 'val_loss': 0.9829284146300747, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 53, 'train_loss': 0.24952595744092584, 'val_loss': 1.0102351914104233, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 54, 'train_loss': 0.24675431089886166, 'val_loss': 1.156264867538061, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 55, 'train_loss': 0.24208020987146991, 'val_loss': 1.0198179717756743, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 56, 'train_loss': 0.26677073108947885, 'val_loss': 0.8631495288294605, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 57, 'train_loss': 0.6243334776264126, 'val_loss': 0.7479097415239383, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 58, 'train_loss': 0.6249463800656594, 'val_loss': 0.9071713309002738, 'test_acc': 0.5811965811965812}
{'fold': 9, 'epoch': 59, 'train_loss': 0.4514309849779485, 'val_loss': 0.7176294571314102, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 60, 'train_loss': 0.38699669807644216, 'val_loss': 0.6855292687049279, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 61, 'train_loss': 0.3525645151986914, 'val_loss': 0.6881009615384616, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 62, 'train_loss': 0.3369439714035745, 'val_loss': 0.6723779531625601, 'test_acc': 0.6923076923076923}
{'fold': 9, 'epoch': 63, 'train_loss': 0.31581297617847637, 'val_loss': 0.7114795782627203, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 64, 'train_loss': 0.30039127852957126, 'val_loss': 0.7370400061974158, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 65, 'train_loss': 0.3033150154150138, 'val_loss': 1.1937768398187099, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 66, 'train_loss': 0.276477010573371, 'val_loss': 1.3339072985526843, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 67, 'train_loss': 0.25434431484190084, 'val_loss': 1.1885446401742787, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 68, 'train_loss': 0.22092961027460584, 'val_loss': 1.109485593616453, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 69, 'train_loss': 0.20935033337544587, 'val_loss': 1.2152218288845487, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 70, 'train_loss': 0.20571924543986886, 'val_loss': 1.3736977862496662, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 71, 'train_loss': 0.2111541995052564, 'val_loss': 0.7904817630083133, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 72, 'train_loss': 0.27592896505937736, 'val_loss': 2.2149634728064904, 'test_acc': 0.6239316239316239}
{'fold': 9, 'epoch': 73, 'train_loss': 0.31371045163122274, 'val_loss': 0.7325035160423344, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 74, 'train_loss': 0.35087579589779094, 'val_loss': 0.7803168663611779, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 75, 'train_loss': 0.2754674503358744, 'val_loss': 0.832496838691907, 'test_acc': 0.6837606837606838}
{'fold': 9, 'epoch': 76, 'train_loss': 0.23704160901449495, 'val_loss': 1.1302564572065303, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 77, 'train_loss': 0.23150635775873216, 'val_loss': 1.5138317662426548, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 78, 'train_loss': 0.20529756050998882, 'val_loss': 1.4060053377069979, 'test_acc': 0.6239316239316239}
{'fold': 9, 'epoch': 79, 'train_loss': 0.18437604959738457, 'val_loss': 1.972614516559829, 'test_acc': 0.6239316239316239}
{'fold': 9, 'epoch': 80, 'train_loss': 0.17399918540554532, 'val_loss': 1.9515603872445912, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 81, 'train_loss': 0.17978319197388018, 'val_loss': 2.8588961087740383, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 82, 'train_loss': 0.16203997347314478, 'val_loss': 1.6715082673944979, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 83, 'train_loss': 0.1507047998198008, 'val_loss': 1.6822784945496128, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 84, 'train_loss': 0.15664473378052146, 'val_loss': 2.44215093107305, 'test_acc': 0.6068376068376068}
{'fold': 9, 'epoch': 85, 'train_loss': 0.15310799671431718, 'val_loss': 2.2959730360243054, 'test_acc': 0.6324786324786325}
{'fold': 9, 'epoch': 86, 'train_loss': 0.1386847655146809, 'val_loss': 2.3115529117421207, 'test_acc': 0.6239316239316239}
{'fold': 9, 'epoch': 87, 'train_loss': 0.14107085461333646, 'val_loss': 2.007101075262086, 'test_acc': 0.6239316239316239}
{'fold': 9, 'epoch': 88, 'train_loss': 0.1356144125683833, 'val_loss': 1.7683851453993056, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 89, 'train_loss': 0.15640823492559336, 'val_loss': 1.7187702146350827, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 90, 'train_loss': 0.17173262799190261, 'val_loss': 1.6699701292901976, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 91, 'train_loss': 0.11895717869875795, 'val_loss': 3.3354518270900106, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 92, 'train_loss': 0.21470289487959976, 'val_loss': 1.0771533933460202, 'test_acc': 0.6581196581196581}
{'fold': 9, 'epoch': 93, 'train_loss': 0.17149463838945, 'val_loss': 1.4597054505959535, 'test_acc': 0.6495726495726496}
{'fold': 9, 'epoch': 94, 'train_loss': 0.1434270180130409, 'val_loss': 2.6352630354400373, 'test_acc': 0.6153846153846154}
{'fold': 9, 'epoch': 95, 'train_loss': 0.11673701769214566, 'val_loss': 3.300606491219284, 'test_acc': 0.6410256410256411}
{'fold': 9, 'epoch': 96, 'train_loss': 0.1876947581768036, 'val_loss': 1.0477555103791065, 'test_acc': 0.5982905982905983}
{'fold': 9, 'epoch': 97, 'train_loss': 0.20255212271112508, 'val_loss': 1.0740370139097557, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 98, 'train_loss': 0.1329791121563669, 'val_loss': 1.369455321222289, 'test_acc': 0.6752136752136753}
{'fold': 9, 'epoch': 99, 'train_loss': 0.09314593609611867, 'val_loss': 1.887759999332265, 'test_acc': 0.6239316239316239}
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
{'fold': 9, 'epoch': 100, 'train_loss': 0.0902900988772764, 'val_loss': 1.4162923698751335, 'test_acc': 0.6410256410256411}
Val Loss: 0.6003, Test Accuracy: 0.649 ± 0.053, Duration: 12.263
Best result - 0.649 ± 0.053
--
NCI1 - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6954133894901786, 'val_loss': 0.67646359817245, 'test_acc': 0.5912408759124088}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6904808500387373, 'val_loss': 0.6720178655174237, 'test_acc': 0.5912408759124088}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6866137729073963, 'val_loss': 0.6922783909632921, 'test_acc': 0.51338199513382}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6855508425519994, 'val_loss': 0.6694378632408569, 'test_acc': 0.5912408759124088}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6798220582832095, 'val_loss': 0.6772806766259409, 'test_acc': 0.559610705596107}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6764689495383678, 'val_loss': 0.6458848735131777, 'test_acc': 0.6180048661800487}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6765091462727011, 'val_loss': 0.6637081879478881, 'test_acc': 0.583941605839416}
{'fold': 9, 'epoch': 8, 'train_loss': 0.67640091264915, 'val_loss': 0.6625100504742921, 'test_acc': 0.583941605839416}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6563732465978377, 'val_loss': 0.6477102386400357, 'test_acc': 0.6374695863746959}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6320414730232128, 'val_loss': 0.61465484034406, 'test_acc': 0.6788321167883211}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6049278852713369, 'val_loss': 0.6435404055890086, 'test_acc': 0.6228710462287105}
{'fold': 9, 'epoch': 12, 'train_loss': 0.6056093801257094, 'val_loss': 0.5944618401446191, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 13, 'train_loss': 0.6130340702632338, 'val_loss': 0.6197078175788379, 'test_acc': 0.6253041362530414}
{'fold': 9, 'epoch': 14, 'train_loss': 0.606866832632218, 'val_loss': 0.5878273019535408, 'test_acc': 0.681265206812652}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5832832019114437, 'val_loss': 0.5684160965782592, 'test_acc': 0.6788321167883211}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5784997477438618, 'val_loss': 0.5816760886904677, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5848401342575278, 'val_loss': 0.5750247486606421, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5755221695795546, 'val_loss': 0.5747593974835101, 'test_acc': 0.6690997566909975}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5805195120419319, 'val_loss': 0.592313745596113, 'test_acc': 0.6472019464720195}
{'fold': 9, 'epoch': 20, 'train_loss': 0.5843391164665964, 'val_loss': 0.5694071962305519, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5702108571129124, 'val_loss': 0.5444249967588995, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5577117200315433, 'val_loss': 0.5417868435527866, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5598873926050182, 'val_loss': 0.5356741879688273, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5497588908295272, 'val_loss': 0.5535279294870196, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5500744674037553, 'val_loss': 0.5481929129347604, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5429860082275966, 'val_loss': 0.5416176974628384, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5436678483828431, 'val_loss': 0.5279388938216978, 'test_acc': 0.7055961070559611}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5335194422090721, 'val_loss': 0.527337457141737, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5368626352644315, 'val_loss': 0.5334751031694621, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5411466666091678, 'val_loss': 0.5342602694991732, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 31, 'train_loss': 0.531429005945396, 'val_loss': 0.5311732234165907, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 32, 'train_loss': 0.521890571227619, 'val_loss': 0.5270201272337977, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5255661938892374, 'val_loss': 0.5188772289712353, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5223293643073154, 'val_loss': 0.5254832961553495, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 35, 'train_loss': 0.5205774273170461, 'val_loss': 0.538204963479889, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5167178279582021, 'val_loss': 0.5657692558864027, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5230162304683323, 'val_loss': 0.5401347547842058, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5145725857312372, 'val_loss': 0.5226085226611209, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 39, 'train_loss': 0.5098282777479965, 'val_loss': 0.5206002887438104, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5105437075134611, 'val_loss': 0.5183622077143686, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 41, 'train_loss': 0.48934281517699396, 'val_loss': 0.5141951289490192, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5063511214407111, 'val_loss': 0.5100122113007408, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 43, 'train_loss': 0.49430706582220224, 'val_loss': 0.4871881512829857, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 44, 'train_loss': 0.48880526626487136, 'val_loss': 0.4914579066626927, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 45, 'train_loss': 0.49425263604978575, 'val_loss': 0.5086588592714927, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 46, 'train_loss': 0.4868147157839615, 'val_loss': 0.4952202075299265, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 47, 'train_loss': 0.49042239495147466, 'val_loss': 0.49252674121346207, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 48, 'train_loss': 0.4784324549120418, 'val_loss': 0.5256271455119707, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 49, 'train_loss': 0.49430559347145747, 'val_loss': 0.5172431184717629, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 50, 'train_loss': 0.49244861649190713, 'val_loss': 0.4868943360600158, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 51, 'train_loss': 0.4839796381130126, 'val_loss': 0.5112952025847424, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 52, 'train_loss': 0.46967163660230427, 'val_loss': 0.48621154469585187, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 53, 'train_loss': 0.4704117670546483, 'val_loss': 0.4751440359148086, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 54, 'train_loss': 0.48335497810022676, 'val_loss': 0.5014734268188477, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 55, 'train_loss': 0.4718046952628161, 'val_loss': 0.5150143189441839, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 56, 'train_loss': 0.4627094908352316, 'val_loss': 0.4970802529884951, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 57, 'train_loss': 0.4589246196758428, 'val_loss': 0.49884427434916623, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 58, 'train_loss': 0.45486558861396026, 'val_loss': 0.5064568856046727, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 59, 'train_loss': 0.47916288155418824, 'val_loss': 0.5187020243809461, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 60, 'train_loss': 0.46330202524969466, 'val_loss': 0.489465177494244, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 61, 'train_loss': 0.44997326199445703, 'val_loss': 0.5098829014167878, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 62, 'train_loss': 0.45114599389461413, 'val_loss': 0.5171199297382884, 'test_acc': 0.7566909975669099}
{'fold': 9, 'epoch': 63, 'train_loss': 0.43841501947156997, 'val_loss': 0.5157603382194129, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 64, 'train_loss': 0.4416707506870121, 'val_loss': 0.5090270958967743, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 65, 'train_loss': 0.46856578894485235, 'val_loss': 0.4929096426116869, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 66, 'train_loss': 0.43500766991988876, 'val_loss': 0.4978718073118632, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 67, 'train_loss': 0.4491920041921945, 'val_loss': 0.554203648346764, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 68, 'train_loss': 0.4584597778436331, 'val_loss': 0.5083466782767118, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 69, 'train_loss': 0.4386075863437931, 'val_loss': 0.5626152576901327, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 70, 'train_loss': 0.4313161726270569, 'val_loss': 0.5392372521170734, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 71, 'train_loss': 0.4497211032395235, 'val_loss': 0.5146706945414671, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 72, 'train_loss': 0.43408595493240076, 'val_loss': 0.5032481288677875, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 73, 'train_loss': 0.4382625512253049, 'val_loss': 0.5442888672914529, 'test_acc': 0.7591240875912408}
{'fold': 9, 'epoch': 74, 'train_loss': 0.4378102154192263, 'val_loss': 0.5063532785197534, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 75, 'train_loss': 0.4455832260368514, 'val_loss': 0.5586379647544991, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 76, 'train_loss': 0.4488842245871133, 'val_loss': 0.5227855510665262, 'test_acc': 0.7518248175182481}
{'fold': 9, 'epoch': 77, 'train_loss': 0.45050953687542544, 'val_loss': 0.5076031000364726, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 78, 'train_loss': 0.4269465429214375, 'val_loss': 0.511731400687039, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 79, 'train_loss': 0.42162753195658215, 'val_loss': 0.5620913958027415, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 80, 'train_loss': 0.42424288877895566, 'val_loss': 0.5305209565916781, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 81, 'train_loss': 0.4158324896564159, 'val_loss': 0.5250302521271717, 'test_acc': 0.7664233576642335}
{'fold': 9, 'epoch': 82, 'train_loss': 0.40303970340394624, 'val_loss': 0.5122040750916567, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 83, 'train_loss': 0.395652129267254, 'val_loss': 0.5676914966889541, 'test_acc': 0.7615571776155717}
{'fold': 9, 'epoch': 84, 'train_loss': 0.3983231998273056, 'val_loss': 0.5256100953930486, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 85, 'train_loss': 0.39863381000040804, 'val_loss': 0.5251309981891419, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 86, 'train_loss': 0.4102243116882306, 'val_loss': 0.5707784917232764, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 87, 'train_loss': 0.40030977390978456, 'val_loss': 0.5136904983334878, 'test_acc': 0.7615571776155717}
{'fold': 9, 'epoch': 88, 'train_loss': 0.3999120963605941, 'val_loss': 0.5466293812958284, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 89, 'train_loss': 0.4017293455391905, 'val_loss': 0.5318778471935114, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 90, 'train_loss': 0.40029353454455263, 'val_loss': 0.5093309026564995, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 91, 'train_loss': 0.37980558431351563, 'val_loss': 0.5223117303964285, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 92, 'train_loss': 0.37961594633522405, 'val_loss': 0.5476163646020449, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 93, 'train_loss': 0.3771410961510781, 'val_loss': 0.6721679102765382, 'test_acc': 0.7566909975669099}
{'fold': 9, 'epoch': 94, 'train_loss': 0.374064545416774, 'val_loss': 0.5779972262046053, 'test_acc': 0.7566909975669099}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3799120140626773, 'val_loss': 0.549085593861675, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 96, 'train_loss': 0.395395023109269, 'val_loss': 0.5228246818783799, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 97, 'train_loss': 0.4005131172582761, 'val_loss': 0.5299185987226575, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 98, 'train_loss': 0.38279819930846964, 'val_loss': 0.5626684731810633, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 99, 'train_loss': 0.3653377831127232, 'val_loss': 0.5541679400887223, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 100, 'train_loss': 0.3634906764303101, 'val_loss': 0.5819035226121146, 'test_acc': 0.7566909975669099}
Val Loss: 0.5300, Test Accuracy: 0.750 ± 0.041, Duration: 16.178
Best result - 0.750 ± 0.041
--
PROTEINS - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.7050685863837383, 'val_loss': 0.6768193975225225, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6836680341783731, 'val_loss': 0.677702826422614, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6771384036099469, 'val_loss': 0.6751273902686866, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6757076106355112, 'val_loss': 0.6742249222489091, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6749855742845203, 'val_loss': 0.6675539446306659, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6661673166802703, 'val_loss': 0.6557051512572143, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6487198279361532, 'val_loss': 0.6595982731999578, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6707080783934973, 'val_loss': 0.6856297673405828, 'test_acc': 0.5315315315315315}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6619340754652397, 'val_loss': 0.6613841013865428, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6595748656927937, 'val_loss': 0.6549896377700943, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6484413082752164, 'val_loss': 0.6239081030493384, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 12, 'train_loss': 0.6167497971376319, 'val_loss': 0.5812341501046946, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 13, 'train_loss': 0.6147963856205796, 'val_loss': 0.6213399526235219, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 14, 'train_loss': 0.6107433441645904, 'val_loss': 0.5716966508745073, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5977789201720395, 'val_loss': 0.5510649809966216, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5954944189683891, 'val_loss': 0.5621233416033221, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5874411844377699, 'val_loss': 0.5827735007346213, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5895849545930505, 'val_loss': 0.5461651570088154, 'test_acc': 0.8018018018018018}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5813934061797513, 'val_loss': 0.5904388427734375, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 20, 'train_loss': 0.594281321222132, 'val_loss': 0.5383388759853603, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5925423979893009, 'val_loss': 0.5972106521194046, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 22, 'train_loss': 0.6061915707106542, 'val_loss': 0.5505040486653646, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5931680430600672, 'val_loss': 0.5348370869954427, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5810177808525051, 'val_loss': 0.5989447241430884, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5954695640322067, 'val_loss': 0.5385057603990709, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5802339891391972, 'val_loss': 0.5757476875373909, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5640922482433811, 'val_loss': 0.5359684024845157, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5706525400832847, 'val_loss': 0.513987601340354, 'test_acc': 0.8018018018018018}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5713578573648643, 'val_loss': 0.5541289389670432, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5754284245264115, 'val_loss': 0.5425087524963929, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 31, 'train_loss': 0.563288582294477, 'val_loss': 0.5236419815200943, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5751459964464275, 'val_loss': 0.5277497918756159, 'test_acc': 0.8018018018018018}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5651738461019215, 'val_loss': 0.5421232618727125, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5683341865186338, 'val_loss': 0.5671693269196931, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 35, 'train_loss': 0.5733028977406948, 'val_loss': 0.5095692196407834, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5788119260041936, 'val_loss': 0.5716471285433382, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5929984358692276, 'val_loss': 0.514209712947811, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5862640503012104, 'val_loss': 0.5829485644091357, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 39, 'train_loss': 0.5726173075227491, 'val_loss': 0.5318569492649388, 'test_acc': 0.8018018018018018}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5716414517157541, 'val_loss': 0.5582535889771607, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 41, 'train_loss': 0.5786176500497041, 'val_loss': 0.5414306709358284, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5754836744197156, 'val_loss': 0.5267920622954497, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 43, 'train_loss': 0.5830661023639803, 'val_loss': 0.5276455922169728, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 44, 'train_loss': 0.5746008826693568, 'val_loss': 0.5402577030766118, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 45, 'train_loss': 0.5687333720701712, 'val_loss': 0.5159122020274669, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 46, 'train_loss': 0.5707515889546687, 'val_loss': 0.5631820403777801, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 47, 'train_loss': 0.5915256486463494, 'val_loss': 0.528838080328864, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 48, 'train_loss': 0.5899216459121233, 'val_loss': 0.5399188136195278, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 49, 'train_loss': 0.583141885957065, 'val_loss': 0.5342288661647487, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 50, 'train_loss': 0.5722531327762453, 'val_loss': 0.5327330237036353, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 51, 'train_loss': 0.5757665360549216, 'val_loss': 0.5464363098144531, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 52, 'train_loss': 0.5753589705318447, 'val_loss': 0.5397395572146854, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 53, 'train_loss': 0.573923264422133, 'val_loss': 0.5424143473307291, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 54, 'train_loss': 0.5851935248583655, 'val_loss': 0.5160833135381475, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 55, 'train_loss': 0.5726040823826217, 'val_loss': 0.5216061016460797, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 56, 'train_loss': 0.5817376840796936, 'val_loss': 0.5138994852701823, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 57, 'train_loss': 0.5871377969965522, 'val_loss': 0.5200726277119404, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5800597653645859, 'val_loss': 0.5382020280167863, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 59, 'train_loss': 0.5681248209893904, 'val_loss': 0.5464374095469982, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 60, 'train_loss': 0.5721189784414974, 'val_loss': 0.5306493054639112, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 61, 'train_loss': 0.5594391854925188, 'val_loss': 0.5571136130942954, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 62, 'train_loss': 0.5693722380665951, 'val_loss': 0.5575551900777731, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 63, 'train_loss': 0.5814119050264626, 'val_loss': 0.5417305198875634, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 64, 'train_loss': 0.5620212409097605, 'val_loss': 0.5643958014410895, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 65, 'train_loss': 0.5812759261607588, 'val_loss': 0.5297814446526605, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 66, 'train_loss': 0.5580263456912956, 'val_loss': 0.5540592777836431, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 67, 'train_loss': 0.5767099877399227, 'val_loss': 0.5229578104105082, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 68, 'train_loss': 0.5575002571682871, 'val_loss': 0.528028814642279, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 69, 'train_loss': 0.5827384730247, 'val_loss': 0.5270356530541772, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 70, 'train_loss': 0.5806357809054998, 'val_loss': 0.557401536821245, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 71, 'train_loss': 0.5615397630851009, 'val_loss': 0.564053166020024, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 72, 'train_loss': 0.5547315504748948, 'val_loss': 0.5477981223716392, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 73, 'train_loss': 0.5591755968954427, 'val_loss': 0.5291795129174585, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 74, 'train_loss': 0.5677273813321534, 'val_loss': 0.5444765864191828, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 75, 'train_loss': 0.5849446735264342, 'val_loss': 0.5290726326607369, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 76, 'train_loss': 0.5729077487816046, 'val_loss': 0.5656288421905793, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 77, 'train_loss': 0.5719893837617303, 'val_loss': 0.5209534791138795, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 78, 'train_loss': 0.5812700535980807, 'val_loss': 0.5141343125351915, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 79, 'train_loss': 0.5549324047485185, 'val_loss': 0.528555071031725, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 80, 'train_loss': 0.5500978993379441, 'val_loss': 0.5395821923608178, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 81, 'train_loss': 0.577983718194009, 'val_loss': 0.5618126327927048, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 82, 'train_loss': 0.5928686034398448, 'val_loss': 0.5600881834287901, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 83, 'train_loss': 0.579385198995588, 'val_loss': 0.5573349686356278, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 84, 'train_loss': 0.5739040032915529, 'val_loss': 0.5709757074579462, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 85, 'train_loss': 0.567053147839376, 'val_loss': 0.5353871938344594, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 86, 'train_loss': 0.5576284771950291, 'val_loss': 0.5543085390383059, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 87, 'train_loss': 0.559706041440953, 'val_loss': 0.5406084833918391, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 88, 'train_loss': 0.5629805965990865, 'val_loss': 0.5396666655669341, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 89, 'train_loss': 0.5608935732766568, 'val_loss': 0.5401340175319362, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 90, 'train_loss': 0.5414805098214134, 'val_loss': 0.5385010865357545, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 91, 'train_loss': 0.5463674026306229, 'val_loss': 0.5453025199271537, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 92, 'train_loss': 0.5522995828645666, 'val_loss': 0.5344606347986169, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 93, 'train_loss': 0.5500407672490335, 'val_loss': 0.5541459160882074, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 94, 'train_loss': 0.539680779916804, 'val_loss': 0.5496345038886543, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 95, 'train_loss': 0.5491207553414517, 'val_loss': 0.5422988410468574, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 96, 'train_loss': 0.5471413427865599, 'val_loss': 0.5350059646743912, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 97, 'train_loss': 0.5437454120344853, 'val_loss': 0.545952015094929, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 98, 'train_loss': 0.5430173041041852, 'val_loss': 0.5320930480957031, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 99, 'train_loss': 0.541331423921082, 'val_loss': 0.5325607437271256, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 100, 'train_loss': 0.5491753108841267, 'val_loss': 0.5640738891051696, 'test_acc': 0.7567567567567568}
Val Loss: 0.5463, Test Accuracy: 0.737 ± 0.041, Duration: 4.328
Best result - 0.737 ± 0.041
--
COLLAB - GraphSAGE
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.9969640469551087, 'val_loss': 0.6519150695800782, 'test_acc': 0.71}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6190487976074219, 'val_loss': 0.5456768112182617, 'test_acc': 0.75}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5823426585197449, 'val_loss': 0.5178388977050781, 'test_acc': 0.746}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5455869145393372, 'val_loss': 0.4915833282470703, 'test_acc': 0.752}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5296809000968933, 'val_loss': 0.5121134109497071, 'test_acc': 0.744}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5339096021652222, 'val_loss': 0.5305363540649414, 'test_acc': 0.714}
{'fold': 9, 'epoch': 7, 'train_loss': 0.511820552110672, 'val_loss': 0.4864895172119141, 'test_acc': 0.766}
{'fold': 9, 'epoch': 8, 'train_loss': 0.47479275727272036, 'val_loss': 0.48835091400146485, 'test_acc': 0.776}
{'fold': 9, 'epoch': 9, 'train_loss': 0.46179296135902403, 'val_loss': 0.4886124000549316, 'test_acc': 0.792}
{'fold': 9, 'epoch': 10, 'train_loss': 0.4385549535751343, 'val_loss': 0.5193292999267578, 'test_acc': 0.792}
{'fold': 9, 'epoch': 11, 'train_loss': 0.41405358743667603, 'val_loss': 0.4846673049926758, 'test_acc': 0.782}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4057142190933228, 'val_loss': 0.5250226364135743, 'test_acc': 0.784}
{'fold': 9, 'epoch': 13, 'train_loss': 0.475656099319458, 'val_loss': 0.4780239562988281, 'test_acc': 0.774}
{'fold': 9, 'epoch': 14, 'train_loss': 0.41249941754341124, 'val_loss': 0.5256702117919921, 'test_acc': 0.8}
{'fold': 9, 'epoch': 15, 'train_loss': 0.3838759977817535, 'val_loss': 0.4932713012695312, 'test_acc': 0.802}
{'fold': 9, 'epoch': 16, 'train_loss': 0.38180332016944885, 'val_loss': 0.49972359848022463, 'test_acc': 0.8}
{'fold': 9, 'epoch': 17, 'train_loss': 0.4027620577812195, 'val_loss': 0.5258642272949219, 'test_acc': 0.796}
{'fold': 9, 'epoch': 18, 'train_loss': 0.35266098618507385, 'val_loss': 0.5916038703918457, 'test_acc': 0.8}
{'fold': 9, 'epoch': 19, 'train_loss': 0.34890161037445067, 'val_loss': 0.6065178909301758, 'test_acc': 0.772}
{'fold': 9, 'epoch': 20, 'train_loss': 0.3342905125617981, 'val_loss': 0.6832482719421387, 'test_acc': 0.796}
{'fold': 9, 'epoch': 21, 'train_loss': 0.31126018953323364, 'val_loss': 0.5163443527221679, 'test_acc': 0.8}
{'fold': 9, 'epoch': 22, 'train_loss': 0.3246297950744629, 'val_loss': 0.4710050506591797, 'test_acc': 0.814}
{'fold': 9, 'epoch': 23, 'train_loss': 0.29499099934101103, 'val_loss': 0.5747069854736329, 'test_acc': 0.806}
{'fold': 9, 'epoch': 24, 'train_loss': 0.2726518337726593, 'val_loss': 0.587240364074707, 'test_acc': 0.778}
{'fold': 9, 'epoch': 25, 'train_loss': 0.2628046314716339, 'val_loss': 0.716328498840332, 'test_acc': 0.82}
{'fold': 9, 'epoch': 26, 'train_loss': 0.2621015553474426, 'val_loss': 0.6383441162109375, 'test_acc': 0.816}
{'fold': 9, 'epoch': 27, 'train_loss': 0.2401008882522583, 'val_loss': 0.6407299194335937, 'test_acc': 0.796}
{'fold': 9, 'epoch': 28, 'train_loss': 0.2542739579677582, 'val_loss': 0.623097297668457, 'test_acc': 0.8}
{'fold': 9, 'epoch': 29, 'train_loss': 0.22249812841415406, 'val_loss': 0.8755559310913086, 'test_acc': 0.814}
{'fold': 9, 'epoch': 30, 'train_loss': 0.31288026309013367, 'val_loss': 0.563925422668457, 'test_acc': 0.814}
{'fold': 9, 'epoch': 31, 'train_loss': 0.23439725446701049, 'val_loss': 0.6896232070922852, 'test_acc': 0.806}
{'fold': 9, 'epoch': 32, 'train_loss': 0.20921818494796754, 'val_loss': 0.6953647003173828, 'test_acc': 0.79}
{'fold': 9, 'epoch': 33, 'train_loss': 0.20558311593532563, 'val_loss': 0.7655429153442382, 'test_acc': 0.788}
{'fold': 9, 'epoch': 34, 'train_loss': 0.20627859449386596, 'val_loss': 0.733254524230957, 'test_acc': 0.798}
{'fold': 9, 'epoch': 35, 'train_loss': 0.2308465166091919, 'val_loss': 0.9077266464233399, 'test_acc': 0.8}
{'fold': 9, 'epoch': 36, 'train_loss': 0.18959926319122314, 'val_loss': 0.9036500320434571, 'test_acc': 0.796}
{'fold': 9, 'epoch': 37, 'train_loss': 0.18462172436714172, 'val_loss': 1.064573699951172, 'test_acc': 0.79}
{'fold': 9, 'epoch': 38, 'train_loss': 0.2002727017402649, 'val_loss': 0.7833406219482422, 'test_acc': 0.794}
{'fold': 9, 'epoch': 39, 'train_loss': 0.22632440042495727, 'val_loss': 0.7618164978027344, 'test_acc': 0.782}
{'fold': 9, 'epoch': 40, 'train_loss': 0.1868117489218712, 'val_loss': 0.8929461288452148, 'test_acc': 0.788}
{'fold': 9, 'epoch': 41, 'train_loss': 0.20939219379425048, 'val_loss': 1.0065680084228517, 'test_acc': 0.77}
{'fold': 9, 'epoch': 42, 'train_loss': 0.22645086598396302, 'val_loss': 1.0696869201660155, 'test_acc': 0.8}
{'fold': 9, 'epoch': 43, 'train_loss': 0.2604014093875885, 'val_loss': 0.8319177322387695, 'test_acc': 0.788}
{'fold': 9, 'epoch': 44, 'train_loss': 0.19592681908607482, 'val_loss': 1.0748680572509766, 'test_acc': 0.816}
{'fold': 9, 'epoch': 45, 'train_loss': 0.19606567585468293, 'val_loss': 0.9898966293334961, 'test_acc': 0.796}
{'fold': 9, 'epoch': 46, 'train_loss': 0.1701669716835022, 'val_loss': 1.0160235900878907, 'test_acc': 0.788}
{'fold': 9, 'epoch': 47, 'train_loss': 0.17808448100090027, 'val_loss': 0.8570667724609375, 'test_acc': 0.804}
{'fold': 9, 'epoch': 48, 'train_loss': 0.1781891657114029, 'val_loss': 1.1245561752319335, 'test_acc': 0.822}
{'fold': 9, 'epoch': 49, 'train_loss': 0.15242660439014435, 'val_loss': 1.2649522247314453, 'test_acc': 0.806}
{'fold': 9, 'epoch': 50, 'train_loss': 0.13240712755918502, 'val_loss': 1.3244791107177734, 'test_acc': 0.81}
{'fold': 9, 'epoch': 51, 'train_loss': 0.13072781443595885, 'val_loss': 1.484668960571289, 'test_acc': 0.802}
{'fold': 9, 'epoch': 52, 'train_loss': 0.21606412506103514, 'val_loss': 0.9611506805419922, 'test_acc': 0.786}
{'fold': 9, 'epoch': 53, 'train_loss': 0.17118855792284013, 'val_loss': 1.0613367919921874, 'test_acc': 0.788}
{'fold': 9, 'epoch': 54, 'train_loss': 0.16835978507995605, 'val_loss': 1.0951785774230958, 'test_acc': 0.81}
{'fold': 9, 'epoch': 55, 'train_loss': 0.17239881330728532, 'val_loss': 0.7816205291748047, 'test_acc': 0.78}
{'fold': 9, 'epoch': 56, 'train_loss': 0.1371739612221718, 'val_loss': 1.1068337173461915, 'test_acc': 0.806}
{'fold': 9, 'epoch': 57, 'train_loss': 0.13137875366210938, 'val_loss': 1.4256761322021485, 'test_acc': 0.814}
{'fold': 9, 'epoch': 58, 'train_loss': 0.1198288516998291, 'val_loss': 1.6208570251464844, 'test_acc': 0.802}
{'fold': 9, 'epoch': 59, 'train_loss': 0.13742214697599411, 'val_loss': 1.09285302734375, 'test_acc': 0.812}
{'fold': 9, 'epoch': 60, 'train_loss': 0.11872768986225128, 'val_loss': 1.6996879119873047, 'test_acc': 0.786}
{'fold': 9, 'epoch': 61, 'train_loss': 0.14287313085794448, 'val_loss': 1.2450927200317383, 'test_acc': 0.806}
{'fold': 9, 'epoch': 62, 'train_loss': 0.21789320772886275, 'val_loss': 1.3572753448486328, 'test_acc': 0.802}
{'fold': 9, 'epoch': 63, 'train_loss': 0.20980256474018097, 'val_loss': 1.1155227279663087, 'test_acc': 0.786}
{'fold': 9, 'epoch': 64, 'train_loss': 0.2366124284863472, 'val_loss': 4.777159400939942, 'test_acc': 0.774}
{'fold': 9, 'epoch': 65, 'train_loss': 0.34202842473983763, 'val_loss': 0.98500341796875, 'test_acc': 0.778}
{'fold': 9, 'epoch': 66, 'train_loss': 0.16829556560516357, 'val_loss': 0.8281833343505859, 'test_acc': 0.8}
{'fold': 9, 'epoch': 67, 'train_loss': 0.12693449956178665, 'val_loss': 1.5870080795288086, 'test_acc': 0.792}
{'fold': 9, 'epoch': 68, 'train_loss': 0.12177201294898987, 'val_loss': 1.5363901977539063, 'test_acc': 0.804}
{'fold': 9, 'epoch': 69, 'train_loss': 0.11854473090171815, 'val_loss': 1.649472785949707, 'test_acc': 0.79}
{'fold': 9, 'epoch': 70, 'train_loss': 0.19840553510189057, 'val_loss': 1.130129753112793, 'test_acc': 0.79}
{'fold': 9, 'epoch': 71, 'train_loss': 0.15939480972290038, 'val_loss': 1.259441192626953, 'test_acc': 0.782}
{'fold': 9, 'epoch': 72, 'train_loss': 0.20639586436748505, 'val_loss': 1.4583912353515625, 'test_acc': 0.796}
{'fold': 9, 'epoch': 73, 'train_loss': 0.1334678153991699, 'val_loss': 1.4165946044921875, 'test_acc': 0.79}
{'fold': 9, 'epoch': 74, 'train_loss': 0.13629017424583434, 'val_loss': 1.76321630859375, 'test_acc': 0.784}
{'fold': 9, 'epoch': 75, 'train_loss': 0.4383170211315155, 'val_loss': 1.3831385803222656, 'test_acc': 0.774}
{'fold': 9, 'epoch': 76, 'train_loss': 0.4879999830722809, 'val_loss': 1.3815901336669922, 'test_acc': 0.788}
{'fold': 9, 'epoch': 77, 'train_loss': 0.16214262938499452, 'val_loss': 1.5277423248291016, 'test_acc': 0.786}
{'fold': 9, 'epoch': 78, 'train_loss': 0.2901778590083122, 'val_loss': 1.9364361267089845, 'test_acc': 0.766}
{'fold': 9, 'epoch': 79, 'train_loss': 0.17401352620124816, 'val_loss': 1.8343473205566405, 'test_acc': 0.796}
{'fold': 9, 'epoch': 80, 'train_loss': 0.3528798808455467, 'val_loss': 1.0285277786254883, 'test_acc': 0.78}
{'fold': 9, 'epoch': 81, 'train_loss': 0.2179257892370224, 'val_loss': 1.6881478576660156, 'test_acc': 0.788}
{'fold': 9, 'epoch': 82, 'train_loss': 0.22950380039215088, 'val_loss': 1.1216390380859376, 'test_acc': 0.772}
{'fold': 9, 'epoch': 83, 'train_loss': 0.1895010766983032, 'val_loss': 1.1529555282592774, 'test_acc': 0.792}
{'fold': 9, 'epoch': 84, 'train_loss': 0.15434024487435818, 'val_loss': 1.507819091796875, 'test_acc': 0.776}
{'fold': 9, 'epoch': 85, 'train_loss': 0.10972134518623353, 'val_loss': 1.4847805633544922, 'test_acc': 0.79}
{'fold': 9, 'epoch': 86, 'train_loss': 0.11009432071447373, 'val_loss': 1.638459243774414, 'test_acc': 0.778}
{'fold': 9, 'epoch': 87, 'train_loss': 0.10225587689876556, 'val_loss': 2.625446716308594, 'test_acc': 0.792}
{'fold': 9, 'epoch': 88, 'train_loss': 0.11834994864463806, 'val_loss': 3.178754898071289, 'test_acc': 0.794}
{'fold': 9, 'epoch': 89, 'train_loss': 0.09587399125099182, 'val_loss': 3.5705137786865233, 'test_acc': 0.786}
{'fold': 9, 'epoch': 90, 'train_loss': 0.08662588763236999, 'val_loss': 3.955457305908203, 'test_acc': 0.77}
{'fold': 9, 'epoch': 91, 'train_loss': 0.09617965573072433, 'val_loss': 3.6256822814941407, 'test_acc': 0.778}
{'fold': 9, 'epoch': 92, 'train_loss': 0.09606595933437348, 'val_loss': 3.1070622253417968, 'test_acc': 0.78}
{'fold': 9, 'epoch': 93, 'train_loss': 0.4697521587610245, 'val_loss': 2.4294558486938476, 'test_acc': 0.808}
{'fold': 9, 'epoch': 94, 'train_loss': 0.219600310087204, 'val_loss': 1.243764175415039, 'test_acc': 0.784}
{'fold': 9, 'epoch': 95, 'train_loss': 0.10595268440246582, 'val_loss': 1.7031956787109375, 'test_acc': 0.778}
{'fold': 9, 'epoch': 96, 'train_loss': 0.18277751040458678, 'val_loss': 1.427504898071289, 'test_acc': 0.782}
{'fold': 9, 'epoch': 97, 'train_loss': 0.11137822765111924, 'val_loss': 1.5747022399902344, 'test_acc': 0.782}
{'fold': 9, 'epoch': 98, 'train_loss': 0.17060190683603288, 'val_loss': 1.7171258850097657, 'test_acc': 0.806}
{'fold': 9, 'epoch': 99, 'train_loss': 0.11950853300094605, 'val_loss': 1.673177719116211, 'test_acc': 0.796}
{'fold': 9, 'epoch': 100, 'train_loss': 0.1442327711582184, 'val_loss': 1.3894009552001954, 'test_acc': 0.79}
Val Loss: 0.4880, Test Accuracy: 0.785 ± 0.023, Duration: 113.553
Best result - 0.785 ± 0.023
--
IMDB-MULTI - GraphSAGE: 0.489 ± 0.030
MUTAG - GraphSAGE: 0.730 ± 0.111
IMDB-BINARY - GraphSAGE: 0.744 ± 0.057
REDDIT-BINARY - GraphSAGE: 0.898 ± 0.022
DD - GraphSAGE: 0.649 ± 0.053
NCI1 - GraphSAGE: 0.750 ± 0.041
PROTEINS - GraphSAGE: 0.737 ± 0.041
COLLAB - GraphSAGE: 0.785 ± 0.023

Process finished with exit code 0
