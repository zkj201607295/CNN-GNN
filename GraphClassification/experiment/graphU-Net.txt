D:\Program\Anaconda\envs\pyg\python.exe F:/Project/BernNet/GraphClassification/main.py
--
IMDB-MULTI - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 1.1008879959583282, 'val_loss': 1.0982599385579428, 'test_acc': 0.3333333333333333}
{'fold': 9, 'epoch': 2, 'train_loss': 1.0995171070098877, 'val_loss': 1.0964113362630208, 'test_acc': 0.3333333333333333}
{'fold': 9, 'epoch': 3, 'train_loss': 1.094835215806961, 'val_loss': 1.08891840616862, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 4, 'train_loss': 1.0822888612747192, 'val_loss': 1.0604645284016927, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 5, 'train_loss': 1.0502539426088333, 'val_loss': 1.022211456298828, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 6, 'train_loss': 1.0363860905170441, 'val_loss': 1.0129591496785482, 'test_acc': 0.5333333333333333}
{'fold': 9, 'epoch': 7, 'train_loss': 1.026515543460846, 'val_loss': 1.0056593068440756, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 8, 'train_loss': 1.0203957825899124, 'val_loss': 1.0020269393920898, 'test_acc': 0.5}
{'fold': 9, 'epoch': 9, 'train_loss': 1.0143847733736038, 'val_loss': 1.0058269246419271, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 10, 'train_loss': 1.0116954386234283, 'val_loss': 1.0052889124552409, 'test_acc': 0.52}
{'fold': 9, 'epoch': 11, 'train_loss': 1.008037480711937, 'val_loss': 1.0008206049601236, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 12, 'train_loss': 1.0014070004224778, 'val_loss': 1.0081990051269532, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 13, 'train_loss': 0.9942224979400635, 'val_loss': 1.0023689651489258, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 14, 'train_loss': 0.9945101708173751, 'val_loss': 1.007795270284017, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 15, 'train_loss': 0.9849342048168183, 'val_loss': 1.0021955108642577, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 16, 'train_loss': 0.9787014484405517, 'val_loss': 1.012733866373698, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 17, 'train_loss': 0.9806047797203064, 'val_loss': 1.0118484497070312, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 18, 'train_loss': 0.981971475481987, 'val_loss': 1.0064433670043946, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 19, 'train_loss': 0.9780417799949646, 'val_loss': 1.0038464864095051, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 20, 'train_loss': 0.9678212195634842, 'val_loss': 1.0060445658365886, 'test_acc': 0.5}
{'fold': 9, 'epoch': 21, 'train_loss': 0.964765340089798, 'val_loss': 1.0015569305419922, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 22, 'train_loss': 0.9622042924165726, 'val_loss': 1.008305320739746, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 23, 'train_loss': 0.9652664691209794, 'val_loss': 1.0052317428588866, 'test_acc': 0.5}
{'fold': 9, 'epoch': 24, 'train_loss': 0.9653189718723297, 'val_loss': 1.0029880142211913, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 25, 'train_loss': 0.9532213747501374, 'val_loss': 1.0004512532552083, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 26, 'train_loss': 0.9564718782901764, 'val_loss': 1.0051799774169923, 'test_acc': 0.46}
{'fold': 9, 'epoch': 27, 'train_loss': 0.958990415930748, 'val_loss': 1.003666508992513, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 28, 'train_loss': 0.9517978101968765, 'val_loss': 1.0034463755289713, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 29, 'train_loss': 0.9476831018924713, 'val_loss': 1.0027853012084962, 'test_acc': 0.48}
{'fold': 9, 'epoch': 30, 'train_loss': 0.9574458956718445, 'val_loss': 1.0114342244466146, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 31, 'train_loss': 0.9484579473733902, 'val_loss': 1.0100633748372396, 'test_acc': 0.46}
{'fold': 9, 'epoch': 32, 'train_loss': 0.943138661980629, 'val_loss': 1.0081285730997722, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 33, 'train_loss': 0.9442722290754318, 'val_loss': 1.0092354838053386, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 34, 'train_loss': 0.9491949886083603, 'val_loss': 1.0158789952596028, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 35, 'train_loss': 0.9376839309930801, 'val_loss': 1.0100979105631511, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 36, 'train_loss': 0.9303159207105637, 'val_loss': 1.0050822321573893, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 37, 'train_loss': 0.9387502819299698, 'val_loss': 1.0072405497233072, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 38, 'train_loss': 0.9374855637550354, 'val_loss': 1.0162715911865234, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 39, 'train_loss': 0.9303307563066483, 'val_loss': 1.0223776117960612, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 40, 'train_loss': 0.9349708884954453, 'val_loss': 1.012880147298177, 'test_acc': 0.48}
{'fold': 9, 'epoch': 41, 'train_loss': 0.9285217016935349, 'val_loss': 1.0167142740885418, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 42, 'train_loss': 0.922796568274498, 'val_loss': 1.0170887502034505, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 43, 'train_loss': 0.9232492476701737, 'val_loss': 1.019981969197591, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 44, 'train_loss': 0.9287759333848953, 'val_loss': 1.0147486114501953, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 45, 'train_loss': 0.9296513110399246, 'val_loss': 1.0201206715901692, 'test_acc': 0.52}
{'fold': 9, 'epoch': 46, 'train_loss': 0.9234802097082138, 'val_loss': 1.025171890258789, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 47, 'train_loss': 0.9317669868469238, 'val_loss': 1.0228457895914713, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 48, 'train_loss': 0.9430858969688416, 'val_loss': 1.0278061294555665, 'test_acc': 0.48}
{'fold': 9, 'epoch': 49, 'train_loss': 0.9272380769252777, 'val_loss': 1.0145724614461262, 'test_acc': 0.48}
{'fold': 9, 'epoch': 50, 'train_loss': 0.923845249414444, 'val_loss': 1.0122156143188477, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 51, 'train_loss': 0.9186100214719772, 'val_loss': 1.0209319814046225, 'test_acc': 0.5}
{'fold': 9, 'epoch': 52, 'train_loss': 0.9240516573190689, 'val_loss': 1.0204965209960937, 'test_acc': 0.46}
{'fold': 9, 'epoch': 53, 'train_loss': 0.9243389666080475, 'val_loss': 1.0137162907918293, 'test_acc': 0.5}
{'fold': 9, 'epoch': 54, 'train_loss': 0.9205321341753006, 'val_loss': 1.028262570699056, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 55, 'train_loss': 0.9209551185369491, 'val_loss': 1.0175123087565103, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 56, 'train_loss': 0.9204120367765427, 'val_loss': 1.0204872767130533, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 57, 'train_loss': 0.9175394803285599, 'val_loss': 1.028963623046875, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 58, 'train_loss': 0.9271780729293824, 'val_loss': 1.0349434280395509, 'test_acc': 0.48}
{'fold': 9, 'epoch': 59, 'train_loss': 0.9203998059034347, 'val_loss': 1.0357277806599934, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 60, 'train_loss': 0.9182072520256043, 'val_loss': 1.0353570302327475, 'test_acc': 0.48}
{'fold': 9, 'epoch': 61, 'train_loss': 0.9231918454170227, 'val_loss': 1.0461059188842774, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 62, 'train_loss': 0.9146860629320145, 'val_loss': 1.0474388885498047, 'test_acc': 0.5}
{'fold': 9, 'epoch': 63, 'train_loss': 0.9267965584993363, 'val_loss': 1.0280238850911458, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 64, 'train_loss': 0.9128300338983536, 'val_loss': 1.0380062993367514, 'test_acc': 0.48}
{'fold': 9, 'epoch': 65, 'train_loss': 0.9144297540187836, 'val_loss': 1.0405221684773762, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 66, 'train_loss': 0.9146573483943939, 'val_loss': 1.038805414835612, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 67, 'train_loss': 0.9083249688148498, 'val_loss': 1.037532196044922, 'test_acc': 0.5}
{'fold': 9, 'epoch': 68, 'train_loss': 0.9184728562831879, 'val_loss': 1.0399539057413738, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 69, 'train_loss': 0.8950222641229629, 'val_loss': 1.047289784749349, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 70, 'train_loss': 0.913332599401474, 'val_loss': 1.0470342381795248, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 71, 'train_loss': 0.9156613886356354, 'val_loss': 1.0682737986246744, 'test_acc': 0.5}
{'fold': 9, 'epoch': 72, 'train_loss': 0.9051887392997742, 'val_loss': 1.0298240534464518, 'test_acc': 0.52}
{'fold': 9, 'epoch': 73, 'train_loss': 0.9086022704839707, 'val_loss': 1.0324296315511068, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 74, 'train_loss': 0.9001541793346405, 'val_loss': 1.0351655705769858, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 75, 'train_loss': 0.9007270395755768, 'val_loss': 1.0351472218831381, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 76, 'train_loss': 0.898894864320755, 'val_loss': 1.0398881530761719, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 77, 'train_loss': 0.9052050828933715, 'val_loss': 1.0388908386230469, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 78, 'train_loss': 0.902361923456192, 'val_loss': 1.0522757720947267, 'test_acc': 0.48}
{'fold': 9, 'epoch': 79, 'train_loss': 0.9051434099674225, 'val_loss': 1.0432933044433594, 'test_acc': 0.5}
{'fold': 9, 'epoch': 80, 'train_loss': 0.8994319140911102, 'val_loss': 1.0470797729492187, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 81, 'train_loss': 0.8913407444953918, 'val_loss': 1.0403143564860027, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 82, 'train_loss': 0.8861836820840836, 'val_loss': 1.0418245951334635, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 83, 'train_loss': 0.8881509363651275, 'val_loss': 1.0578644053141275, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 84, 'train_loss': 0.8903172880411148, 'val_loss': 1.0468804931640625, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 85, 'train_loss': 0.8922496497631073, 'val_loss': 1.0501470565795898, 'test_acc': 0.5}
{'fold': 9, 'epoch': 86, 'train_loss': 0.8813870698213577, 'val_loss': 1.0836769994099935, 'test_acc': 0.5}
{'fold': 9, 'epoch': 87, 'train_loss': 0.8921426832675934, 'val_loss': 1.055754165649414, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 88, 'train_loss': 0.8810998380184174, 'val_loss': 1.0657836151123048, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 89, 'train_loss': 0.8937264889478683, 'val_loss': 1.061068318684896, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 90, 'train_loss': 0.8969603687524795, 'val_loss': 1.0678465016682943, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 91, 'train_loss': 0.910370746254921, 'val_loss': 1.0499293263753255, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 92, 'train_loss': 0.8839216649532318, 'val_loss': 1.054225616455078, 'test_acc': 0.5}
{'fold': 9, 'epoch': 93, 'train_loss': 0.886266115307808, 'val_loss': 1.0632387542724608, 'test_acc': 0.5}
{'fold': 9, 'epoch': 94, 'train_loss': 0.892558577656746, 'val_loss': 1.0602865854899088, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 95, 'train_loss': 0.8774811446666717, 'val_loss': 1.0601608657836914, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 96, 'train_loss': 0.8851380199193954, 'val_loss': 1.0628751118977864, 'test_acc': 0.5}
{'fold': 9, 'epoch': 97, 'train_loss': 0.8828795731067658, 'val_loss': 1.0573879369099934, 'test_acc': 0.5}
{'fold': 9, 'epoch': 98, 'train_loss': 0.8852148294448853, 'val_loss': 1.0731253814697266, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 99, 'train_loss': 0.8714032739400863, 'val_loss': 1.0823361206054687, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 100, 'train_loss': 0.8788568645715713, 'val_loss': 1.0808983866373698, 'test_acc': 0.5}
{'fold': 9, 'epoch': 101, 'train_loss': 0.883057501912117, 'val_loss': 1.0748828125, 'test_acc': 0.5}
{'fold': 9, 'epoch': 102, 'train_loss': 0.8808435350656509, 'val_loss': 1.0635757446289062, 'test_acc': 0.5}
{'fold': 9, 'epoch': 103, 'train_loss': 0.8823033213615418, 'val_loss': 1.082434768676758, 'test_acc': 0.5}
{'fold': 9, 'epoch': 104, 'train_loss': 0.8742313146591186, 'val_loss': 1.0940695190429688, 'test_acc': 0.5}
{'fold': 9, 'epoch': 105, 'train_loss': 0.8795849084854126, 'val_loss': 1.0882520294189453, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 106, 'train_loss': 0.8848290234804154, 'val_loss': 1.1110820770263672, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 107, 'train_loss': 0.88147674202919, 'val_loss': 1.0917100270589193, 'test_acc': 0.5}
{'fold': 9, 'epoch': 108, 'train_loss': 0.8770628303289414, 'val_loss': 1.0785470326741537, 'test_acc': 0.5}
{'fold': 9, 'epoch': 109, 'train_loss': 0.8758124887943268, 'val_loss': 1.0797101084391276, 'test_acc': 0.5}
{'fold': 9, 'epoch': 110, 'train_loss': 0.8759606927633286, 'val_loss': 1.0701481628417968, 'test_acc': 0.52}
{'fold': 9, 'epoch': 111, 'train_loss': 0.8781801402568817, 'val_loss': 1.0828928883870443, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 112, 'train_loss': 0.8738378912210465, 'val_loss': 1.0851328786214192, 'test_acc': 0.5}
{'fold': 9, 'epoch': 113, 'train_loss': 0.8649150788784027, 'val_loss': 1.0987607065836589, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 114, 'train_loss': 0.8672592759132385, 'val_loss': 1.1141608810424806, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 115, 'train_loss': 0.8666471481323242, 'val_loss': 1.1065151723225912, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 116, 'train_loss': 0.8662781953811646, 'val_loss': 1.0949361419677734, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 117, 'train_loss': 0.8709965616464614, 'val_loss': 1.1189236450195312, 'test_acc': 0.5}
{'fold': 9, 'epoch': 118, 'train_loss': 0.8768626272678375, 'val_loss': 1.1062915547688803, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 119, 'train_loss': 0.8657607883214951, 'val_loss': 1.0917992655436197, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 120, 'train_loss': 0.8681423664093018, 'val_loss': 1.0960189565022787, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 121, 'train_loss': 0.866052320599556, 'val_loss': 1.1166719309488933, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 122, 'train_loss': 0.8717235833406448, 'val_loss': 1.0969820149739584, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 123, 'train_loss': 0.8750168353319168, 'val_loss': 1.1184150568644207, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 124, 'train_loss': 0.8576007544994354, 'val_loss': 1.1166541035970052, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 125, 'train_loss': 0.8701551854610443, 'val_loss': 1.1162837982177733, 'test_acc': 0.5}
{'fold': 9, 'epoch': 126, 'train_loss': 0.86997749209404, 'val_loss': 1.1248982493082682, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 127, 'train_loss': 0.8634142816066742, 'val_loss': 1.1272532145182292, 'test_acc': 0.5}
{'fold': 9, 'epoch': 128, 'train_loss': 0.8675605714321136, 'val_loss': 1.1483899434407552, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 129, 'train_loss': 0.8621586173772812, 'val_loss': 1.130333735148112, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 130, 'train_loss': 0.8592100977897644, 'val_loss': 1.1265324147542317, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 131, 'train_loss': 0.8688853293657303, 'val_loss': 1.1160467274983723, 'test_acc': 0.5}
{'fold': 9, 'epoch': 132, 'train_loss': 0.8560020357370377, 'val_loss': 1.1405921173095703, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 133, 'train_loss': 0.856243696808815, 'val_loss': 1.1392693583170572, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 134, 'train_loss': 0.8569972813129425, 'val_loss': 1.1406365203857423, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 135, 'train_loss': 0.8586920827627182, 'val_loss': 1.1374723052978515, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 136, 'train_loss': 0.879848963022232, 'val_loss': 1.1331812032063802, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 137, 'train_loss': 0.8604197531938553, 'val_loss': 1.1335400136311848, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 138, 'train_loss': 0.8631750285625458, 'val_loss': 1.1248679860432942, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 139, 'train_loss': 0.8557023257017136, 'val_loss': 1.1224423217773438, 'test_acc': 0.5}
{'fold': 9, 'epoch': 140, 'train_loss': 0.8693880766630173, 'val_loss': 1.1246091715494793, 'test_acc': 0.5333333333333333}
{'fold': 9, 'epoch': 141, 'train_loss': 0.8510450839996337, 'val_loss': 1.1484203592936197, 'test_acc': 0.5333333333333333}
{'fold': 9, 'epoch': 142, 'train_loss': 0.8567662417888642, 'val_loss': 1.1334082794189453, 'test_acc': 0.52}
{'fold': 9, 'epoch': 143, 'train_loss': 0.8500079482793808, 'val_loss': 1.1436104838053385, 'test_acc': 0.5}
{'fold': 9, 'epoch': 144, 'train_loss': 0.8505936175584793, 'val_loss': 1.145527369181315, 'test_acc': 0.5}
{'fold': 9, 'epoch': 145, 'train_loss': 0.8536580622196197, 'val_loss': 1.143915557861328, 'test_acc': 0.5}
{'fold': 9, 'epoch': 146, 'train_loss': 0.8553985029458999, 'val_loss': 1.1560431416829426, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 147, 'train_loss': 0.8476896435022354, 'val_loss': 1.17195556640625, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 148, 'train_loss': 0.8480263441801071, 'val_loss': 1.1466098785400392, 'test_acc': 0.5}
{'fold': 9, 'epoch': 149, 'train_loss': 0.8501448929309845, 'val_loss': 1.1461423238118489, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 150, 'train_loss': 0.8468038082122803, 'val_loss': 1.1621584320068359, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 151, 'train_loss': 0.8462590426206589, 'val_loss': 1.1449740600585938, 'test_acc': 0.5}
{'fold': 9, 'epoch': 152, 'train_loss': 0.8414907217025757, 'val_loss': 1.1806001536051431, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 153, 'train_loss': 0.8681079804897308, 'val_loss': 1.145764389038086, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 154, 'train_loss': 0.8597942352294922, 'val_loss': 1.133048350016276, 'test_acc': 0.5}
{'fold': 9, 'epoch': 155, 'train_loss': 0.8455603748559952, 'val_loss': 1.1526598358154296, 'test_acc': 0.5}
{'fold': 9, 'epoch': 156, 'train_loss': 0.845635449886322, 'val_loss': 1.176566416422526, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 157, 'train_loss': 0.8534303903579712, 'val_loss': 1.1823656209309896, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 158, 'train_loss': 0.8566299974918365, 'val_loss': 1.1705732981363932, 'test_acc': 0.5}
{'fold': 9, 'epoch': 159, 'train_loss': 0.8481091767549515, 'val_loss': 1.1653102366129557, 'test_acc': 0.5}
{'fold': 9, 'epoch': 160, 'train_loss': 0.8393734961748123, 'val_loss': 1.1740061696370443, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 161, 'train_loss': 0.8445850253105164, 'val_loss': 1.1754522450764975, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 162, 'train_loss': 0.8488453030586243, 'val_loss': 1.1968838246663411, 'test_acc': 0.5}
{'fold': 9, 'epoch': 163, 'train_loss': 0.8492938846349716, 'val_loss': 1.1786539713541666, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 164, 'train_loss': 0.8357398748397827, 'val_loss': 1.194293924967448, 'test_acc': 0.5}
{'fold': 9, 'epoch': 165, 'train_loss': 0.8466811627149582, 'val_loss': 1.2073537699381511, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 166, 'train_loss': 0.8383328646421433, 'val_loss': 1.23752072652181, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 167, 'train_loss': 0.8325361102819443, 'val_loss': 1.2305341084798178, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 168, 'train_loss': 0.83917256295681, 'val_loss': 1.2000422922770182, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 169, 'train_loss': 0.8354071795940399, 'val_loss': 1.2332610321044921, 'test_acc': 0.5}
{'fold': 9, 'epoch': 170, 'train_loss': 0.844626298546791, 'val_loss': 1.1879871622721354, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 171, 'train_loss': 0.8327550292015076, 'val_loss': 1.219052225748698, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 172, 'train_loss': 0.8382326513528824, 'val_loss': 1.233857650756836, 'test_acc': 0.5}
{'fold': 9, 'epoch': 173, 'train_loss': 0.8351087987422943, 'val_loss': 1.2063148498535157, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 174, 'train_loss': 0.8404636472463608, 'val_loss': 1.207028528849284, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 175, 'train_loss': 0.8360697448253631, 'val_loss': 1.2068067169189454, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 176, 'train_loss': 0.8337210118770599, 'val_loss': 1.2224830627441405, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 177, 'train_loss': 0.8360825628042221, 'val_loss': 1.2172506968180339, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 178, 'train_loss': 0.8282924711704254, 'val_loss': 1.257350311279297, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 179, 'train_loss': 0.8340232014656067, 'val_loss': 1.2253940073649088, 'test_acc': 0.52}
{'fold': 9, 'epoch': 180, 'train_loss': 0.8365111798048019, 'val_loss': 1.261234664916992, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 181, 'train_loss': 0.8356102854013443, 'val_loss': 1.2416018931070965, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 182, 'train_loss': 0.8471725881099701, 'val_loss': 1.2179451497395832, 'test_acc': 0.5}
{'fold': 9, 'epoch': 183, 'train_loss': 0.8358407467603683, 'val_loss': 1.2621599833170574, 'test_acc': 0.5}
{'fold': 9, 'epoch': 184, 'train_loss': 0.8271826982498169, 'val_loss': 1.269067866007487, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 185, 'train_loss': 0.8390731900930405, 'val_loss': 1.2338181050618489, 'test_acc': 0.48}
{'fold': 9, 'epoch': 186, 'train_loss': 0.8235982626676559, 'val_loss': 1.2382520039876301, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 187, 'train_loss': 0.8182778716087341, 'val_loss': 1.2864150492350261, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 188, 'train_loss': 0.8222585767507553, 'val_loss': 1.2736742655436197, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 189, 'train_loss': 0.8227043718099594, 'val_loss': 1.2746017710367838, 'test_acc': 0.52}
{'fold': 9, 'epoch': 190, 'train_loss': 0.8257176905870438, 'val_loss': 1.2331078084309897, 'test_acc': 0.5}
{'fold': 9, 'epoch': 191, 'train_loss': 0.8206051319837571, 'val_loss': 1.315182902018229, 'test_acc': 0.5}
{'fold': 9, 'epoch': 192, 'train_loss': 0.8267084509134293, 'val_loss': 1.292666498819987, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 193, 'train_loss': 0.82616206407547, 'val_loss': 1.2521967315673828, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 194, 'train_loss': 0.8268641710281373, 'val_loss': 1.2640445200602213, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 195, 'train_loss': 0.8216334760189057, 'val_loss': 1.2900399271647136, 'test_acc': 0.5}
{'fold': 9, 'epoch': 196, 'train_loss': 0.8346544116735458, 'val_loss': 1.2756721750895181, 'test_acc': 0.52}
{'fold': 9, 'epoch': 197, 'train_loss': 0.8186590135097503, 'val_loss': 1.288529561360677, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 198, 'train_loss': 0.8197989761829376, 'val_loss': 1.2693579864501954, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 199, 'train_loss': 0.8292690545320511, 'val_loss': 1.280905507405599, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 200, 'train_loss': 0.8210279643535614, 'val_loss': 1.2619229380289714, 'test_acc': 0.5066666666666667}
Val Loss: 0.9565, Test Accuracy: 0.498 ± 0.029, Duration: 125.371
Best result - 0.498 ± 0.029
--
MUTAG - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.7027236599671213, 'val_loss': 0.6957697868347168, 'test_acc': 0.3333333333333333}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6935594160305826, 'val_loss': 0.6848047574361166, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 3, 'train_loss': 0.682616905162209, 'val_loss': 0.6730093955993652, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 4, 'train_loss': 0.668804429079357, 'val_loss': 0.6566767162746854, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6582860287867094, 'val_loss': 0.6407579316033257, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6353686844047747, 'val_loss': 0.6358111169603136, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6226951040719685, 'val_loss': 0.6188272900051541, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6150199065082952, 'val_loss': 0.6110434532165527, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 9, 'train_loss': 0.609290278271625, 'val_loss': 0.6054699156019423, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5957799240162498, 'val_loss': 0.5928972032335069, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 11, 'train_loss': 0.598719038461384, 'val_loss': 0.5802257325914171, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5953473997743506, 'val_loss': 0.5702670945061578, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 13, 'train_loss': 0.592250877305081, 'val_loss': 0.5532394515143501, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5567831475483743, 'val_loss': 0.5293560028076172, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5532446535010087, 'val_loss': 0.5014483663770888, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 16, 'train_loss': 0.520610951279339, 'val_loss': 0.4728247324625651, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 17, 'train_loss': 0.49966018372460413, 'val_loss': 0.4309026135338677, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 18, 'train_loss': 0.4762385479713741, 'val_loss': 0.373971594704522, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 19, 'train_loss': 0.4649027350701784, 'val_loss': 0.3233830663892958, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 20, 'train_loss': 0.44362908915469523, 'val_loss': 0.281719790564643, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 21, 'train_loss': 0.38595083669612285, 'val_loss': 0.24927804205152723, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 22, 'train_loss': 0.37897769087239314, 'val_loss': 0.22637107637193468, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 23, 'train_loss': 0.37677323818206787, 'val_loss': 0.20829301410251194, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 24, 'train_loss': 0.39309570820708023, 'val_loss': 0.20067444112565783, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 25, 'train_loss': 0.3960706301425633, 'val_loss': 0.2035048140419854, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 26, 'train_loss': 0.3988582272278635, 'val_loss': 0.20992807547251383, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 27, 'train_loss': 0.3816503129507366, 'val_loss': 0.2176614205042521, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 28, 'train_loss': 0.37649909524541153, 'val_loss': 0.22792675760057238, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 29, 'train_loss': 0.3932609503206454, 'val_loss': 0.23446596993340385, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 30, 'train_loss': 0.38866361112971054, 'val_loss': 0.2410771581861708, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 31, 'train_loss': 0.3764819083245177, 'val_loss': 0.23788669374254015, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 32, 'train_loss': 0.38358873756308304, 'val_loss': 0.2348579830593533, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 33, 'train_loss': 0.37677336209698725, 'val_loss': 0.23301850424872506, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 34, 'train_loss': 0.3971726306174931, 'val_loss': 0.22794980472988552, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 35, 'train_loss': 0.37675735040714864, 'val_loss': 0.23053720262315539, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 36, 'train_loss': 0.3813582399958058, 'val_loss': 0.23250945409138998, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 37, 'train_loss': 0.3698741189743343, 'val_loss': 0.23066319359673393, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 38, 'train_loss': 0.3652582309747997, 'val_loss': 0.22533819410536024, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 39, 'train_loss': 0.3763602940659774, 'val_loss': 0.21889613734351265, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 40, 'train_loss': 0.39570794372182144, 'val_loss': 0.21927617655860054, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 41, 'train_loss': 0.3677491153541364, 'val_loss': 0.22345132297939724, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 42, 'train_loss': 0.3889875419830021, 'val_loss': 0.23190559281243217, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 43, 'train_loss': 0.3612330806882758, 'val_loss': 0.23695916599697536, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 44, 'train_loss': 0.36031467193051386, 'val_loss': 0.23848703172471789, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 45, 'train_loss': 0.37393693233791153, 'val_loss': 0.2344739172193739, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 46, 'train_loss': 0.3730180679183257, 'val_loss': 0.23198318481445312, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 47, 'train_loss': 0.35451387966934006, 'val_loss': 0.22587452994452584, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 48, 'train_loss': 0.3813336570011942, 'val_loss': 0.22515498267279732, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 49, 'train_loss': 0.3663710465556697, 'val_loss': 0.223358154296875, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3718445936315938, 'val_loss': 0.22313004069858128, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 51, 'train_loss': 0.3895233022539239, 'val_loss': 0.22439066569010416, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 52, 'train_loss': 0.3605085407432757, 'val_loss': 0.22391335169474283, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 53, 'train_loss': 0.36999705355418355, 'val_loss': 0.22449477513631186, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 54, 'train_loss': 0.3681263437396602, 'val_loss': 0.22388156255086264, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 55, 'train_loss': 0.37617736976397664, 'val_loss': 0.22383242183261448, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 56, 'train_loss': 0.3502225664101149, 'val_loss': 0.23118967480129665, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 57, 'train_loss': 0.3869699898519014, 'val_loss': 0.23273062705993652, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 58, 'train_loss': 0.36812253923792587, 'val_loss': 0.2230623033311632, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 59, 'train_loss': 0.37427741289138794, 'val_loss': 0.22545279396904838, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 60, 'train_loss': 0.34096179275136246, 'val_loss': 0.22880872090657553, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 61, 'train_loss': 0.385345448004572, 'val_loss': 0.22768081559075248, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 62, 'train_loss': 0.371972257369443, 'val_loss': 0.226286252339681, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 63, 'train_loss': 0.379315269620795, 'val_loss': 0.23123468293084037, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 64, 'train_loss': 0.3629608922883084, 'val_loss': 0.23269346025254992, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 65, 'train_loss': 0.3686026373976155, 'val_loss': 0.22923363579644096, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 66, 'train_loss': 0.3648829264076133, 'val_loss': 0.226442019144694, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 67, 'train_loss': 0.3947374020752154, 'val_loss': 0.22397086355421278, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 68, 'train_loss': 0.3538004536377756, 'val_loss': 0.22659079233805338, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 69, 'train_loss': 0.3462900205662376, 'val_loss': 0.22503256797790527, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 70, 'train_loss': 0.36653807445576314, 'val_loss': 0.22346144252353245, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 71, 'train_loss': 0.3655777926507749, 'val_loss': 0.22089371416303846, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 72, 'train_loss': 0.3551752833943618, 'val_loss': 0.22225472662183973, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 73, 'train_loss': 0.35657446478542526, 'val_loss': 0.22110541661580405, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 74, 'train_loss': 0.33612190618326787, 'val_loss': 0.2175994979010688, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 75, 'train_loss': 0.3515781995497252, 'val_loss': 0.2184323337343004, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 76, 'train_loss': 0.3741790691488667, 'val_loss': 0.2196009953816732, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 77, 'train_loss': 0.3634370000738847, 'val_loss': 0.21682393550872803, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 78, 'train_loss': 0.34634497291163396, 'val_loss': 0.2128507031334771, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 79, 'train_loss': 0.35750332474708557, 'val_loss': 0.20834745301140678, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 80, 'train_loss': 0.35248989337369013, 'val_loss': 0.2095752027299669, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 81, 'train_loss': 0.3665875988571267, 'val_loss': 0.21226696173350015, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 82, 'train_loss': 0.35411704292422846, 'val_loss': 0.20948591497209337, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 83, 'train_loss': 0.3648746460676193, 'val_loss': 0.2042157385084364, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 84, 'train_loss': 0.3293210699370033, 'val_loss': 0.19675358136494955, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 85, 'train_loss': 0.3531866904936339, 'val_loss': 0.1968969768948025, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 86, 'train_loss': 0.3687126158099425, 'val_loss': 0.19662600093417698, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 87, 'train_loss': 0.3267731470497031, 'val_loss': 0.2055242723888821, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 88, 'train_loss': 0.353993968744027, 'val_loss': 0.20988094806671143, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 89, 'train_loss': 0.3546766936779022, 'val_loss': 0.20395519998338488, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 90, 'train_loss': 0.3374565016282232, 'val_loss': 0.20268377992841932, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 91, 'train_loss': 0.3426979395904039, 'val_loss': 0.19822022649976942, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 92, 'train_loss': 0.3396122628136685, 'val_loss': 0.19721949100494385, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 93, 'train_loss': 0.3594200218978681, 'val_loss': 0.20066490438249376, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 94, 'train_loss': 0.33893492268888575, 'val_loss': 0.19758650991651747, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3539576640254573, 'val_loss': 0.1939992904663086, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 96, 'train_loss': 0.33250659547354044, 'val_loss': 0.19314016236199272, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 97, 'train_loss': 0.3225398345997459, 'val_loss': 0.18881922298007542, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 98, 'train_loss': 0.3412283474677487, 'val_loss': 0.1868388122982449, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 99, 'train_loss': 0.3343469563283418, 'val_loss': 0.1835078795750936, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 100, 'train_loss': 0.316405293188597, 'val_loss': 0.1821033689710829, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 101, 'train_loss': 0.35797150589917837, 'val_loss': 0.1795747677485148, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 102, 'train_loss': 0.34525518746752487, 'val_loss': 0.17825698852539062, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 103, 'train_loss': 0.35288944291441066, 'val_loss': 0.17498205767737496, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 104, 'train_loss': 0.3353039763475719, 'val_loss': 0.1741109159257677, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 105, 'train_loss': 0.3447755441853875, 'val_loss': 0.1724068588680691, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 106, 'train_loss': 0.336281171362651, 'val_loss': 0.17377777894337973, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 107, 'train_loss': 0.3493878739444833, 'val_loss': 0.17306698693169487, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 108, 'train_loss': 0.3440914267772122, 'val_loss': 0.1704031096564399, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 109, 'train_loss': 0.33298405769624206, 'val_loss': 0.17026289304097494, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 110, 'train_loss': 0.35344409785772624, 'val_loss': 0.16990423202514648, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 111, 'train_loss': 0.3461662491685466, 'val_loss': 0.17681007915072972, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 112, 'train_loss': 0.3229378508894067, 'val_loss': 0.1805634233686659, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 113, 'train_loss': 0.3268717252894452, 'val_loss': 0.17947810226016575, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 114, 'train_loss': 0.3199996411016113, 'val_loss': 0.17066027058495414, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 115, 'train_loss': 0.3465035181296499, 'val_loss': 0.17735864056481254, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 116, 'train_loss': 0.3190929607341164, 'val_loss': 0.17240462038252088, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 117, 'train_loss': 0.3303849728483903, 'val_loss': 0.1746305359734429, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 118, 'train_loss': 0.3519081904699928, 'val_loss': 0.18109622266557482, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 119, 'train_loss': 0.3398373958311583, 'val_loss': 0.18492073482937282, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 120, 'train_loss': 0.3494067239133935, 'val_loss': 0.18945018450419107, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 121, 'train_loss': 0.35188906286892135, 'val_loss': 0.19479762183295357, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 122, 'train_loss': 0.3475465798064282, 'val_loss': 0.1998418172200521, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 123, 'train_loss': 0.32805635819309636, 'val_loss': 0.20228617721133763, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 124, 'train_loss': 0.3387420404898493, 'val_loss': 0.20232931772867838, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 125, 'train_loss': 0.35395855652658564, 'val_loss': 0.20257984267340767, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 126, 'train_loss': 0.35171379619523097, 'val_loss': 0.2065492735968696, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 127, 'train_loss': 0.36346335316959183, 'val_loss': 0.203250699573093, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 128, 'train_loss': 0.3632942971430327, 'val_loss': 0.20161451233757866, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 129, 'train_loss': 0.34506721637750926, 'val_loss': 0.20770797464582655, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 130, 'train_loss': 0.3411992286380969, 'val_loss': 0.20174584123823378, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 131, 'train_loss': 0.3334121398235622, 'val_loss': 0.19508233335283068, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 132, 'train_loss': 0.3331431330818879, 'val_loss': 0.19219134913550484, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 133, 'train_loss': 0.34062543903526504, 'val_loss': 0.18522634771135119, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 134, 'train_loss': 0.3614468966659747, 'val_loss': 0.18518144554562038, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 135, 'train_loss': 0.33874141307253586, 'val_loss': 0.18216580814785427, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 136, 'train_loss': 0.3264624750927875, 'val_loss': 0.17890412277645534, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 137, 'train_loss': 0.33965946263388586, 'val_loss': 0.17449107435014513, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 138, 'train_loss': 0.328006165592294, 'val_loss': 0.17620990011427137, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 139, 'train_loss': 0.32913769703162343, 'val_loss': 0.16950501335991752, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 140, 'train_loss': 0.3283237885487707, 'val_loss': 0.17327372233072916, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 141, 'train_loss': 0.31674408834231527, 'val_loss': 0.17387649748060438, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 142, 'train_loss': 0.32829844873202474, 'val_loss': 0.17139134142133924, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 143, 'train_loss': 0.34582951272788803, 'val_loss': 0.173085265689426, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 144, 'train_loss': 0.3622255474328995, 'val_loss': 0.176521274778578, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 145, 'train_loss': 0.3357142151186341, 'val_loss': 0.18417345152960884, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 146, 'train_loss': 0.3230797577845423, 'val_loss': 0.1895388232337104, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 147, 'train_loss': 0.3287843246208994, 'val_loss': 0.18756275706821018, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 148, 'train_loss': 0.33863178719031184, 'val_loss': 0.18759041362338597, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 149, 'train_loss': 0.3154633009904309, 'val_loss': 0.17762299378712973, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 150, 'train_loss': 0.3248031680521212, 'val_loss': 0.1792547040515476, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 151, 'train_loss': 0.33699945791771535, 'val_loss': 0.17702350351545545, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 152, 'train_loss': 0.3697139385499452, 'val_loss': 0.18038361602359348, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 153, 'train_loss': 0.3590976329226243, 'val_loss': 0.180444598197937, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 154, 'train_loss': 0.3237729527448353, 'val_loss': 0.18829715251922607, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 155, 'train_loss': 0.33400915876815196, 'val_loss': 0.1968168152703179, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 156, 'train_loss': 0.3422535422601198, 'val_loss': 0.19075363212161595, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 157, 'train_loss': 0.3325527475068444, 'val_loss': 0.19014181031121147, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 158, 'train_loss': 0.35739168838450786, 'val_loss': 0.18504170576731363, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 159, 'train_loss': 0.3364530903728385, 'val_loss': 0.19276614983876547, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 160, 'train_loss': 0.32315700461989955, 'val_loss': 0.18474483489990234, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 161, 'train_loss': 0.3567531312766828, 'val_loss': 0.1675554249021742, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 162, 'train_loss': 0.3360772391683177, 'val_loss': 0.1724870072470771, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 163, 'train_loss': 0.3286625789968591, 'val_loss': 0.16652435726589626, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 164, 'train_loss': 0.3238864211659682, 'val_loss': 0.1659461127387153, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 165, 'train_loss': 0.3494418286963513, 'val_loss': 0.17567067676120335, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 166, 'train_loss': 0.3401469600043799, 'val_loss': 0.18129844135708278, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 167, 'train_loss': 0.33178530986371796, 'val_loss': 0.1870756811565823, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 168, 'train_loss': 0.36654491801010936, 'val_loss': 0.19725230005052355, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 169, 'train_loss': 0.32890445072399943, 'val_loss': 0.18224292331271702, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 170, 'train_loss': 0.33162717521190643, 'val_loss': 0.17418930265638563, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 171, 'train_loss': 0.33811587173687785, 'val_loss': 0.16381514072418213, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 172, 'train_loss': 0.32828216489992645, 'val_loss': 0.16684264606899685, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 173, 'train_loss': 0.34084726085788325, 'val_loss': 0.13373532560136583, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 174, 'train_loss': 0.33796485474235133, 'val_loss': 0.1277306079864502, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 175, 'train_loss': 0.348971468053366, 'val_loss': 0.1374940342373318, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 176, 'train_loss': 0.3254473930911014, 'val_loss': 0.1436503595776028, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 177, 'train_loss': 0.33224428327460037, 'val_loss': 0.14870376057094997, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 178, 'train_loss': 0.3431633577535027, 'val_loss': 0.14911565515730116, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 179, 'train_loss': 0.34545241923708664, 'val_loss': 0.15379595756530762, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 180, 'train_loss': 0.33258499754102605, 'val_loss': 0.15617206361558703, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 181, 'train_loss': 0.3291494469893606, 'val_loss': 0.1504669321907891, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 182, 'train_loss': 0.33525205678061437, 'val_loss': 0.14518021212683785, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 183, 'train_loss': 0.3277162885979602, 'val_loss': 0.14128465122646755, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 184, 'train_loss': 0.31813116057922963, 'val_loss': 0.1433656613032023, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 185, 'train_loss': 0.33508875260227605, 'val_loss': 0.14280553658803305, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 186, 'train_loss': 0.35523982973475204, 'val_loss': 0.144953899913364, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 187, 'train_loss': 0.33360048893250915, 'val_loss': 0.14945589171515572, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 188, 'train_loss': 0.35494427696654673, 'val_loss': 0.15871769852108425, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 189, 'train_loss': 0.32988171828420537, 'val_loss': 0.16510433620876735, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 190, 'train_loss': 0.33488999542437103, 'val_loss': 0.16161828570895725, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 191, 'train_loss': 0.3227624391254626, 'val_loss': 0.15754326184590658, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 192, 'train_loss': 0.33610209430518906, 'val_loss': 0.1588059531317817, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 193, 'train_loss': 0.34544702658527776, 'val_loss': 0.15598156717088488, 'test_acc': 0.8333333333333334}
{'fold': 9, 'epoch': 194, 'train_loss': 0.33772937718190643, 'val_loss': 0.1621358659532335, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 195, 'train_loss': 0.3274740506159632, 'val_loss': 0.1603358056810167, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 196, 'train_loss': 0.3206272846774051, 'val_loss': 0.15728125307295057, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 197, 'train_loss': 0.3243459447434074, 'val_loss': 0.14446683724721274, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 198, 'train_loss': 0.31913152258647115, 'val_loss': 0.13286140229966906, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 199, 'train_loss': 0.3241363850079085, 'val_loss': 0.1300133334265815, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 200, 'train_loss': 0.34717753372694315, 'val_loss': 0.13403117656707764, 'test_acc': 0.7777777777777778}
Val Loss: 0.3150, Test Accuracy: 0.857 ± 0.087, Duration: 32.647
Best result - 0.857 ± 0.087
--
IMDB-BINARY - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6937692940235138, 'val_loss': 0.6919878578186035, 'test_acc': 0.5}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6896335199475289, 'val_loss': 0.6832284927368164, 'test_acc': 0.62}
{'fold': 9, 'epoch': 3, 'train_loss': 0.672544726729393, 'val_loss': 0.6546200180053711, 'test_acc': 0.65}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6209923774003983, 'val_loss': 0.5631745147705078, 'test_acc': 0.67}
{'fold': 9, 'epoch': 5, 'train_loss': 0.573765017837286, 'val_loss': 0.521468677520752, 'test_acc': 0.65}
{'fold': 9, 'epoch': 6, 'train_loss': 0.560319958627224, 'val_loss': 0.5210407066345215, 'test_acc': 0.7}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5546424053609371, 'val_loss': 0.5377167892456055, 'test_acc': 0.68}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5365177743136883, 'val_loss': 0.5235169887542724, 'test_acc': 0.69}
{'fold': 9, 'epoch': 9, 'train_loss': 0.5214386202394963, 'val_loss': 0.5185792064666748, 'test_acc': 0.7}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5254196345806121, 'val_loss': 0.5189446830749511, 'test_acc': 0.69}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5033138498663903, 'val_loss': 0.5068388557434083, 'test_acc': 0.72}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4925568215548992, 'val_loss': 0.5005653572082519, 'test_acc': 0.72}
{'fold': 9, 'epoch': 13, 'train_loss': 0.49881069734692574, 'val_loss': 0.49345659255981444, 'test_acc': 0.71}
{'fold': 9, 'epoch': 14, 'train_loss': 0.4990123838186264, 'val_loss': 0.49060789108276365, 'test_acc': 0.71}
{'fold': 9, 'epoch': 15, 'train_loss': 0.49366206005215646, 'val_loss': 0.4891851615905762, 'test_acc': 0.72}
{'fold': 9, 'epoch': 16, 'train_loss': 0.4866255961358547, 'val_loss': 0.49120416641235354, 'test_acc': 0.69}
{'fold': 9, 'epoch': 17, 'train_loss': 0.48527279794216155, 'val_loss': 0.48833361625671384, 'test_acc': 0.69}
{'fold': 9, 'epoch': 18, 'train_loss': 0.49049404785037043, 'val_loss': 0.48678050994873046, 'test_acc': 0.7}
{'fold': 9, 'epoch': 19, 'train_loss': 0.4847270406782627, 'val_loss': 0.4984414100646973, 'test_acc': 0.69}
{'fold': 9, 'epoch': 20, 'train_loss': 0.4750232994556427, 'val_loss': 0.48615015029907227, 'test_acc': 0.71}
{'fold': 9, 'epoch': 21, 'train_loss': 0.4968309313058853, 'val_loss': 0.48594913482666013, 'test_acc': 0.7}
{'fold': 9, 'epoch': 22, 'train_loss': 0.4910263828933239, 'val_loss': 0.49234508514404296, 'test_acc': 0.74}
{'fold': 9, 'epoch': 23, 'train_loss': 0.4875007592141628, 'val_loss': 0.4818716526031494, 'test_acc': 0.72}
{'fold': 9, 'epoch': 24, 'train_loss': 0.48279499635100365, 'val_loss': 0.4840656852722168, 'test_acc': 0.72}
{'fold': 9, 'epoch': 25, 'train_loss': 0.4753201998770237, 'val_loss': 0.47687808990478514, 'test_acc': 0.7}
{'fold': 9, 'epoch': 26, 'train_loss': 0.48080701306462287, 'val_loss': 0.47664609909057615, 'test_acc': 0.74}
{'fold': 9, 'epoch': 27, 'train_loss': 0.462700679898262, 'val_loss': 0.4785098838806152, 'test_acc': 0.72}
{'fold': 9, 'epoch': 28, 'train_loss': 0.4579677939414978, 'val_loss': 0.479810905456543, 'test_acc': 0.72}
{'fold': 9, 'epoch': 29, 'train_loss': 0.46380299627780913, 'val_loss': 0.49453824043273925, 'test_acc': 0.71}
{'fold': 9, 'epoch': 30, 'train_loss': 0.4698615111410618, 'val_loss': 0.47342906951904296, 'test_acc': 0.74}
{'fold': 9, 'epoch': 31, 'train_loss': 0.4520629085600376, 'val_loss': 0.4785757827758789, 'test_acc': 0.74}
{'fold': 9, 'epoch': 32, 'train_loss': 0.4557965360581875, 'val_loss': 0.4786640739440918, 'test_acc': 0.74}
{'fold': 9, 'epoch': 33, 'train_loss': 0.46003407165408133, 'val_loss': 0.4886670207977295, 'test_acc': 0.72}
{'fold': 9, 'epoch': 34, 'train_loss': 0.45260620042681693, 'val_loss': 0.49458434104919435, 'test_acc': 0.73}
{'fold': 9, 'epoch': 35, 'train_loss': 0.4542321220040321, 'val_loss': 0.48498546600341796, 'test_acc': 0.74}
{'fold': 9, 'epoch': 36, 'train_loss': 0.4509578585624695, 'val_loss': 0.4914701843261719, 'test_acc': 0.72}
{'fold': 9, 'epoch': 37, 'train_loss': 0.4510783784091473, 'val_loss': 0.49240795135498044, 'test_acc': 0.73}
{'fold': 9, 'epoch': 38, 'train_loss': 0.45696677044034006, 'val_loss': 0.4918712329864502, 'test_acc': 0.73}
{'fold': 9, 'epoch': 39, 'train_loss': 0.43467372134327886, 'val_loss': 0.4841169738769531, 'test_acc': 0.69}
{'fold': 9, 'epoch': 40, 'train_loss': 0.4422269225120544, 'val_loss': 0.4963558769226074, 'test_acc': 0.72}
{'fold': 9, 'epoch': 41, 'train_loss': 0.445187346637249, 'val_loss': 0.5073243141174316, 'test_acc': 0.68}
{'fold': 9, 'epoch': 42, 'train_loss': 0.4499379187822342, 'val_loss': 0.4957975196838379, 'test_acc': 0.72}
{'fold': 9, 'epoch': 43, 'train_loss': 0.4523484863340855, 'val_loss': 0.4777543258666992, 'test_acc': 0.72}
{'fold': 9, 'epoch': 44, 'train_loss': 0.43409920334815977, 'val_loss': 0.4846104335784912, 'test_acc': 0.72}
{'fold': 9, 'epoch': 45, 'train_loss': 0.43648288398981094, 'val_loss': 0.48612945556640624, 'test_acc': 0.71}
{'fold': 9, 'epoch': 46, 'train_loss': 0.44970276579260826, 'val_loss': 0.48224559783935544, 'test_acc': 0.69}
{'fold': 9, 'epoch': 47, 'train_loss': 0.44897414147853854, 'val_loss': 0.4805146789550781, 'test_acc': 0.73}
{'fold': 9, 'epoch': 48, 'train_loss': 0.4300073176622391, 'val_loss': 0.4963850116729736, 'test_acc': 0.72}
{'fold': 9, 'epoch': 49, 'train_loss': 0.4305154614150524, 'val_loss': 0.49937470436096193, 'test_acc': 0.7}
{'fold': 9, 'epoch': 50, 'train_loss': 0.4316149689257145, 'val_loss': 0.4765448474884033, 'test_acc': 0.69}
{'fold': 9, 'epoch': 51, 'train_loss': 0.4313210465013981, 'val_loss': 0.5253059482574463, 'test_acc': 0.64}
{'fold': 9, 'epoch': 52, 'train_loss': 0.4285134896636009, 'val_loss': 0.4670313453674316, 'test_acc': 0.73}
{'fold': 9, 'epoch': 53, 'train_loss': 0.42692320570349696, 'val_loss': 0.4873126697540283, 'test_acc': 0.71}
{'fold': 9, 'epoch': 54, 'train_loss': 0.4191321223974228, 'val_loss': 0.47275581359863283, 'test_acc': 0.73}
{'fold': 9, 'epoch': 55, 'train_loss': 0.4116578444838524, 'val_loss': 0.49137516975402834, 'test_acc': 0.73}
{'fold': 9, 'epoch': 56, 'train_loss': 0.4175563283264637, 'val_loss': 0.485625057220459, 'test_acc': 0.74}
{'fold': 9, 'epoch': 57, 'train_loss': 0.41056494787335396, 'val_loss': 0.48512747764587405, 'test_acc': 0.71}
{'fold': 9, 'epoch': 58, 'train_loss': 0.4149781301617622, 'val_loss': 0.4707009696960449, 'test_acc': 0.7}
{'fold': 9, 'epoch': 59, 'train_loss': 0.4185534939169884, 'val_loss': 0.5022678852081299, 'test_acc': 0.71}
{'fold': 9, 'epoch': 60, 'train_loss': 0.428342517465353, 'val_loss': 0.5392845249176026, 'test_acc': 0.62}
{'fold': 9, 'epoch': 61, 'train_loss': 0.4302139073610306, 'val_loss': 0.4727185821533203, 'test_acc': 0.72}
{'fold': 9, 'epoch': 62, 'train_loss': 0.41769873946905134, 'val_loss': 0.4844717025756836, 'test_acc': 0.72}
{'fold': 9, 'epoch': 63, 'train_loss': 0.3967534273862839, 'val_loss': 0.5203503513336182, 'test_acc': 0.75}
{'fold': 9, 'epoch': 64, 'train_loss': 0.40722318850457667, 'val_loss': 0.5035674953460694, 'test_acc': 0.73}
{'fold': 9, 'epoch': 65, 'train_loss': 0.4029967233538628, 'val_loss': 0.4944577407836914, 'test_acc': 0.71}
{'fold': 9, 'epoch': 66, 'train_loss': 0.40142362341284754, 'val_loss': 0.5092629623413086, 'test_acc': 0.74}
{'fold': 9, 'epoch': 67, 'train_loss': 0.38253047689795494, 'val_loss': 0.5091693878173829, 'test_acc': 0.7}
{'fold': 9, 'epoch': 68, 'train_loss': 0.3939628854393959, 'val_loss': 0.501642599105835, 'test_acc': 0.68}
{'fold': 9, 'epoch': 69, 'train_loss': 0.39458294212818146, 'val_loss': 0.4889096832275391, 'test_acc': 0.7}
{'fold': 9, 'epoch': 70, 'train_loss': 0.40076850056648256, 'val_loss': 0.4798558044433594, 'test_acc': 0.73}
{'fold': 9, 'epoch': 71, 'train_loss': 0.388263601064682, 'val_loss': 0.4901325035095215, 'test_acc': 0.71}
{'fold': 9, 'epoch': 72, 'train_loss': 0.3958163432776928, 'val_loss': 0.4820213222503662, 'test_acc': 0.74}
{'fold': 9, 'epoch': 73, 'train_loss': 0.38556191697716713, 'val_loss': 0.5140350723266601, 'test_acc': 0.7}
{'fold': 9, 'epoch': 74, 'train_loss': 0.39469481632113457, 'val_loss': 0.5252099990844726, 'test_acc': 0.69}
{'fold': 9, 'epoch': 75, 'train_loss': 0.3871121175587177, 'val_loss': 0.49442928314208984, 'test_acc': 0.72}
{'fold': 9, 'epoch': 76, 'train_loss': 0.3776314690709114, 'val_loss': 0.5108046817779541, 'test_acc': 0.73}
{'fold': 9, 'epoch': 77, 'train_loss': 0.3983168758451939, 'val_loss': 0.4989912986755371, 'test_acc': 0.72}
{'fold': 9, 'epoch': 78, 'train_loss': 0.37344184294342997, 'val_loss': 0.49611263275146483, 'test_acc': 0.69}
{'fold': 9, 'epoch': 79, 'train_loss': 0.3869385257363319, 'val_loss': 0.5302796459197998, 'test_acc': 0.72}
{'fold': 9, 'epoch': 80, 'train_loss': 0.39334348887205123, 'val_loss': 0.505317611694336, 'test_acc': 0.69}
{'fold': 9, 'epoch': 81, 'train_loss': 0.3852304980158806, 'val_loss': 0.5331826019287109, 'test_acc': 0.74}
{'fold': 9, 'epoch': 82, 'train_loss': 0.3863504283130169, 'val_loss': 0.49403584480285645, 'test_acc': 0.68}
{'fold': 9, 'epoch': 83, 'train_loss': 0.3858055159449577, 'val_loss': 0.5060592365264892, 'test_acc': 0.72}
{'fold': 9, 'epoch': 84, 'train_loss': 0.3811927728354931, 'val_loss': 0.5464805507659912, 'test_acc': 0.7}
{'fold': 9, 'epoch': 85, 'train_loss': 0.38664754033088683, 'val_loss': 0.49071081161499025, 'test_acc': 0.69}
{'fold': 9, 'epoch': 86, 'train_loss': 0.37765415459871293, 'val_loss': 0.5055514621734619, 'test_acc': 0.73}
{'fold': 9, 'epoch': 87, 'train_loss': 0.3671701617538929, 'val_loss': 0.5381944179534912, 'test_acc': 0.71}
{'fold': 9, 'epoch': 88, 'train_loss': 0.3699774228036404, 'val_loss': 0.5144452285766602, 'test_acc': 0.69}
{'fold': 9, 'epoch': 89, 'train_loss': 0.3765519980341196, 'val_loss': 0.5124142456054688, 'test_acc': 0.71}
{'fold': 9, 'epoch': 90, 'train_loss': 0.3782178983092308, 'val_loss': 0.5134911918640137, 'test_acc': 0.68}
{'fold': 9, 'epoch': 91, 'train_loss': 0.38145921379327774, 'val_loss': 0.5031992149353027, 'test_acc': 0.74}
{'fold': 9, 'epoch': 92, 'train_loss': 0.37747842222452166, 'val_loss': 0.5140671634674072, 'test_acc': 0.74}
{'fold': 9, 'epoch': 93, 'train_loss': 0.37514793798327445, 'val_loss': 0.49676177978515623, 'test_acc': 0.7}
{'fold': 9, 'epoch': 94, 'train_loss': 0.38300356864929197, 'val_loss': 0.5278300285339356, 'test_acc': 0.69}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3675845257937908, 'val_loss': 0.47184329986572265, 'test_acc': 0.7}
{'fold': 9, 'epoch': 96, 'train_loss': 0.37352274954319, 'val_loss': 0.5069840431213379, 'test_acc': 0.69}
{'fold': 9, 'epoch': 97, 'train_loss': 0.37945747673511504, 'val_loss': 0.47942185401916504, 'test_acc': 0.72}
{'fold': 9, 'epoch': 98, 'train_loss': 0.3624453715980053, 'val_loss': 0.5440668106079102, 'test_acc': 0.71}
{'fold': 9, 'epoch': 99, 'train_loss': 0.36402431726455686, 'val_loss': 0.5329043006896973, 'test_acc': 0.74}
{'fold': 9, 'epoch': 100, 'train_loss': 0.36509139090776443, 'val_loss': 0.5086314392089843, 'test_acc': 0.72}
{'fold': 9, 'epoch': 101, 'train_loss': 0.3701582118868828, 'val_loss': 0.4694293212890625, 'test_acc': 0.73}
{'fold': 9, 'epoch': 102, 'train_loss': 0.3696203351020813, 'val_loss': 0.5085104274749755, 'test_acc': 0.71}
{'fold': 9, 'epoch': 103, 'train_loss': 0.3646520771086216, 'val_loss': 0.5344012832641601, 'test_acc': 0.65}
{'fold': 9, 'epoch': 104, 'train_loss': 0.36675703078508376, 'val_loss': 0.4943038368225098, 'test_acc': 0.72}
{'fold': 9, 'epoch': 105, 'train_loss': 0.36240319833159446, 'val_loss': 0.5045454692840576, 'test_acc': 0.7}
{'fold': 9, 'epoch': 106, 'train_loss': 0.3619554676115513, 'val_loss': 0.550107593536377, 'test_acc': 0.69}
{'fold': 9, 'epoch': 107, 'train_loss': 0.3705755114555359, 'val_loss': 0.5048230934143066, 'test_acc': 0.68}
{'fold': 9, 'epoch': 108, 'train_loss': 0.35094033256173135, 'val_loss': 0.5632916736602783, 'test_acc': 0.68}
{'fold': 9, 'epoch': 109, 'train_loss': 0.3549457348883152, 'val_loss': 0.5306839847564697, 'test_acc': 0.66}
{'fold': 9, 'epoch': 110, 'train_loss': 0.3618103973567486, 'val_loss': 0.5317137241363525, 'test_acc': 0.7}
{'fold': 9, 'epoch': 111, 'train_loss': 0.3616254679858685, 'val_loss': 0.5691955661773682, 'test_acc': 0.68}
{'fold': 9, 'epoch': 112, 'train_loss': 0.3643003962934017, 'val_loss': 0.5585837936401368, 'test_acc': 0.65}
{'fold': 9, 'epoch': 113, 'train_loss': 0.341345976293087, 'val_loss': 0.5726889133453369, 'test_acc': 0.7}
{'fold': 9, 'epoch': 114, 'train_loss': 0.34812945052981376, 'val_loss': 0.5432142639160156, 'test_acc': 0.66}
{'fold': 9, 'epoch': 115, 'train_loss': 0.3446922808885574, 'val_loss': 0.5496006584167481, 'test_acc': 0.68}
{'fold': 9, 'epoch': 116, 'train_loss': 0.3399958863854408, 'val_loss': 0.5398979759216309, 'test_acc': 0.7}
{'fold': 9, 'epoch': 117, 'train_loss': 0.34732336103916167, 'val_loss': 0.554933090209961, 'test_acc': 0.72}
{'fold': 9, 'epoch': 118, 'train_loss': 0.35929999500513077, 'val_loss': 0.5574091911315918, 'test_acc': 0.68}
{'fold': 9, 'epoch': 119, 'train_loss': 0.3533428832888603, 'val_loss': 0.5769997787475586, 'test_acc': 0.69}
{'fold': 9, 'epoch': 120, 'train_loss': 0.3410432480275631, 'val_loss': 0.5826733207702637, 'test_acc': 0.71}
{'fold': 9, 'epoch': 121, 'train_loss': 0.3285739906132221, 'val_loss': 0.6113635540008545, 'test_acc': 0.7}
{'fold': 9, 'epoch': 122, 'train_loss': 0.3671082079410553, 'val_loss': 0.5184841918945312, 'test_acc': 0.67}
{'fold': 9, 'epoch': 123, 'train_loss': 0.34882498569786546, 'val_loss': 0.5801182842254639, 'test_acc': 0.69}
{'fold': 9, 'epoch': 124, 'train_loss': 0.3467190247029066, 'val_loss': 0.5478875827789307, 'test_acc': 0.71}
{'fold': 9, 'epoch': 125, 'train_loss': 0.34267406314611437, 'val_loss': 0.5565197277069092, 'test_acc': 0.71}
{'fold': 9, 'epoch': 126, 'train_loss': 0.3392026636749506, 'val_loss': 0.6078065395355224, 'test_acc': 0.69}
{'fold': 9, 'epoch': 127, 'train_loss': 0.35196464620530604, 'val_loss': 0.6092468547821045, 'test_acc': 0.71}
{'fold': 9, 'epoch': 128, 'train_loss': 0.347227830439806, 'val_loss': 0.6151107501983643, 'test_acc': 0.69}
{'fold': 9, 'epoch': 129, 'train_loss': 0.34076314941048624, 'val_loss': 0.5588368892669677, 'test_acc': 0.67}
{'fold': 9, 'epoch': 130, 'train_loss': 0.32645186223089695, 'val_loss': 0.5906300449371338, 'test_acc': 0.66}
{'fold': 9, 'epoch': 131, 'train_loss': 0.341955479606986, 'val_loss': 0.5978684425354004, 'test_acc': 0.71}
{'fold': 9, 'epoch': 132, 'train_loss': 0.3441273972392082, 'val_loss': 0.5744769382476806, 'test_acc': 0.69}
{'fold': 9, 'epoch': 133, 'train_loss': 0.3545042432844639, 'val_loss': 0.5376719856262206, 'test_acc': 0.72}
{'fold': 9, 'epoch': 134, 'train_loss': 0.3506649099290371, 'val_loss': 0.5262034797668457, 'test_acc': 0.71}
{'fold': 9, 'epoch': 135, 'train_loss': 0.3442011535167694, 'val_loss': 0.6147187423706054, 'test_acc': 0.67}
{'fold': 9, 'epoch': 136, 'train_loss': 0.34671561904251574, 'val_loss': 0.5115742301940918, 'test_acc': 0.7}
{'fold': 9, 'epoch': 137, 'train_loss': 0.35170451179146767, 'val_loss': 0.5744365215301513, 'test_acc': 0.73}
{'fold': 9, 'epoch': 138, 'train_loss': 0.35110052227973937, 'val_loss': 0.5440528392791748, 'test_acc': 0.72}
{'fold': 9, 'epoch': 139, 'train_loss': 0.34342910833656787, 'val_loss': 0.5660300922393798, 'test_acc': 0.68}
{'fold': 9, 'epoch': 140, 'train_loss': 0.3385672107338905, 'val_loss': 0.6188419151306153, 'test_acc': 0.69}
{'fold': 9, 'epoch': 141, 'train_loss': 0.3336106188595295, 'val_loss': 0.6070429611206055, 'test_acc': 0.72}
{'fold': 9, 'epoch': 142, 'train_loss': 0.3411402743309736, 'val_loss': 0.5478637409210205, 'test_acc': 0.7}
{'fold': 9, 'epoch': 143, 'train_loss': 0.3349603436887264, 'val_loss': 0.6590531730651855, 'test_acc': 0.68}
{'fold': 9, 'epoch': 144, 'train_loss': 0.3401636444032192, 'val_loss': 0.6220535850524902, 'test_acc': 0.7}
{'fold': 9, 'epoch': 145, 'train_loss': 0.32515521459281443, 'val_loss': 0.6456990814208985, 'test_acc': 0.67}
{'fold': 9, 'epoch': 146, 'train_loss': 0.3352552317082882, 'val_loss': 0.6084673595428467, 'test_acc': 0.7}
{'fold': 9, 'epoch': 147, 'train_loss': 0.34493072554469106, 'val_loss': 0.6126090335845947, 'test_acc': 0.67}
{'fold': 9, 'epoch': 148, 'train_loss': 0.3392025247216225, 'val_loss': 0.6422881031036377, 'test_acc': 0.7}
{'fold': 9, 'epoch': 149, 'train_loss': 0.3321811333298683, 'val_loss': 0.6378018283843994, 'test_acc': 0.68}
{'fold': 9, 'epoch': 150, 'train_loss': 0.32211670503020284, 'val_loss': 0.6111271381378174, 'test_acc': 0.69}
{'fold': 9, 'epoch': 151, 'train_loss': 0.3354718241840601, 'val_loss': 0.6622429943084717, 'test_acc': 0.71}
{'fold': 9, 'epoch': 152, 'train_loss': 0.3270395573228598, 'val_loss': 0.6990848350524902, 'test_acc': 0.68}
{'fold': 9, 'epoch': 153, 'train_loss': 0.3478300929069519, 'val_loss': 0.5847649002075195, 'test_acc': 0.63}
{'fold': 9, 'epoch': 154, 'train_loss': 0.3273533135652542, 'val_loss': 0.6730534553527832, 'test_acc': 0.71}
{'fold': 9, 'epoch': 155, 'train_loss': 0.3264583732932806, 'val_loss': 0.5635607528686524, 'test_acc': 0.67}
{'fold': 9, 'epoch': 156, 'train_loss': 0.3224296446889639, 'val_loss': 0.7172894811630249, 'test_acc': 0.68}
{'fold': 9, 'epoch': 157, 'train_loss': 0.3488280963152647, 'val_loss': 0.6264280128479004, 'test_acc': 0.69}
{'fold': 9, 'epoch': 158, 'train_loss': 0.3280401103198528, 'val_loss': 0.7300846672058106, 'test_acc': 0.67}
{'fold': 9, 'epoch': 159, 'train_loss': 0.31797556541860106, 'val_loss': 0.6851016998291015, 'test_acc': 0.68}
{'fold': 9, 'epoch': 160, 'train_loss': 0.3286635775119066, 'val_loss': 0.6351227569580078, 'test_acc': 0.7}
{'fold': 9, 'epoch': 161, 'train_loss': 0.3254930701106787, 'val_loss': 0.6981396579742432, 'test_acc': 0.69}
{'fold': 9, 'epoch': 162, 'train_loss': 0.3292633034288883, 'val_loss': 0.6275393676757812, 'test_acc': 0.7}
{'fold': 9, 'epoch': 163, 'train_loss': 0.3242921020835638, 'val_loss': 0.7093818473815918, 'test_acc': 0.69}
{'fold': 9, 'epoch': 164, 'train_loss': 0.3073826402425766, 'val_loss': 0.618450584411621, 'test_acc': 0.7}
{'fold': 9, 'epoch': 165, 'train_loss': 0.3318568989634514, 'val_loss': 0.573310308456421, 'test_acc': 0.72}
{'fold': 9, 'epoch': 166, 'train_loss': 0.3285220094025135, 'val_loss': 0.6498730373382569, 'test_acc': 0.72}
{'fold': 9, 'epoch': 167, 'train_loss': 0.3140447840094566, 'val_loss': 0.6566874122619629, 'test_acc': 0.67}
{'fold': 9, 'epoch': 168, 'train_loss': 0.3146268703043461, 'val_loss': 0.7315700054168701, 'test_acc': 0.71}
{'fold': 9, 'epoch': 169, 'train_loss': 0.31854418069124224, 'val_loss': 0.6527405643463134, 'test_acc': 0.68}
{'fold': 9, 'epoch': 170, 'train_loss': 0.3244544852524996, 'val_loss': 0.6540348625183106, 'test_acc': 0.71}
{'fold': 9, 'epoch': 171, 'train_loss': 0.3167925950139761, 'val_loss': 0.6783744144439697, 'test_acc': 0.71}
{'fold': 9, 'epoch': 172, 'train_loss': 0.29872464314103125, 'val_loss': 0.6598204231262207, 'test_acc': 0.68}
{'fold': 9, 'epoch': 173, 'train_loss': 0.31688900887966154, 'val_loss': 0.7292718315124511, 'test_acc': 0.73}
{'fold': 9, 'epoch': 174, 'train_loss': 0.31403238959610463, 'val_loss': 0.6716359996795654, 'test_acc': 0.72}
{'fold': 9, 'epoch': 175, 'train_loss': 0.37261146008968354, 'val_loss': 0.490206298828125, 'test_acc': 0.61}
{'fold': 9, 'epoch': 176, 'train_loss': 0.3388478718698025, 'val_loss': 0.6215865421295166, 'test_acc': 0.68}
{'fold': 9, 'epoch': 177, 'train_loss': 0.31713011488318443, 'val_loss': 0.6624152374267578, 'test_acc': 0.68}
{'fold': 9, 'epoch': 178, 'train_loss': 0.3310952253639698, 'val_loss': 0.6788446426391601, 'test_acc': 0.68}
{'fold': 9, 'epoch': 179, 'train_loss': 0.3050832532346249, 'val_loss': 0.697202091217041, 'test_acc': 0.71}
{'fold': 9, 'epoch': 180, 'train_loss': 0.3043772004544735, 'val_loss': 0.7355564880371094, 'test_acc': 0.68}
{'fold': 9, 'epoch': 181, 'train_loss': 0.3073097221553326, 'val_loss': 0.7301918029785156, 'test_acc': 0.67}
{'fold': 9, 'epoch': 182, 'train_loss': 0.315973225235939, 'val_loss': 0.6672604560852051, 'test_acc': 0.72}
{'fold': 9, 'epoch': 183, 'train_loss': 0.3083075225353241, 'val_loss': 0.6924984741210938, 'test_acc': 0.7}
{'fold': 9, 'epoch': 184, 'train_loss': 0.3038211714476347, 'val_loss': 0.7425056838989258, 'test_acc': 0.72}
{'fold': 9, 'epoch': 185, 'train_loss': 0.3107677549123764, 'val_loss': 0.7656580448150635, 'test_acc': 0.71}
{'fold': 9, 'epoch': 186, 'train_loss': 0.3037709180265665, 'val_loss': 0.7280001926422119, 'test_acc': 0.72}
{'fold': 9, 'epoch': 187, 'train_loss': 0.30655675306916236, 'val_loss': 0.7822937393188476, 'test_acc': 0.73}
{'fold': 9, 'epoch': 188, 'train_loss': 0.2998519890010357, 'val_loss': 0.7586971473693848, 'test_acc': 0.73}
{'fold': 9, 'epoch': 189, 'train_loss': 0.3121882684528828, 'val_loss': 0.6911928939819336, 'test_acc': 0.69}
{'fold': 9, 'epoch': 190, 'train_loss': 0.3155351862311363, 'val_loss': 0.5806435394287109, 'test_acc': 0.67}
{'fold': 9, 'epoch': 191, 'train_loss': 0.31173101514577867, 'val_loss': 0.7154121589660645, 'test_acc': 0.69}
{'fold': 9, 'epoch': 192, 'train_loss': 0.31895360313355925, 'val_loss': 0.7402753925323486, 'test_acc': 0.73}
{'fold': 9, 'epoch': 193, 'train_loss': 0.3036388874053955, 'val_loss': 0.6907168197631836, 'test_acc': 0.68}
{'fold': 9, 'epoch': 194, 'train_loss': 0.2991445899009705, 'val_loss': 0.6661740684509277, 'test_acc': 0.69}
{'fold': 9, 'epoch': 195, 'train_loss': 0.31435582265257833, 'val_loss': 0.6926025199890137, 'test_acc': 0.72}
{'fold': 9, 'epoch': 196, 'train_loss': 0.2847233060747385, 'val_loss': 0.7771173477172851, 'test_acc': 0.72}
{'fold': 9, 'epoch': 197, 'train_loss': 0.3171589970588684, 'val_loss': 0.6561097240447998, 'test_acc': 0.71}
{'fold': 9, 'epoch': 198, 'train_loss': 0.3184575326740742, 'val_loss': 0.6387465286254883, 'test_acc': 0.72}
{'fold': 9, 'epoch': 199, 'train_loss': 0.3092154983431101, 'val_loss': 0.7595615005493164, 'test_acc': 0.69}
{'fold': 9, 'epoch': 200, 'train_loss': 0.29743805825710296, 'val_loss': 0.798953161239624, 'test_acc': 0.7}
Val Loss: 0.4739, Test Accuracy: 0.736 ± 0.041, Duration: 76.191
Best result - 0.736 ± 0.041
--
REDDIT-BINARY - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.636240703612566, 'val_loss': 0.5809200024604797, 'test_acc': 0.73}
{'fold': 9, 'epoch': 2, 'train_loss': 0.560037524998188, 'val_loss': 0.5271607971191407, 'test_acc': 0.785}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5334577977657318, 'val_loss': 0.5158531510829926, 'test_acc': 0.785}
{'fold': 9, 'epoch': 4, 'train_loss': 0.525820679962635, 'val_loss': 0.5032717323303223, 'test_acc': 0.785}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5041988290846348, 'val_loss': 0.473902587890625, 'test_acc': 0.785}
{'fold': 9, 'epoch': 6, 'train_loss': 0.4703696221113205, 'val_loss': 0.4191837739944458, 'test_acc': 0.81}
{'fold': 9, 'epoch': 7, 'train_loss': 0.39311235919594767, 'val_loss': 0.34756770491600036, 'test_acc': 0.82}
{'fold': 9, 'epoch': 8, 'train_loss': 0.369543788023293, 'val_loss': 0.3301720416545868, 'test_acc': 0.805}
{'fold': 9, 'epoch': 9, 'train_loss': 0.3450145035982132, 'val_loss': 0.32143556952476504, 'test_acc': 0.85}
{'fold': 9, 'epoch': 10, 'train_loss': 0.33563196323812006, 'val_loss': 0.3026785242557526, 'test_acc': 0.845}
{'fold': 9, 'epoch': 11, 'train_loss': 0.3164380773901939, 'val_loss': 0.3535936450958252, 'test_acc': 0.815}
{'fold': 9, 'epoch': 12, 'train_loss': 0.32153149619698523, 'val_loss': 0.2877156567573547, 'test_acc': 0.885}
{'fold': 9, 'epoch': 13, 'train_loss': 0.2934305191040039, 'val_loss': 0.26361348271369933, 'test_acc': 0.87}
{'fold': 9, 'epoch': 14, 'train_loss': 0.31634656731039285, 'val_loss': 0.3201952588558197, 'test_acc': 0.845}
{'fold': 9, 'epoch': 15, 'train_loss': 0.3043458925560117, 'val_loss': 0.2671738016605377, 'test_acc': 0.855}
{'fold': 9, 'epoch': 16, 'train_loss': 0.2888927137479186, 'val_loss': 0.2723881816864014, 'test_acc': 0.89}
{'fold': 9, 'epoch': 17, 'train_loss': 0.28279009740799665, 'val_loss': 0.3004473352432251, 'test_acc': 0.865}
{'fold': 9, 'epoch': 18, 'train_loss': 0.28249162845313547, 'val_loss': 0.2539647662639618, 'test_acc': 0.865}
{'fold': 9, 'epoch': 19, 'train_loss': 0.26761044953018426, 'val_loss': 0.2991773533821106, 'test_acc': 0.86}
{'fold': 9, 'epoch': 20, 'train_loss': 0.26464673429727553, 'val_loss': 0.2656006681919098, 'test_acc': 0.895}
{'fold': 9, 'epoch': 21, 'train_loss': 0.2446315674111247, 'val_loss': 0.2951047372817993, 'test_acc': 0.855}
{'fold': 9, 'epoch': 22, 'train_loss': 0.24700177945196627, 'val_loss': 0.23919093132019043, 'test_acc': 0.89}
{'fold': 9, 'epoch': 23, 'train_loss': 0.23949741143733264, 'val_loss': 0.24603784561157227, 'test_acc': 0.895}
{'fold': 9, 'epoch': 24, 'train_loss': 0.2419663852080703, 'val_loss': 0.2718128877878189, 'test_acc': 0.895}
{'fold': 9, 'epoch': 25, 'train_loss': 0.2412780810147524, 'val_loss': 0.2980090737342834, 'test_acc': 0.875}
{'fold': 9, 'epoch': 26, 'train_loss': 0.22606833828613163, 'val_loss': 0.2336091160774231, 'test_acc': 0.89}
{'fold': 9, 'epoch': 27, 'train_loss': 0.21389253344386816, 'val_loss': 0.34862125396728516, 'test_acc': 0.835}
{'fold': 9, 'epoch': 28, 'train_loss': 0.22064929977059364, 'val_loss': 0.2943477344512939, 'test_acc': 0.88}
{'fold': 9, 'epoch': 29, 'train_loss': 0.21503482526168227, 'val_loss': 0.22263284921646118, 'test_acc': 0.895}
{'fold': 9, 'epoch': 30, 'train_loss': 0.2112539046443999, 'val_loss': 0.3325393068790436, 'test_acc': 0.855}
{'fold': 9, 'epoch': 31, 'train_loss': 0.22236292585730552, 'val_loss': 0.30884689927101133, 'test_acc': 0.86}
{'fold': 9, 'epoch': 32, 'train_loss': 0.21562187997624277, 'val_loss': 0.27737626671791077, 'test_acc': 0.865}
{'fold': 9, 'epoch': 33, 'train_loss': 0.21277318047359586, 'val_loss': 0.21407375812530519, 'test_acc': 0.895}
{'fold': 9, 'epoch': 34, 'train_loss': 0.19648600406944752, 'val_loss': 0.28227843046188356, 'test_acc': 0.885}
{'fold': 9, 'epoch': 35, 'train_loss': 0.2005810523405671, 'val_loss': 0.23421805143356322, 'test_acc': 0.9}
{'fold': 9, 'epoch': 36, 'train_loss': 0.1831558587960899, 'val_loss': 0.2683599543571472, 'test_acc': 0.895}
{'fold': 9, 'epoch': 37, 'train_loss': 0.1865566092543304, 'val_loss': 0.22925457239151, 'test_acc': 0.89}
{'fold': 9, 'epoch': 38, 'train_loss': 0.19008161975070834, 'val_loss': 0.2674993491172791, 'test_acc': 0.89}
{'fold': 9, 'epoch': 39, 'train_loss': 0.19121019067242742, 'val_loss': 0.2997767543792725, 'test_acc': 0.865}
{'fold': 9, 'epoch': 40, 'train_loss': 0.1992960125207901, 'val_loss': 0.2341753900051117, 'test_acc': 0.905}
{'fold': 9, 'epoch': 41, 'train_loss': 0.2049786577001214, 'val_loss': 0.2825055813789368, 'test_acc': 0.885}
{'fold': 9, 'epoch': 42, 'train_loss': 0.18821503277868032, 'val_loss': 0.2696379160881042, 'test_acc': 0.89}
{'fold': 9, 'epoch': 43, 'train_loss': 0.1821692619472742, 'val_loss': 0.2925431799888611, 'test_acc': 0.88}
{'fold': 9, 'epoch': 44, 'train_loss': 0.16774363303557038, 'val_loss': 0.2242070245742798, 'test_acc': 0.905}
{'fold': 9, 'epoch': 45, 'train_loss': 0.1853554026223719, 'val_loss': 0.25853178977966307, 'test_acc': 0.88}
{'fold': 9, 'epoch': 46, 'train_loss': 0.172051121853292, 'val_loss': 0.23016048431396485, 'test_acc': 0.91}
{'fold': 9, 'epoch': 47, 'train_loss': 0.17070286134257912, 'val_loss': 0.3082840955257416, 'test_acc': 0.895}
{'fold': 9, 'epoch': 48, 'train_loss': 0.1813777083531022, 'val_loss': 0.24887365102767944, 'test_acc': 0.88}
{'fold': 9, 'epoch': 49, 'train_loss': 0.1806718952022493, 'val_loss': 0.24638302326202394, 'test_acc': 0.895}
{'fold': 9, 'epoch': 50, 'train_loss': 0.1609098993241787, 'val_loss': 0.25186221837997436, 'test_acc': 0.895}
{'fold': 9, 'epoch': 51, 'train_loss': 0.16585654811933637, 'val_loss': 0.2537333846092224, 'test_acc': 0.9}
{'fold': 9, 'epoch': 52, 'train_loss': 0.15791906472295522, 'val_loss': 0.2711587738990784, 'test_acc': 0.89}
{'fold': 9, 'epoch': 53, 'train_loss': 0.16068406938575208, 'val_loss': 0.2427062201499939, 'test_acc': 0.89}
{'fold': 9, 'epoch': 54, 'train_loss': 0.16852473309263588, 'val_loss': 0.2622331881523132, 'test_acc': 0.9}
{'fold': 9, 'epoch': 55, 'train_loss': 0.17179750576615332, 'val_loss': 0.25984615564346314, 'test_acc': 0.92}
{'fold': 9, 'epoch': 56, 'train_loss': 0.16374468039721252, 'val_loss': 0.24447262287139893, 'test_acc': 0.9}
{'fold': 9, 'epoch': 57, 'train_loss': 0.15238245781511067, 'val_loss': 0.22688597679138184, 'test_acc': 0.915}
{'fold': 9, 'epoch': 58, 'train_loss': 0.17449556654319168, 'val_loss': 0.32986069440841675, 'test_acc': 0.865}
{'fold': 9, 'epoch': 59, 'train_loss': 0.14889498362317682, 'val_loss': 0.2989945387840271, 'test_acc': 0.885}
{'fold': 9, 'epoch': 60, 'train_loss': 0.16331658279523253, 'val_loss': 0.2671464800834656, 'test_acc': 0.9}
{'fold': 9, 'epoch': 61, 'train_loss': 0.15438493024557828, 'val_loss': 0.27327374696731566, 'test_acc': 0.9}
{'fold': 9, 'epoch': 62, 'train_loss': 0.15336639741435648, 'val_loss': 0.31002278804779054, 'test_acc': 0.88}
{'fold': 9, 'epoch': 63, 'train_loss': 0.15185787798836828, 'val_loss': 0.3423652648925781, 'test_acc': 0.875}
{'fold': 9, 'epoch': 64, 'train_loss': 0.16214524917304515, 'val_loss': 0.2501820397377014, 'test_acc': 0.9}
{'fold': 9, 'epoch': 65, 'train_loss': 0.13950981246307492, 'val_loss': 0.3233821415901184, 'test_acc': 0.89}
{'fold': 9, 'epoch': 66, 'train_loss': 0.14659184319898486, 'val_loss': 0.2961443281173706, 'test_acc': 0.895}
{'fold': 9, 'epoch': 67, 'train_loss': 0.15715659661218523, 'val_loss': 0.28389476537704467, 'test_acc': 0.9}
{'fold': 9, 'epoch': 68, 'train_loss': 0.16289135329425336, 'val_loss': 0.2652525568008423, 'test_acc': 0.895}
{'fold': 9, 'epoch': 69, 'train_loss': 0.15397025090642275, 'val_loss': 0.2988141107559204, 'test_acc': 0.9}
{'fold': 9, 'epoch': 70, 'train_loss': 0.17071907520294188, 'val_loss': 0.2459134888648987, 'test_acc': 0.91}
{'fold': 9, 'epoch': 71, 'train_loss': 0.14548219833523035, 'val_loss': 0.26758517742156984, 'test_acc': 0.89}
{'fold': 9, 'epoch': 72, 'train_loss': 0.14448490934446453, 'val_loss': 0.2654409408569336, 'test_acc': 0.895}
{'fold': 9, 'epoch': 73, 'train_loss': 0.12958399062044917, 'val_loss': 0.2682016396522522, 'test_acc': 0.895}
{'fold': 9, 'epoch': 74, 'train_loss': 0.1448607739061117, 'val_loss': 0.2961209058761597, 'test_acc': 0.89}
{'fold': 9, 'epoch': 75, 'train_loss': 0.15021079098805784, 'val_loss': 0.2990948939323425, 'test_acc': 0.885}
{'fold': 9, 'epoch': 76, 'train_loss': 0.1388899581041187, 'val_loss': 0.338060040473938, 'test_acc': 0.885}
{'fold': 9, 'epoch': 77, 'train_loss': 0.1766374814324081, 'val_loss': 0.24981556415557862, 'test_acc': 0.905}
{'fold': 9, 'epoch': 78, 'train_loss': 0.15012391065247357, 'val_loss': 0.2717706060409546, 'test_acc': 0.885}
{'fold': 9, 'epoch': 79, 'train_loss': 0.1487332738470286, 'val_loss': 0.25595165967941286, 'test_acc': 0.895}
{'fold': 9, 'epoch': 80, 'train_loss': 0.13923912388272583, 'val_loss': 0.27021992206573486, 'test_acc': 0.9}
{'fold': 9, 'epoch': 81, 'train_loss': 0.14627478262409568, 'val_loss': 0.43827258110046385, 'test_acc': 0.875}
{'fold': 9, 'epoch': 82, 'train_loss': 0.15418216898106038, 'val_loss': 0.2748749232292175, 'test_acc': 0.91}
{'fold': 9, 'epoch': 83, 'train_loss': 0.13675646102055908, 'val_loss': 0.2542573642730713, 'test_acc': 0.895}
{'fold': 9, 'epoch': 84, 'train_loss': 0.12913064705207944, 'val_loss': 0.28036692142486574, 'test_acc': 0.9}
{'fold': 9, 'epoch': 85, 'train_loss': 0.1390857260674238, 'val_loss': 0.28368053913116453, 'test_acc': 0.9}
{'fold': 9, 'epoch': 86, 'train_loss': 0.13921589301899076, 'val_loss': 0.3313888454437256, 'test_acc': 0.89}
{'fold': 9, 'epoch': 87, 'train_loss': 0.1284923565108329, 'val_loss': 0.3144772863388062, 'test_acc': 0.905}
{'fold': 9, 'epoch': 88, 'train_loss': 0.1307935901917517, 'val_loss': 0.24417695999145508, 'test_acc': 0.915}
{'fold': 9, 'epoch': 89, 'train_loss': 0.12984101767651737, 'val_loss': 0.32838126420974734, 'test_acc': 0.905}
{'fold': 9, 'epoch': 90, 'train_loss': 0.13130437075160445, 'val_loss': 0.433414192199707, 'test_acc': 0.86}
{'fold': 9, 'epoch': 91, 'train_loss': 0.1365494292229414, 'val_loss': 0.26340617179870607, 'test_acc': 0.895}
{'fold': 9, 'epoch': 92, 'train_loss': 0.11640249225310981, 'val_loss': 0.34920186519622803, 'test_acc': 0.89}
{'fold': 9, 'epoch': 93, 'train_loss': 0.11924879248254001, 'val_loss': 0.3355177927017212, 'test_acc': 0.89}
{'fold': 9, 'epoch': 94, 'train_loss': 0.12360601015388965, 'val_loss': 0.3551848554611206, 'test_acc': 0.89}
{'fold': 9, 'epoch': 95, 'train_loss': 0.1290513828396797, 'val_loss': 0.29504761219024656, 'test_acc': 0.895}
{'fold': 9, 'epoch': 96, 'train_loss': 0.12393264509737492, 'val_loss': 0.3642239451408386, 'test_acc': 0.89}
{'fold': 9, 'epoch': 97, 'train_loss': 0.12072442206554115, 'val_loss': 0.3367716717720032, 'test_acc': 0.9}
{'fold': 9, 'epoch': 98, 'train_loss': 0.11649438915774227, 'val_loss': 0.2953302311897278, 'test_acc': 0.895}
{'fold': 9, 'epoch': 99, 'train_loss': 0.1334741938393563, 'val_loss': 0.40540447950363157, 'test_acc': 0.88}
{'fold': 9, 'epoch': 100, 'train_loss': 0.13354530732613057, 'val_loss': 0.37812989234924316, 'test_acc': 0.835}
{'fold': 9, 'epoch': 101, 'train_loss': 0.14215108631178736, 'val_loss': 0.23368587970733642, 'test_acc': 0.915}
{'fold': 9, 'epoch': 102, 'train_loss': 0.12393906377255917, 'val_loss': 0.2756582951545715, 'test_acc': 0.9}
{'fold': 9, 'epoch': 103, 'train_loss': 0.12173669068142771, 'val_loss': 0.28970248222351075, 'test_acc': 0.92}
{'fold': 9, 'epoch': 104, 'train_loss': 0.12142477459274233, 'val_loss': 0.29551383495330813, 'test_acc': 0.915}
{'fold': 9, 'epoch': 105, 'train_loss': 0.10925276323687286, 'val_loss': 0.29465301513671877, 'test_acc': 0.9}
{'fold': 9, 'epoch': 106, 'train_loss': 0.12169253313913941, 'val_loss': 0.2781290102005005, 'test_acc': 0.875}
{'fold': 9, 'epoch': 107, 'train_loss': 0.12335044229403139, 'val_loss': 0.2683438777923584, 'test_acc': 0.905}
{'fold': 9, 'epoch': 108, 'train_loss': 0.11131355003453791, 'val_loss': 0.32198720455169677, 'test_acc': 0.91}
{'fold': 9, 'epoch': 109, 'train_loss': 0.12022154983133078, 'val_loss': 0.27031137466430666, 'test_acc': 0.9}
{'fold': 9, 'epoch': 110, 'train_loss': 0.11488435193896293, 'val_loss': 0.36189000129699705, 'test_acc': 0.885}
{'fold': 9, 'epoch': 111, 'train_loss': 0.11945197791792453, 'val_loss': 0.2742774248123169, 'test_acc': 0.895}
{'fold': 9, 'epoch': 112, 'train_loss': 0.10256957532837988, 'val_loss': 0.3138856029510498, 'test_acc': 0.905}
{'fold': 9, 'epoch': 113, 'train_loss': 0.10646234792657197, 'val_loss': 0.30657012939453127, 'test_acc': 0.89}
{'fold': 9, 'epoch': 114, 'train_loss': 0.1157896236050874, 'val_loss': 0.2507424640655518, 'test_acc': 0.93}
{'fold': 9, 'epoch': 115, 'train_loss': 0.12609367901459337, 'val_loss': 0.2779589033126831, 'test_acc': 0.92}
{'fold': 9, 'epoch': 116, 'train_loss': 0.120653090858832, 'val_loss': 0.2920256519317627, 'test_acc': 0.91}
{'fold': 9, 'epoch': 117, 'train_loss': 0.11119312224909664, 'val_loss': 0.3277126431465149, 'test_acc': 0.9}
{'fold': 9, 'epoch': 118, 'train_loss': 0.11127344681881368, 'val_loss': 0.2836840271949768, 'test_acc': 0.915}
{'fold': 9, 'epoch': 119, 'train_loss': 0.09987959081772715, 'val_loss': 0.28180977821350095, 'test_acc': 0.91}
{'fold': 9, 'epoch': 120, 'train_loss': 0.10775484424084425, 'val_loss': 0.2653210639953613, 'test_acc': 0.92}
{'fold': 9, 'epoch': 121, 'train_loss': 0.10718716357368976, 'val_loss': 0.2714504623413086, 'test_acc': 0.925}
{'fold': 9, 'epoch': 122, 'train_loss': 0.10941503318026662, 'val_loss': 0.3808764910697937, 'test_acc': 0.885}
{'fold': 9, 'epoch': 123, 'train_loss': 0.09845412557478994, 'val_loss': 0.3069050049781799, 'test_acc': 0.91}
{'fold': 9, 'epoch': 124, 'train_loss': 0.09468923583626747, 'val_loss': 0.3090242862701416, 'test_acc': 0.91}
{'fold': 9, 'epoch': 125, 'train_loss': 0.10954224481247365, 'val_loss': 0.31009117603302, 'test_acc': 0.9}
{'fold': 9, 'epoch': 126, 'train_loss': 0.09615885186940432, 'val_loss': 0.3136114597320557, 'test_acc': 0.88}
{'fold': 9, 'epoch': 127, 'train_loss': 0.08980266712605953, 'val_loss': 0.3248254680633545, 'test_acc': 0.89}
{'fold': 9, 'epoch': 128, 'train_loss': 0.10983173144049943, 'val_loss': 0.3733243441581726, 'test_acc': 0.905}
{'fold': 9, 'epoch': 129, 'train_loss': 0.10033827195875347, 'val_loss': 0.2522768068313599, 'test_acc': 0.885}
{'fold': 9, 'epoch': 130, 'train_loss': 0.10514943406451494, 'val_loss': 0.282436306476593, 'test_acc': 0.9}
{'fold': 9, 'epoch': 131, 'train_loss': 0.10095652677118779, 'val_loss': 0.28317076444625855, 'test_acc': 0.895}
{'fold': 9, 'epoch': 132, 'train_loss': 0.09885994694195688, 'val_loss': 0.2843670630455017, 'test_acc': 0.905}
{'fold': 9, 'epoch': 133, 'train_loss': 0.09033291200175882, 'val_loss': 0.3004327297210693, 'test_acc': 0.91}
{'fold': 9, 'epoch': 134, 'train_loss': 0.10212640876416117, 'val_loss': 0.3312900137901306, 'test_acc': 0.895}
{'fold': 9, 'epoch': 135, 'train_loss': 0.10356977947521954, 'val_loss': 0.28311938762664796, 'test_acc': 0.885}
{'fold': 9, 'epoch': 136, 'train_loss': 0.09446317865513265, 'val_loss': 0.29664370536804197, 'test_acc': 0.9}
{'fold': 9, 'epoch': 137, 'train_loss': 0.10799904901068658, 'val_loss': 0.2721704912185669, 'test_acc': 0.93}
{'fold': 9, 'epoch': 138, 'train_loss': 0.09361686315387488, 'val_loss': 0.3520965528488159, 'test_acc': 0.9}
{'fold': 9, 'epoch': 139, 'train_loss': 0.09312814597506076, 'val_loss': 0.3088979148864746, 'test_acc': 0.915}
{'fold': 9, 'epoch': 140, 'train_loss': 0.11144352438859642, 'val_loss': 0.3068231558799744, 'test_acc': 0.895}
{'fold': 9, 'epoch': 141, 'train_loss': 0.1046169079374522, 'val_loss': 0.2763416910171509, 'test_acc': 0.915}
{'fold': 9, 'epoch': 142, 'train_loss': 0.09532555206678808, 'val_loss': 0.38140272855758667, 'test_acc': 0.9}
{'fold': 9, 'epoch': 143, 'train_loss': 0.07945022177882492, 'val_loss': 0.2851226234436035, 'test_acc': 0.925}
{'fold': 9, 'epoch': 144, 'train_loss': 0.09479006591718644, 'val_loss': 0.3952778387069702, 'test_acc': 0.89}
{'fold': 9, 'epoch': 145, 'train_loss': 0.11962310941889882, 'val_loss': 0.29563156604766844, 'test_acc': 0.87}
{'fold': 9, 'epoch': 146, 'train_loss': 0.10045000361278653, 'val_loss': 0.31672871112823486, 'test_acc': 0.915}
{'fold': 9, 'epoch': 147, 'train_loss': 0.09268864984624088, 'val_loss': 0.3204803466796875, 'test_acc': 0.92}
{'fold': 9, 'epoch': 148, 'train_loss': 0.08970621475018561, 'val_loss': 0.330957727432251, 'test_acc': 0.905}
{'fold': 9, 'epoch': 149, 'train_loss': 0.10833158236928284, 'val_loss': 0.301743655204773, 'test_acc': 0.91}
{'fold': 9, 'epoch': 150, 'train_loss': 0.09188186551909894, 'val_loss': 0.3238591527938843, 'test_acc': 0.91}
{'fold': 9, 'epoch': 151, 'train_loss': 0.09091997416689993, 'val_loss': 0.3371280765533447, 'test_acc': 0.91}
{'fold': 9, 'epoch': 152, 'train_loss': 0.08833172526210546, 'val_loss': 0.3243438816070557, 'test_acc': 0.9}
{'fold': 9, 'epoch': 153, 'train_loss': 0.0856781174428761, 'val_loss': 0.31016829013824465, 'test_acc': 0.925}
{'fold': 9, 'epoch': 154, 'train_loss': 0.10049301947001368, 'val_loss': 0.32484289646148684, 'test_acc': 0.905}
{'fold': 9, 'epoch': 155, 'train_loss': 0.08555324538610876, 'val_loss': 0.31085519790649413, 'test_acc': 0.91}
{'fold': 9, 'epoch': 156, 'train_loss': 0.08849919051863253, 'val_loss': 0.26914679527282714, 'test_acc': 0.925}
{'fold': 9, 'epoch': 157, 'train_loss': 0.09432275139261037, 'val_loss': 0.32399444818496703, 'test_acc': 0.915}
{'fold': 9, 'epoch': 158, 'train_loss': 0.10001469640992582, 'val_loss': 0.31910645961761475, 'test_acc': 0.925}
{'fold': 9, 'epoch': 159, 'train_loss': 0.09234868846833706, 'val_loss': 0.3902952408790588, 'test_acc': 0.895}
{'fold': 9, 'epoch': 160, 'train_loss': 0.10284909065812826, 'val_loss': 0.30696428298950196, 'test_acc': 0.915}
{'fold': 9, 'epoch': 161, 'train_loss': 0.0837826224276796, 'val_loss': 0.4040095567703247, 'test_acc': 0.885}
{'fold': 9, 'epoch': 162, 'train_loss': 0.0886949519161135, 'val_loss': 0.3189201021194458, 'test_acc': 0.92}
{'fold': 9, 'epoch': 163, 'train_loss': 0.08474515257403255, 'val_loss': 0.3619350528717041, 'test_acc': 0.925}
{'fold': 9, 'epoch': 164, 'train_loss': 0.08456352225039154, 'val_loss': 0.41693533420562745, 'test_acc': 0.905}
{'fold': 9, 'epoch': 165, 'train_loss': 0.0802354181651026, 'val_loss': 0.36731881618499757, 'test_acc': 0.89}
{'fold': 9, 'epoch': 166, 'train_loss': 0.073915462102741, 'val_loss': 0.3313274908065796, 'test_acc': 0.91}
{'fold': 9, 'epoch': 167, 'train_loss': 0.07739078735467046, 'val_loss': 0.39488390445709226, 'test_acc': 0.89}
{'fold': 9, 'epoch': 168, 'train_loss': 0.08266445300541818, 'val_loss': 0.3515468978881836, 'test_acc': 0.915}
{'fold': 9, 'epoch': 169, 'train_loss': 0.0738367700134404, 'val_loss': 0.34664360523223875, 'test_acc': 0.92}
{'fold': 9, 'epoch': 170, 'train_loss': 0.08058675063075497, 'val_loss': 0.353927047252655, 'test_acc': 0.905}
{'fold': 9, 'epoch': 171, 'train_loss': 0.08354343834798783, 'val_loss': 0.2882900810241699, 'test_acc': 0.92}
{'fold': 9, 'epoch': 172, 'train_loss': 0.10127478819340467, 'val_loss': 0.31107842922210693, 'test_acc': 0.905}
{'fold': 9, 'epoch': 173, 'train_loss': 0.09185734444763512, 'val_loss': 0.28320995807647703, 'test_acc': 0.93}
{'fold': 9, 'epoch': 174, 'train_loss': 0.08041808675043285, 'val_loss': 0.33536776542663577, 'test_acc': 0.91}
{'fold': 9, 'epoch': 175, 'train_loss': 0.07983681982150301, 'val_loss': 0.3566707539558411, 'test_acc': 0.915}
{'fold': 9, 'epoch': 176, 'train_loss': 0.07696909087244422, 'val_loss': 0.36158462524414064, 'test_acc': 0.895}
{'fold': 9, 'epoch': 177, 'train_loss': 0.0823251533554867, 'val_loss': 0.32813220739364624, 'test_acc': 0.915}
{'fold': 9, 'epoch': 178, 'train_loss': 0.07155856580939143, 'val_loss': 0.34170007705688477, 'test_acc': 0.915}
{'fold': 9, 'epoch': 179, 'train_loss': 0.08136363465455361, 'val_loss': 0.35435713529586793, 'test_acc': 0.915}
{'fold': 9, 'epoch': 180, 'train_loss': 0.08123217339161784, 'val_loss': 0.32328525066375735, 'test_acc': 0.92}
{'fold': 9, 'epoch': 181, 'train_loss': 0.07697197040542961, 'val_loss': 0.392559814453125, 'test_acc': 0.915}
{'fold': 9, 'epoch': 182, 'train_loss': 0.07535099325468764, 'val_loss': 0.39685358047485353, 'test_acc': 0.93}
{'fold': 9, 'epoch': 183, 'train_loss': 0.08610183340497315, 'val_loss': 0.3198098850250244, 'test_acc': 0.92}
{'fold': 9, 'epoch': 184, 'train_loss': 0.07952476928476244, 'val_loss': 0.3663198399543762, 'test_acc': 0.91}
{'fold': 9, 'epoch': 185, 'train_loss': 0.07820781557820737, 'val_loss': 0.35074726104736326, 'test_acc': 0.915}
{'fold': 9, 'epoch': 186, 'train_loss': 0.07753807171247899, 'val_loss': 0.32204570293426515, 'test_acc': 0.925}
{'fold': 9, 'epoch': 187, 'train_loss': 0.07506682804087177, 'val_loss': 0.3754804039001465, 'test_acc': 0.91}
{'fold': 9, 'epoch': 188, 'train_loss': 0.07636866951652337, 'val_loss': 0.37757821798324587, 'test_acc': 0.915}
{'fold': 9, 'epoch': 189, 'train_loss': 0.08052317786496133, 'val_loss': 0.32605561017990115, 'test_acc': 0.92}
{'fold': 9, 'epoch': 190, 'train_loss': 0.07376973831560463, 'val_loss': 0.31707355499267575, 'test_acc': 0.93}
{'fold': 9, 'epoch': 191, 'train_loss': 0.0794262088369578, 'val_loss': 0.38887666702270507, 'test_acc': 0.91}
{'fold': 9, 'epoch': 192, 'train_loss': 0.08856499844696372, 'val_loss': 0.32002485275268555, 'test_acc': 0.925}
{'fold': 9, 'epoch': 193, 'train_loss': 0.06620546488557011, 'val_loss': 0.31659910202026365, 'test_acc': 0.925}
{'fold': 9, 'epoch': 194, 'train_loss': 0.07065471056848764, 'val_loss': 0.3094251799583435, 'test_acc': 0.92}
{'fold': 9, 'epoch': 195, 'train_loss': 0.0756878815824166, 'val_loss': 0.30866859674453734, 'test_acc': 0.93}
{'fold': 9, 'epoch': 196, 'train_loss': 0.09052523158024997, 'val_loss': 0.31988996505737305, 'test_acc': 0.925}
{'fold': 9, 'epoch': 197, 'train_loss': 0.07143672676756978, 'val_loss': 0.403936972618103, 'test_acc': 0.91}
{'fold': 9, 'epoch': 198, 'train_loss': 0.061040602857246995, 'val_loss': 0.35690568923950194, 'test_acc': 0.93}
{'fold': 9, 'epoch': 199, 'train_loss': 0.07667287194635719, 'val_loss': 0.3767783975601196, 'test_acc': 0.925}
{'fold': 9, 'epoch': 200, 'train_loss': 0.07744008630979807, 'val_loss': 0.32628349781036375, 'test_acc': 0.93}
Val Loss: 0.2941, Test Accuracy: 0.878 ± 0.026, Duration: 202.226
Best result - 0.878 ± 0.026
--
DD - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6797258540735407, 'val_loss': 0.6591798016148754, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6227113541405079, 'val_loss': 0.5665040138440255, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5601172622735218, 'val_loss': 0.5410312098315638, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5539900443311465, 'val_loss': 0.5405877105191222, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5367148758496268, 'val_loss': 0.5335867140028212, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5215692805536722, 'val_loss': 0.5466929052630042, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5324023008599119, 'val_loss': 0.5316655085637019, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5269201733803345, 'val_loss': 0.5309928828834468, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 9, 'train_loss': 0.5226896136241445, 'val_loss': 0.5292379428178836, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5158604492070311, 'val_loss': 0.5145076523479234, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5127362433378979, 'val_loss': 0.5061203231159438, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5206649807297578, 'val_loss': 0.5108988672240168, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 13, 'train_loss': 0.5212243036445925, 'val_loss': 0.5112580193413628, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5107875245354944, 'val_loss': 0.509405038295648, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 15, 'train_loss': 0.49916392451120634, 'val_loss': 0.5165563404050648, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 16, 'train_loss': 0.4864222404815383, 'val_loss': 0.5008838523147453, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 17, 'train_loss': 0.49546060029227856, 'val_loss': 0.5030496385362413, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 18, 'train_loss': 0.4826974741230577, 'val_loss': 0.5200096847664597, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 19, 'train_loss': 0.4847487567339913, 'val_loss': 0.5097996638371394, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 20, 'train_loss': 0.47228608469841843, 'val_loss': 0.5059768644153563, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 21, 'train_loss': 0.4729707189283128, 'val_loss': 0.5133362468491253, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 22, 'train_loss': 0.4667170185406329, 'val_loss': 0.5165007175543369, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 23, 'train_loss': 0.4855842888355255, 'val_loss': 0.5092502659202641, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 24, 'train_loss': 0.4746199924561937, 'val_loss': 0.5085585178473057, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 25, 'train_loss': 0.46655529472282375, 'val_loss': 0.5110108465211004, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 26, 'train_loss': 0.4695639598925235, 'val_loss': 0.5313201317420373, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 27, 'train_loss': 0.46489668688026525, 'val_loss': 0.5130065689739, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 28, 'train_loss': 0.4615418567495831, 'val_loss': 0.530878882122855, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 29, 'train_loss': 0.4558733254671097, 'val_loss': 0.5072405236399072, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 30, 'train_loss': 0.45313220951011624, 'val_loss': 0.5095170991033571, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 31, 'train_loss': 0.4599995895967645, 'val_loss': 0.5210978353125417, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 32, 'train_loss': 0.45030379838357537, 'val_loss': 0.5098251277564937, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 33, 'train_loss': 0.4514880359677945, 'val_loss': 0.5047565525413579, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 34, 'train_loss': 0.45075090848288296, 'val_loss': 0.5068266452887119, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 35, 'train_loss': 0.44226327210159627, 'val_loss': 0.508462400517912, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 36, 'train_loss': 0.4581346453751548, 'val_loss': 0.506972891652686, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 37, 'train_loss': 0.4369489333387149, 'val_loss': 0.5148241744082198, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 38, 'train_loss': 0.43429322187173164, 'val_loss': 0.5054217933589576, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 39, 'train_loss': 0.4308529842202946, 'val_loss': 0.5075884924994575, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 40, 'train_loss': 0.4464525409926802, 'val_loss': 0.5235339759761451, 'test_acc': 0.7264957264957265}
{'fold': 9, 'epoch': 41, 'train_loss': 0.44258235066624013, 'val_loss': 0.5079369178185096, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 42, 'train_loss': 0.4321984695428509, 'val_loss': 0.5034384931254591, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 43, 'train_loss': 0.41499643659187574, 'val_loss': 0.507082034380008, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 44, 'train_loss': 0.4352693389785492, 'val_loss': 0.5002207959819044, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 45, 'train_loss': 0.4225408312375263, 'val_loss': 0.5032002701718583, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 46, 'train_loss': 0.42433376180923593, 'val_loss': 0.49818912734333265, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 47, 'train_loss': 0.42341131060305287, 'val_loss': 0.5095311678372897, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 48, 'train_loss': 0.43410464654029424, 'val_loss': 0.5014060745891343, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 49, 'train_loss': 0.41706679963459403, 'val_loss': 0.5055829724694929, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 50, 'train_loss': 0.40700126881316556, 'val_loss': 0.5081694187262119, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 51, 'train_loss': 0.4126828343181287, 'val_loss': 0.5130407056237898, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 52, 'train_loss': 0.4153991908592693, 'val_loss': 0.5058403667221721, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 53, 'train_loss': 0.4048994854092598, 'val_loss': 0.51727172655937, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 54, 'train_loss': 0.40642771781501125, 'val_loss': 0.5115128867646568, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 55, 'train_loss': 0.4042264732011294, 'val_loss': 0.5757765158628806, 'test_acc': 0.7008547008547008}
{'fold': 9, 'epoch': 56, 'train_loss': 0.421809760948359, 'val_loss': 0.5000190408820779, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 57, 'train_loss': 0.40339875789517066, 'val_loss': 0.5125037951347156, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 58, 'train_loss': 0.3959233157210431, 'val_loss': 0.5160218915368757, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 59, 'train_loss': 0.3846408386983104, 'val_loss': 0.5201568114451873, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 60, 'train_loss': 0.39550104295298205, 'val_loss': 0.5165601877065805, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 61, 'train_loss': 0.3978733494877815, 'val_loss': 0.5247620476616753, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 62, 'train_loss': 0.39587327661150595, 'val_loss': 0.5068854144495777, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 63, 'train_loss': 0.3849837873446739, 'val_loss': 0.5025150103446765, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 64, 'train_loss': 0.38347217516373777, 'val_loss': 0.5254207839313735, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 65, 'train_loss': 0.38048930541943693, 'val_loss': 0.5092159499469985, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 66, 'train_loss': 0.3809556228629613, 'val_loss': 0.5213288364247379, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 67, 'train_loss': 0.38994135240377004, 'val_loss': 0.5210162920829577, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 68, 'train_loss': 0.38874976917848747, 'val_loss': 0.5074683295355903, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 69, 'train_loss': 0.37629023762577674, 'val_loss': 0.5270626850617237, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 70, 'train_loss': 0.3679648529169923, 'val_loss': 0.5140085627890041, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 71, 'train_loss': 0.3796115909087456, 'val_loss': 0.5179842924460386, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 72, 'train_loss': 0.3743227590191162, 'val_loss': 0.5092344365568242, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 73, 'train_loss': 0.3670347561523066, 'val_loss': 0.5284885504306891, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 74, 'train_loss': 0.385673214002686, 'val_loss': 0.49958788227831197, 'test_acc': 0.811965811965812}
{'fold': 9, 'epoch': 75, 'train_loss': 0.3701504749261727, 'val_loss': 0.530842544686081, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 76, 'train_loss': 0.37009813693367827, 'val_loss': 0.5219885019155649, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 77, 'train_loss': 0.34971074336918734, 'val_loss': 0.5630209996150091, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 78, 'train_loss': 0.35925311140589794, 'val_loss': 0.537629151955629, 'test_acc': 0.811965811965812}
{'fold': 9, 'epoch': 79, 'train_loss': 0.38470456155679994, 'val_loss': 0.5309934534578242, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 80, 'train_loss': 0.36834518965018, 'val_loss': 0.5464039337940705, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 81, 'train_loss': 0.36659638299527814, 'val_loss': 0.5228412008693075, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 82, 'train_loss': 0.3589158786176625, 'val_loss': 0.5538120432796642, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 83, 'train_loss': 0.3486222795258134, 'val_loss': 0.5434162270309578, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 84, 'train_loss': 0.3380448173542144, 'val_loss': 0.5397200462145683, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 85, 'train_loss': 0.35076658471913663, 'val_loss': 0.5527280986818492, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 86, 'train_loss': 0.3476808508700233, 'val_loss': 0.5470143505650708, 'test_acc': 0.8205128205128205}
{'fold': 9, 'epoch': 87, 'train_loss': 0.33988161517654436, 'val_loss': 0.5631701314551198, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 88, 'train_loss': 0.3506900567119404, 'val_loss': 0.577415531517094, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 89, 'train_loss': 0.34406674192365955, 'val_loss': 0.5617189488859258, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 90, 'train_loss': 0.34292535565919796, 'val_loss': 0.562461918235844, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 91, 'train_loss': 0.3470875958643727, 'val_loss': 0.5481922117053953, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 92, 'train_loss': 0.3414543368301149, 'val_loss': 0.5667510073409121, 'test_acc': 0.811965811965812}
{'fold': 9, 'epoch': 93, 'train_loss': 0.33506887140920605, 'val_loss': 0.6075135581513755, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 94, 'train_loss': 0.3319481273450084, 'val_loss': 0.5626659556331798, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3173059054603011, 'val_loss': 0.5645381731864734, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 96, 'train_loss': 0.32708886758250705, 'val_loss': 0.5477872017102364, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 97, 'train_loss': 0.32626370612089917, 'val_loss': 0.5982936141837356, 'test_acc': 0.8034188034188035}
{'fold': 9, 'epoch': 98, 'train_loss': 0.33076604222089556, 'val_loss': 0.5845739250509148, 'test_acc': 0.811965811965812}
{'fold': 9, 'epoch': 99, 'train_loss': 0.3355880017881676, 'val_loss': 0.5974082294692341, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 100, 'train_loss': 0.332641307832831, 'val_loss': 0.5811219989744008, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 101, 'train_loss': 0.3331778743383238, 'val_loss': 0.57652100131043, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 102, 'train_loss': 0.3253540379011025, 'val_loss': 0.6291901678101629, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 103, 'train_loss': 0.30703413353885634, 'val_loss': 0.6089321853768113, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 104, 'train_loss': 0.32541602856274376, 'val_loss': 0.6090063926501151, 'test_acc': 0.7948717948717948}
{'fold': 9, 'epoch': 105, 'train_loss': 0.32743775604640024, 'val_loss': 0.5834929637419872, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 106, 'train_loss': 0.3132432138515731, 'val_loss': 0.5980147337302183, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 107, 'train_loss': 0.30274831686737175, 'val_loss': 0.6010375063643496, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 108, 'train_loss': 0.3023414670537084, 'val_loss': 0.6553875849797175, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 109, 'train_loss': 0.31221572284476234, 'val_loss': 0.6001729720678085, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 110, 'train_loss': 0.320128788003477, 'val_loss': 0.6412324008778629, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 111, 'train_loss': 0.3166942717665333, 'val_loss': 0.6382224580161592, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 112, 'train_loss': 0.34099147096276283, 'val_loss': 0.6217457045856704, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 113, 'train_loss': 0.32049376012410147, 'val_loss': 0.6494417435083634, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 114, 'train_loss': 0.3128665486761069, 'val_loss': 0.7066462264101729, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 115, 'train_loss': 0.3184771757509749, 'val_loss': 0.696615724482088, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 116, 'train_loss': 0.3084052338943643, 'val_loss': 0.655751709245209, 'test_acc': 0.7863247863247863}
{'fold': 9, 'epoch': 117, 'train_loss': 0.305243252508216, 'val_loss': 0.6814183618268396, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 118, 'train_loss': 0.295527932060472, 'val_loss': 0.6396613161788027, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 119, 'train_loss': 0.2788676212904817, 'val_loss': 0.6489937937157786, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 120, 'train_loss': 0.2875079641402778, 'val_loss': 0.6337735754811865, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 121, 'train_loss': 0.29276247783485104, 'val_loss': 0.6480654855059762, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 122, 'train_loss': 0.3024575094045219, 'val_loss': 0.6389864571074135, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 123, 'train_loss': 0.29328761407631937, 'val_loss': 0.6525783864860861, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 124, 'train_loss': 0.2814821887571933, 'val_loss': 0.7035911103599092, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 125, 'train_loss': 0.282126796258203, 'val_loss': 0.668618422288161, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 126, 'train_loss': 0.27301097954860176, 'val_loss': 0.7637729155711639, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 127, 'train_loss': 0.30455268969980337, 'val_loss': 0.6482777065700955, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 128, 'train_loss': 0.2922253971130161, 'val_loss': 0.732034895155165, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 129, 'train_loss': 0.3112449613794432, 'val_loss': 0.6637255676791199, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 130, 'train_loss': 0.29108611696352393, 'val_loss': 0.6889792222243089, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 131, 'train_loss': 0.2817736169544317, 'val_loss': 0.7577528016180055, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 132, 'train_loss': 0.2857939723437115, 'val_loss': 0.6707069853432158, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 133, 'train_loss': 0.2924331927956161, 'val_loss': 0.7275269337189503, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 134, 'train_loss': 0.28784579543744104, 'val_loss': 0.7595529474763789, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 135, 'train_loss': 0.2860944697286113, 'val_loss': 0.7069264599400708, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 136, 'train_loss': 0.27030169553423333, 'val_loss': 0.741204351441473, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 137, 'train_loss': 0.2650447970856044, 'val_loss': 0.714741437863081, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 138, 'train_loss': 0.2621031929502043, 'val_loss': 0.7281157664763622, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 139, 'train_loss': 0.26265776466767665, 'val_loss': 0.7849332369290866, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 140, 'train_loss': 0.2692600621257798, 'val_loss': 0.7039825243827624, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 141, 'train_loss': 0.2844276207862264, 'val_loss': 0.689952133048294, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 142, 'train_loss': 0.2580164219489542, 'val_loss': 0.7842641325078459, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 143, 'train_loss': 0.2701500398501501, 'val_loss': 0.8018446050138555, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 144, 'train_loss': 0.27353467640735335, 'val_loss': 0.7565806788257045, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 145, 'train_loss': 0.26577564032148504, 'val_loss': 0.7757784851595887, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 146, 'train_loss': 0.2623905039439767, 'val_loss': 0.7866543174808861, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 147, 'train_loss': 0.26503554681095026, 'val_loss': 0.7673363970895098, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 148, 'train_loss': 0.2708757682308807, 'val_loss': 0.8577135852259449, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 149, 'train_loss': 0.2823258446434797, 'val_loss': 0.7416643648066072, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 150, 'train_loss': 0.26694290346260796, 'val_loss': 0.8085912394727397, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 151, 'train_loss': 0.2567118885532274, 'val_loss': 0.7473396562103533, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 152, 'train_loss': 0.2574668470454418, 'val_loss': 0.7788572066869491, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 153, 'train_loss': 0.25380693786477637, 'val_loss': 0.7810875330215845, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 154, 'train_loss': 0.25381720293376403, 'val_loss': 0.7504321693355201, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 155, 'train_loss': 0.24790934795292757, 'val_loss': 0.8070392119578826, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 156, 'train_loss': 0.23793306927812302, 'val_loss': 0.8756718105740018, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 157, 'train_loss': 0.2546346521604869, 'val_loss': 0.7611316126635951, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 158, 'train_loss': 0.2556077640945629, 'val_loss': 0.8429618574615217, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 159, 'train_loss': 0.2540474063006498, 'val_loss': 0.9961903889973959, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 160, 'train_loss': 0.2731610819444818, 'val_loss': 0.8672169742421207, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 161, 'train_loss': 0.23934970455149474, 'val_loss': 0.8438886006673177, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 162, 'train_loss': 0.23841563833214469, 'val_loss': 0.8612445929111578, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 163, 'train_loss': 0.25064313594820137, 'val_loss': 0.8054637419871795, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 164, 'train_loss': 0.24905922876323683, 'val_loss': 0.8218243916829427, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 165, 'train_loss': 0.24966984595787728, 'val_loss': 0.8697923187516693, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 166, 'train_loss': 0.25158207768858487, 'val_loss': 0.8758280501406417, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 167, 'train_loss': 0.25355434619774253, 'val_loss': 0.8763536632570446, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 168, 'train_loss': 0.24991356707730536, 'val_loss': 0.9030167017227564, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 169, 'train_loss': 0.24633886311518943, 'val_loss': 0.939708253257295, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 170, 'train_loss': 0.2639347208758532, 'val_loss': 0.7937889425163596, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 171, 'train_loss': 0.24899693938382603, 'val_loss': 0.8261000152327057, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 172, 'train_loss': 0.2575344623903097, 'val_loss': 0.9579259432279147, 'test_acc': 0.717948717948718}
{'fold': 9, 'epoch': 173, 'train_loss': 0.23806358318207627, 'val_loss': 0.8787592374361478, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 174, 'train_loss': 0.22041812381249362, 'val_loss': 0.9348992567795974, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 175, 'train_loss': 0.229032123745498, 'val_loss': 0.8861146910577757, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 176, 'train_loss': 0.2240765570836552, 'val_loss': 0.9598399431277544, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 177, 'train_loss': 0.226203140502764, 'val_loss': 0.9092790000459068, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 178, 'train_loss': 0.22321537635841612, 'val_loss': 1.0004061837481637, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 179, 'train_loss': 0.2345292968517643, 'val_loss': 0.9308195195646367, 'test_acc': 0.717948717948718}
{'fold': 9, 'epoch': 180, 'train_loss': 0.23572038344533766, 'val_loss': 0.9935679965549045, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 181, 'train_loss': 0.24347111399648552, 'val_loss': 0.8984508351383046, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 182, 'train_loss': 0.2220298239045729, 'val_loss': 0.9950608147515191, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 183, 'train_loss': 0.2030261469594503, 'val_loss': 0.9269579047830696, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 184, 'train_loss': 0.23341260222181426, 'val_loss': 0.9579642858260717, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 185, 'train_loss': 0.2191460483028727, 'val_loss': 1.066118876139323, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 186, 'train_loss': 0.21296028521353916, 'val_loss': 0.9237667311969985, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 187, 'train_loss': 0.2182794857328221, 'val_loss': 0.9395616971529447, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 188, 'train_loss': 0.2148618939948284, 'val_loss': 0.9362371395795773, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 189, 'train_loss': 0.23983748143507264, 'val_loss': 0.9330975785214677, 'test_acc': 0.7777777777777778}
{'fold': 9, 'epoch': 190, 'train_loss': 0.21542330509272672, 'val_loss': 1.00724854428544, 'test_acc': 0.7094017094017094}
{'fold': 9, 'epoch': 191, 'train_loss': 0.2090976628459106, 'val_loss': 1.1734830416165865, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 192, 'train_loss': 0.22132510483517484, 'val_loss': 1.0919690906492054, 'test_acc': 0.7692307692307693}
{'fold': 9, 'epoch': 193, 'train_loss': 0.20586323798081632, 'val_loss': 1.0227660154684997, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 194, 'train_loss': 0.21520105020095737, 'val_loss': 1.0134536547538562, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 195, 'train_loss': 0.2155030444895817, 'val_loss': 1.07926510541867, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 196, 'train_loss': 0.22991932960132422, 'val_loss': 0.953004396878756, 'test_acc': 0.7606837606837606}
{'fold': 9, 'epoch': 197, 'train_loss': 0.232216525223043, 'val_loss': 1.2003504435221355, 'test_acc': 0.7435897435897436}
{'fold': 9, 'epoch': 198, 'train_loss': 0.2005545068847931, 'val_loss': 1.0444544930743356, 'test_acc': 0.7350427350427351}
{'fold': 9, 'epoch': 199, 'train_loss': 0.21915190625872652, 'val_loss': 1.0388783511952457, 'test_acc': 0.7521367521367521}
{'fold': 9, 'epoch': 200, 'train_loss': 0.2559208074995017, 'val_loss': 1.0800204806857638, 'test_acc': 0.7606837606837606}
Val Loss: 0.4772, Test Accuracy: 0.776 ± 0.021, Duration: 111.955
Best result - 0.776 ± 0.021
--
NCI1 - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6890806183762794, 'val_loss': 0.6672184797969177, 'test_acc': 0.5936739659367397}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6608417921692785, 'val_loss': 0.6367428540603378, 'test_acc': 0.5936739659367397}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6448657077594395, 'val_loss': 0.6152478610222067, 'test_acc': 0.6131386861313869}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6296142705165557, 'val_loss': 0.6128503609167688, 'test_acc': 0.6374695863746959}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6273657834007792, 'val_loss': 0.6046687216654311, 'test_acc': 0.6447688564476886}
{'fold': 9, 'epoch': 6, 'train_loss': 0.619765895344045, 'val_loss': 0.60062504974885, 'test_acc': 0.6472019464720195}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6150226563650326, 'val_loss': 0.5937159554511672, 'test_acc': 0.6520681265206812}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6080988482402189, 'val_loss': 0.6026492014418553, 'test_acc': 0.6618004866180048}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6098958219054842, 'val_loss': 0.5884782972126982, 'test_acc': 0.6763990267639902}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6019321040515482, 'val_loss': 0.5875588437936602, 'test_acc': 0.6593673965936739}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6014742709859444, 'val_loss': 0.5911649764309255, 'test_acc': 0.6545012165450121}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5942953218073741, 'val_loss': 0.5765445365812947, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 13, 'train_loss': 0.5902612802103488, 'val_loss': 0.5830976574380322, 'test_acc': 0.6739659367396593}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5901776019239078, 'val_loss': 0.5679851958931508, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5785237167873521, 'val_loss': 0.5590762071075811, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5728377015703786, 'val_loss': 0.5477906108772668, 'test_acc': 0.681265206812652}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5694255423154274, 'val_loss': 0.5776181557462743, 'test_acc': 0.6739659367396593}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5704827557732589, 'val_loss': 0.5422745400681693, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5674177604000064, 'val_loss': 0.5474938487774554, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 20, 'train_loss': 0.556545150541041, 'val_loss': 0.5301333100256258, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5580669379364835, 'val_loss': 0.5298660491794855, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5496655989737407, 'val_loss': 0.5363269722374686, 'test_acc': 0.7055961070559611}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5466611708385231, 'val_loss': 0.5267656980639827, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5454718658741373, 'val_loss': 0.5267375751133383, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5397465522706943, 'val_loss': 0.528861985589466, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5507516792438326, 'val_loss': 0.5360070295867548, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5410782410933154, 'val_loss': 0.5278248844935656, 'test_acc': 0.6909975669099757}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5309686724939485, 'val_loss': 0.5255905485501254, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5376587866866676, 'val_loss': 0.5204258893238077, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5349331643894641, 'val_loss': 0.5225996820305966, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5396785813308981, 'val_loss': 0.5142023778019741, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5326158999309053, 'val_loss': 0.5214230799616978, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5318774648391418, 'val_loss': 0.5282893633320384, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5298813268215987, 'val_loss': 0.5226699894072075, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 35, 'train_loss': 0.5210228906060658, 'val_loss': 0.5152556565556213, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5257481528024603, 'val_loss': 0.5311554168552668, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5327917752909834, 'val_loss': 0.513816341576495, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5214269630012721, 'val_loss': 0.5123029230864958, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 39, 'train_loss': 0.517817834650513, 'val_loss': 0.5188184956274473, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5259918400841038, 'val_loss': 0.5086562674120975, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 41, 'train_loss': 0.516829847963187, 'val_loss': 0.5114901790943749, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5170768991003941, 'val_loss': 0.5146329095473835, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 43, 'train_loss': 0.5207727514479282, 'val_loss': 0.5123800570077269, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 44, 'train_loss': 0.517497409760517, 'val_loss': 0.5099396299561735, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 45, 'train_loss': 0.5237186602214827, 'val_loss': 0.5035628205088223, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 46, 'train_loss': 0.5097014100229653, 'val_loss': 0.512023995392514, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 47, 'train_loss': 0.5164196843648479, 'val_loss': 0.5026213931341241, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 48, 'train_loss': 0.5188108151846559, 'val_loss': 0.506893858712375, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 49, 'train_loss': 0.5116546193178553, 'val_loss': 0.5040063092308323, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 50, 'train_loss': 0.5050465541816976, 'val_loss': 0.5100102204185912, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 51, 'train_loss': 0.508953271447307, 'val_loss': 0.507177181197489, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 52, 'train_loss': 0.5073660011709171, 'val_loss': 0.5060022730026802, 'test_acc': 0.6934306569343066}
{'fold': 9, 'epoch': 53, 'train_loss': 0.5088250232438971, 'val_loss': 0.5141035019626292, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 54, 'train_loss': 0.504318537068193, 'val_loss': 0.5066920927841297, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 55, 'train_loss': 0.501481358804842, 'val_loss': 0.5021390195600598, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 56, 'train_loss': 0.5015425563511187, 'val_loss': 0.5217453105026209, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 57, 'train_loss': 0.500980840112171, 'val_loss': 0.5047410746850527, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5082522694864412, 'val_loss': 0.5149977004150985, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 59, 'train_loss': 0.5028072024566413, 'val_loss': 0.5106412418857398, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 60, 'train_loss': 0.49882452592362453, 'val_loss': 0.5012568220894992, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 61, 'train_loss': 0.496609710863907, 'val_loss': 0.49990052086303416, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 62, 'train_loss': 0.4920600921350674, 'val_loss': 0.5033513646926323, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 63, 'train_loss': 0.496896420517107, 'val_loss': 0.5058519033910004, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 64, 'train_loss': 0.4958633668448803, 'val_loss': 0.5059099684666543, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 65, 'train_loss': 0.4928959486258291, 'val_loss': 0.5008492574204494, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 66, 'train_loss': 0.48758354478508886, 'val_loss': 0.5029310286770192, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 67, 'train_loss': 0.4894842316199393, 'val_loss': 0.5057547353479984, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 68, 'train_loss': 0.4889589810240878, 'val_loss': 0.5009190635959597, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 69, 'train_loss': 0.4914044869424653, 'val_loss': 0.5152678292453144, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 70, 'train_loss': 0.4898780883446227, 'val_loss': 0.514618319026455, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 71, 'train_loss': 0.48679190003958933, 'val_loss': 0.5020540056437471, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 72, 'train_loss': 0.4891343026483146, 'val_loss': 0.4966133656002889, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 73, 'train_loss': 0.4790352066285419, 'val_loss': 0.5046093655328681, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 74, 'train_loss': 0.47616523558641, 'val_loss': 0.5157553447714107, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 75, 'train_loss': 0.4803318953427085, 'val_loss': 0.504205675890846, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 76, 'train_loss': 0.4736456595850687, 'val_loss': 0.5132145150734561, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 77, 'train_loss': 0.47693583532406464, 'val_loss': 0.5134142344305405, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 78, 'train_loss': 0.47968396979526884, 'val_loss': 0.5037302170356694, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 79, 'train_loss': 0.46988865624379067, 'val_loss': 0.5189643219439652, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 80, 'train_loss': 0.47637590472280544, 'val_loss': 0.5034381003275404, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 81, 'train_loss': 0.47718075929331955, 'val_loss': 0.508177360478979, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 82, 'train_loss': 0.4727730714056614, 'val_loss': 0.49282166789628, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 83, 'train_loss': 0.46241574881285646, 'val_loss': 0.4982222814629548, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 84, 'train_loss': 0.4712624217036867, 'val_loss': 0.49580449199444476, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 85, 'train_loss': 0.464281823404514, 'val_loss': 0.5198711153944623, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 86, 'train_loss': 0.4651722263028152, 'val_loss': 0.5067297478371873, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 87, 'train_loss': 0.46260042118765143, 'val_loss': 0.5075705776539452, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 88, 'train_loss': 0.4671424826348785, 'val_loss': 0.5058449283423505, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 89, 'train_loss': 0.4643503328526977, 'val_loss': 0.5136375752098659, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 90, 'train_loss': 0.47078610369323814, 'val_loss': 0.4953631333771123, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 91, 'train_loss': 0.4588078690053773, 'val_loss': 0.5084647621841616, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 92, 'train_loss': 0.46521249011050175, 'val_loss': 0.4957121456916605, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 93, 'train_loss': 0.46459405972574747, 'val_loss': 0.4961199516797588, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 94, 'train_loss': 0.45990859505033843, 'val_loss': 0.49986669907024595, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 95, 'train_loss': 0.44765117209758204, 'val_loss': 0.4998721519525904, 'test_acc': 0.6934306569343066}
{'fold': 9, 'epoch': 96, 'train_loss': 0.45479395104585774, 'val_loss': 0.5191195968293796, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 97, 'train_loss': 0.4580751132138454, 'val_loss': 0.5027860608994236, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 98, 'train_loss': 0.4542262203937029, 'val_loss': 0.48759378307927265, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 99, 'train_loss': 0.45265831020626707, 'val_loss': 0.5066468779478049, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 100, 'train_loss': 0.44501345316423985, 'val_loss': 0.5017423003259367, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 101, 'train_loss': 0.4642567349611408, 'val_loss': 0.48868239186976076, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 102, 'train_loss': 0.4555858784783496, 'val_loss': 0.48644231067666754, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 103, 'train_loss': 0.44136563106609955, 'val_loss': 0.5022098699045298, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 104, 'train_loss': 0.4442111558287683, 'val_loss': 0.5042203870712986, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 105, 'train_loss': 0.4426345429281249, 'val_loss': 0.5048593210187852, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 106, 'train_loss': 0.43776428373190607, 'val_loss': 0.5240528635735059, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 107, 'train_loss': 0.4445881667363383, 'val_loss': 0.49634131085843647, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 108, 'train_loss': 0.4380645489823209, 'val_loss': 0.507310955483838, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 109, 'train_loss': 0.44162606518634046, 'val_loss': 0.5358599270637308, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 110, 'train_loss': 0.4370240866050233, 'val_loss': 0.5132443086944357, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 111, 'train_loss': 0.4373905347646588, 'val_loss': 0.5291362586102637, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 112, 'train_loss': 0.4481819232884985, 'val_loss': 0.4997459513717614, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 113, 'train_loss': 0.4392142759187378, 'val_loss': 0.5174581244624155, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 114, 'train_loss': 0.43651310359909584, 'val_loss': 0.49690636869184585, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 115, 'train_loss': 0.43230172969999103, 'val_loss': 0.5120892025838513, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 116, 'train_loss': 0.43509094166929707, 'val_loss': 0.5134714548895248, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 117, 'train_loss': 0.43117368678106877, 'val_loss': 0.5018984430317751, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 118, 'train_loss': 0.43769123247505104, 'val_loss': 0.51553202719584, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 119, 'train_loss': 0.43235335580623935, 'val_loss': 0.5010880983078857, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 120, 'train_loss': 0.4281008333837899, 'val_loss': 0.5089138940593042, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 121, 'train_loss': 0.41940347295607966, 'val_loss': 0.5353006748097366, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 122, 'train_loss': 0.4214095613599694, 'val_loss': 0.508408571971884, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 123, 'train_loss': 0.42819944839843, 'val_loss': 0.5044150712136225, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 124, 'train_loss': 0.42573568072632284, 'val_loss': 0.49430891719177694, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 125, 'train_loss': 0.42808181917580373, 'val_loss': 0.5230018495063132, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 126, 'train_loss': 0.42182611287945376, 'val_loss': 0.5159223978826889, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 127, 'train_loss': 0.42228865460322723, 'val_loss': 0.48867380648053765, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 128, 'train_loss': 0.4088395649608034, 'val_loss': 0.513845035339504, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 129, 'train_loss': 0.41779199525387617, 'val_loss': 0.506090725715433, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 130, 'train_loss': 0.4193141409297929, 'val_loss': 0.5459742488072157, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 131, 'train_loss': 0.41768224591756387, 'val_loss': 0.5155830986598402, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 132, 'train_loss': 0.4286266491360908, 'val_loss': 0.49228306234317976, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 133, 'train_loss': 0.4188186513246411, 'val_loss': 0.5331896436185443, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 134, 'train_loss': 0.41730022658831883, 'val_loss': 0.5188159849811934, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 135, 'train_loss': 0.41625428716414165, 'val_loss': 0.533285609707055, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 136, 'train_loss': 0.41313937241143556, 'val_loss': 0.49681955880492273, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 137, 'train_loss': 0.4175453493847464, 'val_loss': 0.5316288987505465, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 138, 'train_loss': 0.4128190778250242, 'val_loss': 0.5222059050325639, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 139, 'train_loss': 0.4115833402985204, 'val_loss': 0.5158814154112136, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 140, 'train_loss': 0.40394559339450226, 'val_loss': 0.5323782640071971, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 141, 'train_loss': 0.41129243526145487, 'val_loss': 0.5329964816425259, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 142, 'train_loss': 0.40849628326666615, 'val_loss': 0.5343996498126473, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 143, 'train_loss': 0.4014989307326992, 'val_loss': 0.49816518630424556, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 144, 'train_loss': 0.4006081203909686, 'val_loss': 0.5040537098608457, 'test_acc': 0.7566909975669099}
{'fold': 9, 'epoch': 145, 'train_loss': 0.3985794281219914, 'val_loss': 0.5099499649084978, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 146, 'train_loss': 0.4053543869161258, 'val_loss': 0.5060594609764081, 'test_acc': 0.7518248175182481}
{'fold': 9, 'epoch': 147, 'train_loss': 0.4102189996599281, 'val_loss': 0.5240065581607123, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 148, 'train_loss': 0.3973956232088326, 'val_loss': 0.5201037005496432, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 149, 'train_loss': 0.39969341837576705, 'val_loss': 0.5130527802627453, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 150, 'train_loss': 0.3860833612236663, 'val_loss': 0.5223171739972711, 'test_acc': 0.7615571776155717}
{'fold': 9, 'epoch': 151, 'train_loss': 0.3939434128956203, 'val_loss': 0.5147470488165417, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 152, 'train_loss': 0.3938392884757397, 'val_loss': 0.543876624745464, 'test_acc': 0.7566909975669099}
{'fold': 9, 'epoch': 153, 'train_loss': 0.3972732791282835, 'val_loss': 0.5367425839686336, 'test_acc': 0.7518248175182481}
{'fold': 9, 'epoch': 154, 'train_loss': 0.38903553044273903, 'val_loss': 0.5316761369542774, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 155, 'train_loss': 0.39765465379196363, 'val_loss': 0.553411172834336, 'test_acc': 0.7518248175182481}
{'fold': 9, 'epoch': 156, 'train_loss': 0.3874189503436541, 'val_loss': 0.5320365423123622, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 157, 'train_loss': 0.39467021964327265, 'val_loss': 0.5092013839387546, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 158, 'train_loss': 0.38891835532484265, 'val_loss': 0.5654394655622125, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 159, 'train_loss': 0.3899441481071667, 'val_loss': 0.5268953420820027, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 160, 'train_loss': 0.3718477932967409, 'val_loss': 0.5393165532689895, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 161, 'train_loss': 0.3861199999703978, 'val_loss': 0.5508448700545188, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 162, 'train_loss': 0.389679931158567, 'val_loss': 0.5417703920907347, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 163, 'train_loss': 0.3770848558331928, 'val_loss': 0.5424162361163583, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 164, 'train_loss': 0.38523757408787734, 'val_loss': 0.5223560797327046, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 165, 'train_loss': 0.37679628701540674, 'val_loss': 0.4991347227073354, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 166, 'train_loss': 0.3854962464449179, 'val_loss': 0.5249095044286872, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 167, 'train_loss': 0.377232146197862, 'val_loss': 0.5465519155609057, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 168, 'train_loss': 0.3770490900552186, 'val_loss': 0.5198270978718779, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 169, 'train_loss': 0.3848472652535369, 'val_loss': 0.5682703607563845, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 170, 'train_loss': 0.37449978629167935, 'val_loss': 0.5238093448091308, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 171, 'train_loss': 0.3783640217607039, 'val_loss': 0.5304610352156516, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 172, 'train_loss': 0.3647313715115081, 'val_loss': 0.5509059237737726, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 173, 'train_loss': 0.366639631399273, 'val_loss': 0.5420043416266894, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 174, 'train_loss': 0.345307434018511, 'val_loss': 0.529850516586118, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 175, 'train_loss': 0.3725546887756264, 'val_loss': 0.5140275839181422, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 176, 'train_loss': 0.365478071907576, 'val_loss': 0.55508903633359, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 177, 'train_loss': 0.37558261131065607, 'val_loss': 0.568065364865491, 'test_acc': 0.7566909975669099}
{'fold': 9, 'epoch': 178, 'train_loss': 0.37015346959777123, 'val_loss': 0.5793015185353819, 'test_acc': 0.7469586374695864}
{'fold': 9, 'epoch': 179, 'train_loss': 0.3669939645885551, 'val_loss': 0.5313674295615686, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 180, 'train_loss': 0.3643285329759556, 'val_loss': 0.5696624328910289, 'test_acc': 0.7615571776155717}
{'fold': 9, 'epoch': 181, 'train_loss': 0.36766286825176575, 'val_loss': 0.5624760583659448, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 182, 'train_loss': 0.34748228198855463, 'val_loss': 0.5817416114528684, 'test_acc': 0.754257907542579}
{'fold': 9, 'epoch': 183, 'train_loss': 0.36267030717682663, 'val_loss': 0.5486999613815271, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 184, 'train_loss': 0.35416387239076796, 'val_loss': 0.566152164245754, 'test_acc': 0.7518248175182481}
{'fold': 9, 'epoch': 185, 'train_loss': 0.3605978195793437, 'val_loss': 0.5639951896203406, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 186, 'train_loss': 0.35582296262039753, 'val_loss': 0.5611507016666905, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 187, 'train_loss': 0.3602632015508457, 'val_loss': 0.5517625275029463, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 188, 'train_loss': 0.35777084328179815, 'val_loss': 0.5588737218629415, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 189, 'train_loss': 0.3622272734659432, 'val_loss': 0.5936110002281022, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 190, 'train_loss': 0.34914963518398523, 'val_loss': 0.5623086293538412, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 191, 'train_loss': 0.3537995143093332, 'val_loss': 0.5716426598764685, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 192, 'train_loss': 0.3522000694579452, 'val_loss': 0.5717108093038963, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 193, 'train_loss': 0.3496302250963058, 'val_loss': 0.5577190102161862, 'test_acc': 0.7250608272506083}
{'fold': 9, 'epoch': 194, 'train_loss': 0.345641099079682, 'val_loss': 0.5973530233341412, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 195, 'train_loss': 0.35512149056596476, 'val_loss': 0.5629182244739394, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 196, 'train_loss': 0.3543381289082722, 'val_loss': 0.5690171689592719, 'test_acc': 0.7493917274939172}
{'fold': 9, 'epoch': 197, 'train_loss': 0.3396752191721088, 'val_loss': 0.5598058259690185, 'test_acc': 0.7445255474452555}
{'fold': 9, 'epoch': 198, 'train_loss': 0.3543158619508256, 'val_loss': 0.600034458503816, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 199, 'train_loss': 0.3488510760077595, 'val_loss': 0.6419470571253422, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 200, 'train_loss': 0.345208954908987, 'val_loss': 0.6091195173797236, 'test_acc': 0.7274939172749392}
Val Loss: 0.5121, Test Accuracy: 0.750 ± 0.019, Duration: 286.686
Best result - 0.750 ± 0.019
--
PROTEINS - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6838994638285653, 'val_loss': 0.6651174871771185, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6511433519899644, 'val_loss': 0.6307998519759994, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6170620996542652, 'val_loss': 0.5982134879172385, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5824980254125114, 'val_loss': 0.5853159964621604, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5777941647202077, 'val_loss': 0.5725766431103956, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5746763751964377, 'val_loss': 0.5604754439345351, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5563750419552479, 'val_loss': 0.5506352605046453, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5482996338947053, 'val_loss': 0.5444177335447019, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 9, 'train_loss': 0.5433273195016264, 'val_loss': 0.5484506418039133, 'test_acc': 0.8018018018018018}
{'fold': 9, 'epoch': 10, 'train_loss': 0.5366302212882123, 'val_loss': 0.5365392152253572, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 11, 'train_loss': 0.5396179906045547, 'val_loss': 0.5288580129812429, 'test_acc': 0.8018018018018018}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5263286908266922, 'val_loss': 0.5211169955966709, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 13, 'train_loss': 0.525277567331237, 'val_loss': 0.5166397266559772, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5330633093612362, 'val_loss': 0.5308356242136912, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5301791000045109, 'val_loss': 0.5291215363923494, 'test_acc': 0.7927927927927928}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5251351817689761, 'val_loss': 0.5108165053633956, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5187600814934933, 'val_loss': 0.5161065110215196, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5179252581363575, 'val_loss': 0.5122729636527397, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5198097369486234, 'val_loss': 0.5140029288627006, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 20, 'train_loss': 0.516047265192475, 'val_loss': 0.5151745220562359, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5060551202658451, 'val_loss': 0.5115541166013425, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5155214113418503, 'val_loss': 0.5091554452707102, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5102937367026653, 'val_loss': 0.5226332346598307, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5137410468926735, 'val_loss': 0.5091644149642807, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5128506955875692, 'val_loss': 0.5060570003750088, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5176148958479114, 'val_loss': 0.501945787721926, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5110698492840083, 'val_loss': 0.5069107708630262, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5047869329099302, 'val_loss': 0.5089601568273596, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 29, 'train_loss': 0.495818332590238, 'val_loss': 0.5136046882148262, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5120995532382618, 'val_loss': 0.5099978404002147, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5036013543806493, 'val_loss': 0.5067261188953847, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5001551723640776, 'val_loss': 0.5083590670748874, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5159990381110798, 'val_loss': 0.5004474193126232, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5110385785199175, 'val_loss': 0.5069151869765273, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 35, 'train_loss': 0.5070709648357096, 'val_loss': 0.51720768696553, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5072226248405598, 'val_loss': 0.5135721430048212, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5117567562896395, 'val_loss': 0.5073795662269937, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 38, 'train_loss': 0.49363458276999117, 'val_loss': 0.5021217621124543, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 39, 'train_loss': 0.5009594864716835, 'val_loss': 0.5101803272694081, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5071337957574864, 'val_loss': 0.5042346404479431, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 41, 'train_loss': 0.49803213730002893, 'val_loss': 0.5080965918463629, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 42, 'train_loss': 0.50505343591324, 'val_loss': 0.5086222811862156, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 43, 'train_loss': 0.4988805743981692, 'val_loss': 0.5033733092986785, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 44, 'train_loss': 0.49860866543419835, 'val_loss': 0.4996642207240199, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 45, 'train_loss': 0.503567535267133, 'val_loss': 0.49672846751170113, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 46, 'train_loss': 0.4971804068947481, 'val_loss': 0.508184982849671, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 47, 'train_loss': 0.4945078999907882, 'val_loss': 0.5044164915342588, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 48, 'train_loss': 0.49966841815698027, 'val_loss': 0.49958995441058734, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 49, 'train_loss': 0.4975645357510859, 'val_loss': 0.5079715144526851, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 50, 'train_loss': 0.4982753672985115, 'val_loss': 0.4999216096895235, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 51, 'train_loss': 0.4978297239401525, 'val_loss': 0.5028080124038834, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 52, 'train_loss': 0.503907155910325, 'val_loss': 0.5050198838517472, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 53, 'train_loss': 0.491937315624571, 'val_loss': 0.5027342787734023, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 54, 'train_loss': 0.4916117315741902, 'val_loss': 0.5088744636054512, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 55, 'train_loss': 0.502719111514814, 'val_loss': 0.4981829497191283, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 56, 'train_loss': 0.5013935115401592, 'val_loss': 0.508511259749129, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 57, 'train_loss': 0.49186769780085143, 'val_loss': 0.5005812086500563, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 58, 'train_loss': 0.4898226873240487, 'val_loss': 0.5042157731614672, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 59, 'train_loss': 0.4929675098621484, 'val_loss': 0.5051011094101915, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 60, 'train_loss': 0.4904184589281628, 'val_loss': 0.49580460625725825, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 61, 'train_loss': 0.49541525989269164, 'val_loss': 0.5046244612685195, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 62, 'train_loss': 0.49964249595648513, 'val_loss': 0.5047789049578143, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 63, 'train_loss': 0.48915908071729874, 'val_loss': 0.5097769659918707, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 64, 'train_loss': 0.49635825755218865, 'val_loss': 0.49485775371929547, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 65, 'train_loss': 0.4890919997033848, 'val_loss': 0.4945977528889974, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 66, 'train_loss': 0.4957063888459896, 'val_loss': 0.5000229397335568, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 67, 'train_loss': 0.48249542020788094, 'val_loss': 0.49699257515572215, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 68, 'train_loss': 0.49231033072327124, 'val_loss': 0.5021632941993507, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 69, 'train_loss': 0.4877474837832981, 'val_loss': 0.5074592796531884, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 70, 'train_loss': 0.49329828854763147, 'val_loss': 0.5128692592586483, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 71, 'train_loss': 0.49192296575616906, 'val_loss': 0.49677065256479624, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 72, 'train_loss': 0.48407424539829347, 'val_loss': 0.517126719156901, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 73, 'train_loss': 0.4874041209919284, 'val_loss': 0.507012685139974, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 74, 'train_loss': 0.4923705280027807, 'val_loss': 0.5060861948374156, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 75, 'train_loss': 0.49206503172113436, 'val_loss': 0.495360279942418, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 76, 'train_loss': 0.48466947032546354, 'val_loss': 0.50957102388949, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 77, 'train_loss': 0.4986937682235281, 'val_loss': 0.5112804550308365, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 78, 'train_loss': 0.4854361319582069, 'val_loss': 0.5009329168646185, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 79, 'train_loss': 0.4867508260890691, 'val_loss': 0.5240854486688837, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 80, 'train_loss': 0.49487294532634596, 'val_loss': 0.496054812594577, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 81, 'train_loss': 0.48074587146039766, 'val_loss': 0.49373963502076296, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 82, 'train_loss': 0.48505750107845474, 'val_loss': 0.5094096896884678, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 83, 'train_loss': 0.48913687567919595, 'val_loss': 0.49636784115353144, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 84, 'train_loss': 0.48143369441080575, 'val_loss': 0.5169721208177172, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 85, 'train_loss': 0.4886216948730777, 'val_loss': 0.5047240214304881, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 86, 'train_loss': 0.48304761128393486, 'val_loss': 0.511179898236249, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 87, 'train_loss': 0.4886615645604503, 'val_loss': 0.5342665148210956, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 88, 'train_loss': 0.4818938586246285, 'val_loss': 0.5065114648492487, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 89, 'train_loss': 0.488417890637812, 'val_loss': 0.49939086845329217, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 90, 'train_loss': 0.4917667826217433, 'val_loss': 0.5052597286464932, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 91, 'train_loss': 0.47339732438225535, 'val_loss': 0.4943752116985149, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 92, 'train_loss': 0.48135561433304036, 'val_loss': 0.49920611338572457, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 93, 'train_loss': 0.48461158568610246, 'val_loss': 0.49163634497840125, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 94, 'train_loss': 0.4803124402307902, 'val_loss': 0.5105071024851756, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 95, 'train_loss': 0.4739327110626079, 'val_loss': 0.4977787120922192, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 96, 'train_loss': 0.47993460648790354, 'val_loss': 0.5007532136934297, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 97, 'train_loss': 0.48048357008282183, 'val_loss': 0.511313618840398, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 98, 'train_loss': 0.4832928776741028, 'val_loss': 0.49873269570840373, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 99, 'train_loss': 0.4760943267883275, 'val_loss': 0.4911573770883921, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 100, 'train_loss': 0.4789710150222586, 'val_loss': 0.5093572805593679, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 101, 'train_loss': 0.484060920649506, 'val_loss': 0.5012466499397347, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 102, 'train_loss': 0.4808173283984766, 'val_loss': 0.5110420708183769, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 103, 'train_loss': 0.4793000199176647, 'val_loss': 0.4995840948981208, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 104, 'train_loss': 0.4803901802409779, 'val_loss': 0.5007307722761825, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 105, 'train_loss': 0.47352477777686586, 'val_loss': 0.5093775568781672, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 106, 'train_loss': 0.47269434971038743, 'val_loss': 0.5032139168129312, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 107, 'train_loss': 0.47782141050505716, 'val_loss': 0.4979448919897681, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 108, 'train_loss': 0.47314081569311994, 'val_loss': 0.5112774651329797, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 109, 'train_loss': 0.4869451763653996, 'val_loss': 0.49878496737093536, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 110, 'train_loss': 0.4791707329276435, 'val_loss': 0.5113276232470263, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 111, 'train_loss': 0.46859573635589397, 'val_loss': 0.50917420945726, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 112, 'train_loss': 0.4639104587662501, 'val_loss': 0.520005853326471, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 113, 'train_loss': 0.48239847044350725, 'val_loss': 0.5159805572784699, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 114, 'train_loss': 0.4783762956307793, 'val_loss': 0.5267622492334865, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 115, 'train_loss': 0.47251492798930467, 'val_loss': 0.5076226071194485, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 116, 'train_loss': 0.47292720428620927, 'val_loss': 0.5180478310799813, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 117, 'train_loss': 0.4704567558235592, 'val_loss': 0.5221289213713225, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 118, 'train_loss': 0.47669289158249545, 'val_loss': 0.5196472202335392, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 119, 'train_loss': 0.4677112096487874, 'val_loss': 0.5214162259488493, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 120, 'train_loss': 0.4725060366620921, 'val_loss': 0.5030673774513038, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 121, 'train_loss': 0.479261496050992, 'val_loss': 0.5223602776054863, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 122, 'train_loss': 0.4694740049766772, 'val_loss': 0.5091992971059438, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 123, 'train_loss': 0.46469757934210676, 'val_loss': 0.5264750300226985, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 124, 'train_loss': 0.4727391042693295, 'val_loss': 0.5122552132821298, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 125, 'train_loss': 0.4576093920754262, 'val_loss': 0.5240095327566335, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 126, 'train_loss': 0.4663809434532718, 'val_loss': 0.5119591618443394, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 127, 'train_loss': 0.4679876436488797, 'val_loss': 0.5178146705971108, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 128, 'train_loss': 0.46805838001296174, 'val_loss': 0.5175418338260135, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 129, 'train_loss': 0.462334523196975, 'val_loss': 0.5274318488868507, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 130, 'train_loss': 0.4669521386775906, 'val_loss': 0.517407614905555, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 131, 'train_loss': 0.45500210780487316, 'val_loss': 0.5253957284463419, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 132, 'train_loss': 0.4648972573103728, 'val_loss': 0.5160073288926134, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 133, 'train_loss': 0.46093325462405527, 'val_loss': 0.5248944394223325, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 134, 'train_loss': 0.4639869854105041, 'val_loss': 0.539641268618472, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 135, 'train_loss': 0.4618520762783911, 'val_loss': 0.5334476264747413, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 136, 'train_loss': 0.46518322735121753, 'val_loss': 0.5338404715598166, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 137, 'train_loss': 0.46734054622425375, 'val_loss': 0.5165060747851122, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 138, 'train_loss': 0.468024560799101, 'val_loss': 0.5345162400254259, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 139, 'train_loss': 0.4575724142167705, 'val_loss': 0.5236280286634291, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 140, 'train_loss': 0.46109620730082196, 'val_loss': 0.5407600574665241, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 141, 'train_loss': 0.4546246775473007, 'val_loss': 0.5300367716196421, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 142, 'train_loss': 0.4495972116988917, 'val_loss': 0.5193050659454621, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 143, 'train_loss': 0.4558527289014874, 'val_loss': 0.5387073379379135, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 144, 'train_loss': 0.4571046881402783, 'val_loss': 0.5151885780128272, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 145, 'train_loss': 0.4533017291765823, 'val_loss': 0.5199478252513988, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 146, 'train_loss': 0.4499560430997149, 'val_loss': 0.5348528612841357, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 147, 'train_loss': 0.4573475121448337, 'val_loss': 0.5101706186930338, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 148, 'train_loss': 0.453385804036651, 'val_loss': 0.522910264161256, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 149, 'train_loss': 0.4549036635092212, 'val_loss': 0.522388320785385, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 150, 'train_loss': 0.458366271321621, 'val_loss': 0.5217899459976334, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 151, 'train_loss': 0.4514295346407778, 'val_loss': 0.5293823620220562, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 152, 'train_loss': 0.45731716635652664, 'val_loss': 0.5286250758815456, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 153, 'train_loss': 0.45525014350309917, 'val_loss': 0.5449898694012616, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 154, 'train_loss': 0.45242354093175946, 'val_loss': 0.5103436891023103, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 155, 'train_loss': 0.4480924453799572, 'val_loss': 0.5384062689703863, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 156, 'train_loss': 0.45471399621128633, 'val_loss': 0.5166075938456768, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 157, 'train_loss': 0.45963107094620215, 'val_loss': 0.5292720622844524, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 158, 'train_loss': 0.4421025477475189, 'val_loss': 0.5280269760269303, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 159, 'train_loss': 0.4524056643548638, 'val_loss': 0.5500755653725015, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 160, 'train_loss': 0.44565757065509704, 'val_loss': 0.524023588713225, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 161, 'train_loss': 0.4471313883158494, 'val_loss': 0.5256282187796928, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 162, 'train_loss': 0.4371181565904457, 'val_loss': 0.54909120164476, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 163, 'train_loss': 0.4517923712931097, 'val_loss': 0.531621469033731, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 164, 'train_loss': 0.4593855776770749, 'val_loss': 0.534335437121692, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 165, 'train_loss': 0.44929528156113546, 'val_loss': 0.5355176667909365, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 166, 'train_loss': 0.4467791599858088, 'val_loss': 0.5289164534560195, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 167, 'train_loss': 0.44380246830307674, 'val_loss': 0.53791754095404, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 168, 'train_loss': 0.4347706771258152, 'val_loss': 0.5351170376614407, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 169, 'train_loss': 0.4480579874732278, 'val_loss': 0.5415671752379821, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 170, 'train_loss': 0.4363035824563768, 'val_loss': 0.5505080867458034, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 171, 'train_loss': 0.44028791805309075, 'val_loss': 0.5459835121223519, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 172, 'train_loss': 0.43819883144664445, 'val_loss': 0.548451415053359, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 173, 'train_loss': 0.4254292039959519, 'val_loss': 0.5373609903696421, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 174, 'train_loss': 0.4452773302492469, 'val_loss': 0.538716221714879, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 175, 'train_loss': 0.43776773091919896, 'val_loss': 0.5281882758613106, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 176, 'train_loss': 0.4349971699594247, 'val_loss': 0.5716324024372272, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 177, 'train_loss': 0.43470572963708176, 'val_loss': 0.5504734451706345, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 178, 'train_loss': 0.4467946467576204, 'val_loss': 0.5359126254244968, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 179, 'train_loss': 0.4444952162628623, 'val_loss': 0.5474566897830447, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 180, 'train_loss': 0.4469766908823842, 'val_loss': 0.5784982389157957, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 181, 'train_loss': 0.4498508485278698, 'val_loss': 0.5494555911502322, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 182, 'train_loss': 0.4556814570619602, 'val_loss': 0.530324970279728, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 183, 'train_loss': 0.4337588394129718, 'val_loss': 0.547474801003396, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 184, 'train_loss': 0.42941433020713754, 'val_loss': 0.5387705210092906, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 185, 'train_loss': 0.4414613775733344, 'val_loss': 0.5553807267197618, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 186, 'train_loss': 0.44196411846864103, 'val_loss': 0.5388919383555919, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 187, 'train_loss': 0.4317747643499663, 'val_loss': 0.5432600244745478, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 188, 'train_loss': 0.4423975205983377, 'val_loss': 0.5589801685230152, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 189, 'train_loss': 0.4373053141715952, 'val_loss': 0.5426437274829762, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 190, 'train_loss': 0.423930515143205, 'val_loss': 0.5575699677338471, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 191, 'train_loss': 0.4346931172340406, 'val_loss': 0.5618123750428896, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 192, 'train_loss': 0.4240809538549044, 'val_loss': 0.5460115553022505, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 193, 'train_loss': 0.42343684669696924, 'val_loss': 0.5530097720859287, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 194, 'train_loss': 0.4321540931258539, 'val_loss': 0.558886347590266, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 195, 'train_loss': 0.42282355172866926, 'val_loss': 0.565315985464835, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 196, 'train_loss': 0.41561765953747914, 'val_loss': 0.5902022799930057, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 197, 'train_loss': 0.42175639568755924, 'val_loss': 0.5749826345357809, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 198, 'train_loss': 0.41736170107668097, 'val_loss': 0.5713371414322037, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 199, 'train_loss': 0.42309189023393573, 'val_loss': 0.5899333782024212, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 200, 'train_loss': 0.4256142958848163, 'val_loss': 0.5675441982509853, 'test_acc': 0.7657657657657657}
Val Loss: 0.5080, Test Accuracy: 0.731 ± 0.047, Duration: 79.342
Best result - 0.731 ± 0.047
--
COLLAB - Classifier
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'nn.glob.global_sort_pool' is deprecated, use 'nn.aggr.SortAggr' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.9988441750407219, 'val_loss': 0.9366344566345215, 'test_acc': 0.52}
{'fold': 9, 'epoch': 2, 'train_loss': 0.8162290492653846, 'val_loss': 0.6343054904937744, 'test_acc': 0.722}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5998524062335491, 'val_loss': 0.5357372074127197, 'test_acc': 0.736}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5451080198585987, 'val_loss': 0.5376266765594483, 'test_acc': 0.732}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5243073783814907, 'val_loss': 0.48979900455474856, 'test_acc': 0.744}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5080360101163387, 'val_loss': 0.49319976329803467, 'test_acc': 0.752}
{'fold': 9, 'epoch': 7, 'train_loss': 0.4986677920818329, 'val_loss': 0.4909257459640503, 'test_acc': 0.738}
{'fold': 9, 'epoch': 8, 'train_loss': 0.4839095976948738, 'val_loss': 0.46327436923980714, 'test_acc': 0.764}
{'fold': 9, 'epoch': 9, 'train_loss': 0.4733112868666649, 'val_loss': 0.5236524696350098, 'test_acc': 0.744}
{'fold': 9, 'epoch': 10, 'train_loss': 0.47142805889248846, 'val_loss': 0.46913068866729735, 'test_acc': 0.77}
{'fold': 9, 'epoch': 11, 'train_loss': 0.4651957541704178, 'val_loss': 0.44860728931427, 'test_acc': 0.776}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4549281744658947, 'val_loss': 0.4435464859008789, 'test_acc': 0.776}
{'fold': 9, 'epoch': 13, 'train_loss': 0.44986884474754335, 'val_loss': 0.4581576261520386, 'test_acc': 0.78}
{'fold': 9, 'epoch': 14, 'train_loss': 0.44719073563814166, 'val_loss': 0.43176831817626954, 'test_acc': 0.782}
{'fold': 9, 'epoch': 15, 'train_loss': 0.42900093212723733, 'val_loss': 0.4283733196258545, 'test_acc': 0.792}
{'fold': 9, 'epoch': 16, 'train_loss': 0.4247483715415001, 'val_loss': 0.43249268913269046, 'test_acc': 0.796}
{'fold': 9, 'epoch': 17, 'train_loss': 0.4210050582885742, 'val_loss': 0.4248038291931152, 'test_acc': 0.8}
{'fold': 9, 'epoch': 18, 'train_loss': 0.4089821156859398, 'val_loss': 0.43276812648773194, 'test_acc': 0.78}
{'fold': 9, 'epoch': 19, 'train_loss': 0.4018686120212078, 'val_loss': 0.43537317657470703, 'test_acc': 0.81}
{'fold': 9, 'epoch': 20, 'train_loss': 0.40241652868688105, 'val_loss': 0.4206230602264404, 'test_acc': 0.796}
{'fold': 9, 'epoch': 21, 'train_loss': 0.3914767475426197, 'val_loss': 0.4346353664398193, 'test_acc': 0.798}
{'fold': 9, 'epoch': 22, 'train_loss': 0.390935558155179, 'val_loss': 0.4750246706008911, 'test_acc': 0.796}
{'fold': 9, 'epoch': 23, 'train_loss': 0.3826942610740662, 'val_loss': 0.41573105573654173, 'test_acc': 0.806}
{'fold': 9, 'epoch': 24, 'train_loss': 0.379317936450243, 'val_loss': 0.42950307273864746, 'test_acc': 0.79}
{'fold': 9, 'epoch': 25, 'train_loss': 0.383210853934288, 'val_loss': 0.4238098611831665, 'test_acc': 0.81}
{'fold': 9, 'epoch': 26, 'train_loss': 0.37351701632142065, 'val_loss': 0.4189591784477234, 'test_acc': 0.816}
{'fold': 9, 'epoch': 27, 'train_loss': 0.37256317369639874, 'val_loss': 0.43247059631347656, 'test_acc': 0.79}
{'fold': 9, 'epoch': 28, 'train_loss': 0.3677313512563705, 'val_loss': 0.4575530300140381, 'test_acc': 0.802}
{'fold': 9, 'epoch': 29, 'train_loss': 0.3649876624345779, 'val_loss': 0.43355067348480225, 'test_acc': 0.8}
{'fold': 9, 'epoch': 30, 'train_loss': 0.35798444613814356, 'val_loss': 0.45030935859680177, 'test_acc': 0.804}
{'fold': 9, 'epoch': 31, 'train_loss': 0.3549591986835003, 'val_loss': 0.45301341247558596, 'test_acc': 0.808}
{'fold': 9, 'epoch': 32, 'train_loss': 0.35273735627532005, 'val_loss': 0.4241384210586548, 'test_acc': 0.802}
{'fold': 9, 'epoch': 33, 'train_loss': 0.3488391400128603, 'val_loss': 0.48078015327453616, 'test_acc': 0.812}
{'fold': 9, 'epoch': 34, 'train_loss': 0.3549506325274706, 'val_loss': 0.48676588439941404, 'test_acc': 0.806}
{'fold': 9, 'epoch': 35, 'train_loss': 0.33241421699523926, 'val_loss': 0.43980759811401365, 'test_acc': 0.808}
{'fold': 9, 'epoch': 36, 'train_loss': 0.3321265012025833, 'val_loss': 0.4799948558807373, 'test_acc': 0.8}
{'fold': 9, 'epoch': 37, 'train_loss': 0.35528651244938375, 'val_loss': 0.4374312148094177, 'test_acc': 0.806}
{'fold': 9, 'epoch': 38, 'train_loss': 0.33956065252423284, 'val_loss': 0.44419004011154173, 'test_acc': 0.796}
{'fold': 9, 'epoch': 39, 'train_loss': 0.335145301669836, 'val_loss': 0.45877554893493655, 'test_acc': 0.796}
{'fold': 9, 'epoch': 40, 'train_loss': 0.33235051959753037, 'val_loss': 0.4468065299987793, 'test_acc': 0.798}
{'fold': 9, 'epoch': 41, 'train_loss': 0.3223093031346798, 'val_loss': 0.4783601226806641, 'test_acc': 0.778}
{'fold': 9, 'epoch': 42, 'train_loss': 0.3204188172519207, 'val_loss': 0.4451402978897095, 'test_acc': 0.798}
{'fold': 9, 'epoch': 43, 'train_loss': 0.32690894104540347, 'val_loss': 0.4879176330566406, 'test_acc': 0.806}
{'fold': 9, 'epoch': 44, 'train_loss': 0.31778504215180875, 'val_loss': 0.4937836990356445, 'test_acc': 0.802}
{'fold': 9, 'epoch': 45, 'train_loss': 0.31350526012480256, 'val_loss': 0.5481119575500488, 'test_acc': 0.788}
{'fold': 9, 'epoch': 46, 'train_loss': 0.30687934316694737, 'val_loss': 0.49206468963623046, 'test_acc': 0.806}
{'fold': 9, 'epoch': 47, 'train_loss': 0.3071104510128498, 'val_loss': 0.4642427225112915, 'test_acc': 0.802}
{'fold': 9, 'epoch': 48, 'train_loss': 0.31761469423770905, 'val_loss': 0.497189603805542, 'test_acc': 0.816}
{'fold': 9, 'epoch': 49, 'train_loss': 0.31003005474805834, 'val_loss': 0.4648199453353882, 'test_acc': 0.79}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3064986806362867, 'val_loss': 0.5146424837112427, 'test_acc': 0.812}
{'fold': 9, 'epoch': 51, 'train_loss': 0.30094113886356355, 'val_loss': 0.47339524126052857, 'test_acc': 0.788}
{'fold': 9, 'epoch': 52, 'train_loss': 0.30233781665563586, 'val_loss': 0.46763057041168216, 'test_acc': 0.798}
{'fold': 9, 'epoch': 53, 'train_loss': 0.29588646061718465, 'val_loss': 0.48369449901580813, 'test_acc': 0.816}
{'fold': 9, 'epoch': 54, 'train_loss': 0.29388210937380793, 'val_loss': 0.4920965805053711, 'test_acc': 0.794}
{'fold': 9, 'epoch': 55, 'train_loss': 0.29691155299544336, 'val_loss': 0.5103694806098938, 'test_acc': 0.802}
{'fold': 9, 'epoch': 56, 'train_loss': 0.29098371893167496, 'val_loss': 0.47387749576568605, 'test_acc': 0.816}
{'fold': 9, 'epoch': 57, 'train_loss': 0.29136720262467863, 'val_loss': 0.5179306855201721, 'test_acc': 0.804}
{'fold': 9, 'epoch': 58, 'train_loss': 0.28626859925687315, 'val_loss': 0.49126993465423585, 'test_acc': 0.798}
{'fold': 9, 'epoch': 59, 'train_loss': 0.28311265163123606, 'val_loss': 0.5300723803043366, 'test_acc': 0.794}
{'fold': 9, 'epoch': 60, 'train_loss': 0.2923683478310704, 'val_loss': 0.5002015762329102, 'test_acc': 0.8}
{'fold': 9, 'epoch': 61, 'train_loss': 0.27195565924048426, 'val_loss': 0.5363045868873596, 'test_acc': 0.818}
{'fold': 9, 'epoch': 62, 'train_loss': 0.28559182103723285, 'val_loss': 0.4916957631111145, 'test_acc': 0.802}
{'fold': 9, 'epoch': 63, 'train_loss': 0.2872091539204121, 'val_loss': 0.49292591428756716, 'test_acc': 0.802}
{'fold': 9, 'epoch': 64, 'train_loss': 0.2805424699187279, 'val_loss': 0.539206181526184, 'test_acc': 0.812}
{'fold': 9, 'epoch': 65, 'train_loss': 0.26921710394322873, 'val_loss': 0.5321611661911011, 'test_acc': 0.812}
{'fold': 9, 'epoch': 66, 'train_loss': 0.2727205618470907, 'val_loss': 0.5705346622467041, 'test_acc': 0.794}
{'fold': 9, 'epoch': 67, 'train_loss': 0.29206132955849173, 'val_loss': 0.5005258121490479, 'test_acc': 0.804}
{'fold': 9, 'epoch': 68, 'train_loss': 0.2663727057725191, 'val_loss': 0.5602953262329101, 'test_acc': 0.806}
{'fold': 9, 'epoch': 69, 'train_loss': 0.26796219527721404, 'val_loss': 0.5743412542343139, 'test_acc': 0.79}
{'fold': 9, 'epoch': 70, 'train_loss': 0.26847236715257167, 'val_loss': 0.5448840336799622, 'test_acc': 0.818}
{'fold': 9, 'epoch': 71, 'train_loss': 0.2658456955850124, 'val_loss': 0.522450587272644, 'test_acc': 0.804}
{'fold': 9, 'epoch': 72, 'train_loss': 0.27124928127974274, 'val_loss': 0.5833443546295166, 'test_acc': 0.812}
{'fold': 9, 'epoch': 73, 'train_loss': 0.2686993659287691, 'val_loss': 0.5283850183486939, 'test_acc': 0.804}
{'fold': 9, 'epoch': 74, 'train_loss': 0.26445913687348366, 'val_loss': 0.6182602710723877, 'test_acc': 0.808}
{'fold': 9, 'epoch': 75, 'train_loss': 0.26701559230685235, 'val_loss': 0.5691110725402833, 'test_acc': 0.806}
{'fold': 9, 'epoch': 76, 'train_loss': 0.2531893714144826, 'val_loss': 0.5415153417587281, 'test_acc': 0.798}
{'fold': 9, 'epoch': 77, 'train_loss': 0.26697309847921136, 'val_loss': 0.5509193592071533, 'test_acc': 0.802}
{'fold': 9, 'epoch': 78, 'train_loss': 0.25134362205863, 'val_loss': 0.5671639785766601, 'test_acc': 0.802}
{'fold': 9, 'epoch': 79, 'train_loss': 0.24764861606061458, 'val_loss': 0.5871937894821166, 'test_acc': 0.804}
{'fold': 9, 'epoch': 80, 'train_loss': 0.2544073845818639, 'val_loss': 0.583565245628357, 'test_acc': 0.814}
{'fold': 9, 'epoch': 81, 'train_loss': 0.24291382633149625, 'val_loss': 0.6084438047409058, 'test_acc': 0.806}
{'fold': 9, 'epoch': 82, 'train_loss': 0.2527900543995202, 'val_loss': 0.5867126865386962, 'test_acc': 0.798}
{'fold': 9, 'epoch': 83, 'train_loss': 0.2643172999471426, 'val_loss': 0.6198481607437134, 'test_acc': 0.812}
{'fold': 9, 'epoch': 84, 'train_loss': 0.24924849301576615, 'val_loss': 0.5932182674407959, 'test_acc': 0.816}
{'fold': 9, 'epoch': 85, 'train_loss': 0.24706807229667901, 'val_loss': 0.6590606098175049, 'test_acc': 0.81}
{'fold': 9, 'epoch': 86, 'train_loss': 0.2473495329171419, 'val_loss': 0.5906028776168823, 'test_acc': 0.806}
{'fold': 9, 'epoch': 87, 'train_loss': 0.24993310660123824, 'val_loss': 0.6423799619674683, 'test_acc': 0.82}
{'fold': 9, 'epoch': 88, 'train_loss': 0.23835037678480148, 'val_loss': 0.6449804515838623, 'test_acc': 0.802}
{'fold': 9, 'epoch': 89, 'train_loss': 0.23488605774939061, 'val_loss': 0.6225625467300415, 'test_acc': 0.792}
{'fold': 9, 'epoch': 90, 'train_loss': 0.2327316154539585, 'val_loss': 0.6027269916534423, 'test_acc': 0.8}
{'fold': 9, 'epoch': 91, 'train_loss': 0.24714113786816597, 'val_loss': 0.5871912655830384, 'test_acc': 0.79}
{'fold': 9, 'epoch': 92, 'train_loss': 0.24034486845135689, 'val_loss': 0.6589612503051758, 'test_acc': 0.808}
{'fold': 9, 'epoch': 93, 'train_loss': 0.22843734238296748, 'val_loss': 0.6588926277160645, 'test_acc': 0.8}
{'fold': 9, 'epoch': 94, 'train_loss': 0.24395519360899925, 'val_loss': 0.703885443687439, 'test_acc': 0.806}
{'fold': 9, 'epoch': 95, 'train_loss': 0.27485750295221806, 'val_loss': 0.6652557592391968, 'test_acc': 0.792}
{'fold': 9, 'epoch': 96, 'train_loss': 0.2352948159724474, 'val_loss': 0.5738570790290832, 'test_acc': 0.784}
{'fold': 9, 'epoch': 97, 'train_loss': 0.2357171792164445, 'val_loss': 0.704271282196045, 'test_acc': 0.808}
{'fold': 9, 'epoch': 98, 'train_loss': 0.22591594252735375, 'val_loss': 0.6565591411590577, 'test_acc': 0.798}
{'fold': 9, 'epoch': 99, 'train_loss': 0.2290600870549679, 'val_loss': 0.681986047744751, 'test_acc': 0.816}
{'fold': 9, 'epoch': 100, 'train_loss': 0.23681040663272143, 'val_loss': 0.683837739944458, 'test_acc': 0.806}
{'fold': 9, 'epoch': 101, 'train_loss': 0.22609446417540313, 'val_loss': 0.6588619203567505, 'test_acc': 0.802}
{'fold': 9, 'epoch': 102, 'train_loss': 0.22072549380362033, 'val_loss': 0.6468557529449462, 'test_acc': 0.814}
{'fold': 9, 'epoch': 103, 'train_loss': 0.22429065693169833, 'val_loss': 0.6406149549484252, 'test_acc': 0.796}
{'fold': 9, 'epoch': 104, 'train_loss': 0.228518538326025, 'val_loss': 0.6916994895935059, 'test_acc': 0.806}
{'fold': 9, 'epoch': 105, 'train_loss': 0.22411449611186982, 'val_loss': 0.6416961154937744, 'test_acc': 0.806}
{'fold': 9, 'epoch': 106, 'train_loss': 0.22351667582988738, 'val_loss': 0.6698762245178222, 'test_acc': 0.79}
{'fold': 9, 'epoch': 107, 'train_loss': 0.23076848581433296, 'val_loss': 0.6808088283538818, 'test_acc': 0.802}
{'fold': 9, 'epoch': 108, 'train_loss': 0.2128769395314157, 'val_loss': 0.6899692029953003, 'test_acc': 0.806}
{'fold': 9, 'epoch': 109, 'train_loss': 0.22289461158216, 'val_loss': 0.6770993556976318, 'test_acc': 0.804}
{'fold': 9, 'epoch': 110, 'train_loss': 0.21920164953917265, 'val_loss': 0.6586853342056275, 'test_acc': 0.804}
{'fold': 9, 'epoch': 111, 'train_loss': 0.2150544971227646, 'val_loss': 0.7487149791717529, 'test_acc': 0.8}
{'fold': 9, 'epoch': 112, 'train_loss': 0.2236526994034648, 'val_loss': 0.6404331388473511, 'test_acc': 0.778}
{'fold': 9, 'epoch': 113, 'train_loss': 0.21640122819691895, 'val_loss': 0.6825924530029297, 'test_acc': 0.804}
{'fold': 9, 'epoch': 114, 'train_loss': 0.20456893470138313, 'val_loss': 0.6954828090667725, 'test_acc': 0.8}
{'fold': 9, 'epoch': 115, 'train_loss': 0.21699866466224194, 'val_loss': 0.7040319423675537, 'test_acc': 0.788}
{'fold': 9, 'epoch': 116, 'train_loss': 0.2131186121329665, 'val_loss': 0.7145733509063721, 'test_acc': 0.794}
{'fold': 9, 'epoch': 117, 'train_loss': 0.20858314663171768, 'val_loss': 0.691871768951416, 'test_acc': 0.802}
{'fold': 9, 'epoch': 118, 'train_loss': 0.2077156787738204, 'val_loss': 0.6482096920013428, 'test_acc': 0.794}
{'fold': 9, 'epoch': 119, 'train_loss': 0.2053836126253009, 'val_loss': 0.7115890445709229, 'test_acc': 0.782}
{'fold': 9, 'epoch': 120, 'train_loss': 0.21706297799944876, 'val_loss': 0.6721455364227295, 'test_acc': 0.8}
{'fold': 9, 'epoch': 121, 'train_loss': 0.2233158314973116, 'val_loss': 0.7482183704376221, 'test_acc': 0.802}
{'fold': 9, 'epoch': 122, 'train_loss': 0.21206151247024535, 'val_loss': 0.6857677330970764, 'test_acc': 0.792}
{'fold': 9, 'epoch': 123, 'train_loss': 0.19004913192242384, 'val_loss': 0.7162332344055176, 'test_acc': 0.796}
{'fold': 9, 'epoch': 124, 'train_loss': 0.20865847453474998, 'val_loss': 0.6962098159790039, 'test_acc': 0.808}
{'fold': 9, 'epoch': 125, 'train_loss': 0.19512883085757493, 'val_loss': 0.7627898197174072, 'test_acc': 0.796}
{'fold': 9, 'epoch': 126, 'train_loss': 0.2123058194667101, 'val_loss': 0.8036989345550537, 'test_acc': 0.806}
{'fold': 9, 'epoch': 127, 'train_loss': 0.20491247329860926, 'val_loss': 0.7305528149604797, 'test_acc': 0.798}
{'fold': 9, 'epoch': 128, 'train_loss': 0.19471624478697777, 'val_loss': 0.7968535771369935, 'test_acc': 0.794}
{'fold': 9, 'epoch': 129, 'train_loss': 0.20647196900099515, 'val_loss': 0.8029425067901611, 'test_acc': 0.806}
{'fold': 9, 'epoch': 130, 'train_loss': 0.20487906325608493, 'val_loss': 0.7542631034851074, 'test_acc': 0.804}
{'fold': 9, 'epoch': 131, 'train_loss': 0.20021171744912863, 'val_loss': 0.8491942348480225, 'test_acc': 0.806}
{'fold': 9, 'epoch': 132, 'train_loss': 0.20757794372737406, 'val_loss': 0.783135890007019, 'test_acc': 0.8}
{'fold': 9, 'epoch': 133, 'train_loss': 0.2226997059211135, 'val_loss': 0.7564334292411804, 'test_acc': 0.802}
{'fold': 9, 'epoch': 134, 'train_loss': 0.20564086690545083, 'val_loss': 0.7722797622680664, 'test_acc': 0.786}
{'fold': 9, 'epoch': 135, 'train_loss': 0.2048904082737863, 'val_loss': 0.7280073299407959, 'test_acc': 0.8}
{'fold': 9, 'epoch': 136, 'train_loss': 0.2049154333770275, 'val_loss': 0.7563403744697571, 'test_acc': 0.808}
{'fold': 9, 'epoch': 137, 'train_loss': 0.18766357658430935, 'val_loss': 0.8307001476287842, 'test_acc': 0.804}
{'fold': 9, 'epoch': 138, 'train_loss': 0.1962230628542602, 'val_loss': 0.7864434680938721, 'test_acc': 0.812}
{'fold': 9, 'epoch': 139, 'train_loss': 0.1905006156116724, 'val_loss': 0.8255009679794312, 'test_acc': 0.798}
{'fold': 9, 'epoch': 140, 'train_loss': 0.18114470161497592, 'val_loss': 0.9115917415618896, 'test_acc': 0.796}
{'fold': 9, 'epoch': 141, 'train_loss': 0.1921977359056473, 'val_loss': 0.7970007429122925, 'test_acc': 0.81}
{'fold': 9, 'epoch': 142, 'train_loss': 0.18284293819218875, 'val_loss': 0.8115880603790283, 'test_acc': 0.792}
{'fold': 9, 'epoch': 143, 'train_loss': 0.19256097167730332, 'val_loss': 0.8622303705215454, 'test_acc': 0.806}
{'fold': 9, 'epoch': 144, 'train_loss': 0.18422443144023418, 'val_loss': 0.7673711452484131, 'test_acc': 0.788}
{'fold': 9, 'epoch': 145, 'train_loss': 0.1777712567895651, 'val_loss': 0.7604018468856811, 'test_acc': 0.796}
{'fold': 9, 'epoch': 146, 'train_loss': 0.1845503956079483, 'val_loss': 0.803415988445282, 'test_acc': 0.804}
{'fold': 9, 'epoch': 147, 'train_loss': 0.18252291802316903, 'val_loss': 0.7907291765213013, 'test_acc': 0.798}
{'fold': 9, 'epoch': 148, 'train_loss': 0.1863791162893176, 'val_loss': 0.8713136911392212, 'test_acc': 0.802}
{'fold': 9, 'epoch': 149, 'train_loss': 0.18796739161014556, 'val_loss': 0.8382774925231934, 'test_acc': 0.81}
{'fold': 9, 'epoch': 150, 'train_loss': 0.19746392268687488, 'val_loss': 0.7949734058380127, 'test_acc': 0.794}
{'fold': 9, 'epoch': 151, 'train_loss': 0.19566190384328366, 'val_loss': 1.0845857543945312, 'test_acc': 0.798}
{'fold': 9, 'epoch': 152, 'train_loss': 0.208056000508368, 'val_loss': 0.7677481994628906, 'test_acc': 0.81}
{'fold': 9, 'epoch': 153, 'train_loss': 0.1862729622796178, 'val_loss': 0.8298743009567261, 'test_acc': 0.79}
{'fold': 9, 'epoch': 154, 'train_loss': 0.19226711224764587, 'val_loss': 0.9168930377960205, 'test_acc': 0.8}
{'fold': 9, 'epoch': 155, 'train_loss': 0.170437522046268, 'val_loss': 0.7823632555007934, 'test_acc': 0.806}
{'fold': 9, 'epoch': 156, 'train_loss': 0.18114077420905234, 'val_loss': 0.9193295516967773, 'test_acc': 0.804}
{'fold': 9, 'epoch': 157, 'train_loss': 0.17822554202750326, 'val_loss': 0.8476628475189208, 'test_acc': 0.794}
{'fold': 9, 'epoch': 158, 'train_loss': 0.17331778284162283, 'val_loss': 0.8558802680969239, 'test_acc': 0.804}
{'fold': 9, 'epoch': 159, 'train_loss': 0.17260108571499586, 'val_loss': 0.7909888353347778, 'test_acc': 0.808}
{'fold': 9, 'epoch': 160, 'train_loss': 0.1757637294381857, 'val_loss': 0.8614878253936767, 'test_acc': 0.808}
{'fold': 9, 'epoch': 161, 'train_loss': 0.17803984362632036, 'val_loss': 0.8390290560722351, 'test_acc': 0.802}
{'fold': 9, 'epoch': 162, 'train_loss': 0.16844066370278596, 'val_loss': 0.8515999484062194, 'test_acc': 0.806}
{'fold': 9, 'epoch': 163, 'train_loss': 0.1809461056254804, 'val_loss': 0.8740786762237549, 'test_acc': 0.8}
{'fold': 9, 'epoch': 164, 'train_loss': 0.17004398699849843, 'val_loss': 0.8646827440261841, 'test_acc': 0.79}
{'fold': 9, 'epoch': 165, 'train_loss': 0.17570613823831083, 'val_loss': 0.8259417638778687, 'test_acc': 0.79}
{'fold': 9, 'epoch': 166, 'train_loss': 0.16830420009791852, 'val_loss': 0.8481520423889161, 'test_acc': 0.798}
{'fold': 9, 'epoch': 167, 'train_loss': 0.1768310586735606, 'val_loss': 0.8666731147766114, 'test_acc': 0.798}
{'fold': 9, 'epoch': 168, 'train_loss': 0.16999983113259076, 'val_loss': 0.9649333076477051, 'test_acc': 0.806}
{'fold': 9, 'epoch': 169, 'train_loss': 0.16834664072841407, 'val_loss': 0.8928039398193359, 'test_acc': 0.796}
{'fold': 9, 'epoch': 170, 'train_loss': 0.19198550641536713, 'val_loss': 0.7850533046722412, 'test_acc': 0.8}
{'fold': 9, 'epoch': 171, 'train_loss': 0.17156526455655693, 'val_loss': 0.8548323335647583, 'test_acc': 0.808}
{'fold': 9, 'epoch': 172, 'train_loss': 0.1614068078622222, 'val_loss': 0.8623123502731324, 'test_acc': 0.808}
{'fold': 9, 'epoch': 173, 'train_loss': 0.1786331620812416, 'val_loss': 0.9103877544403076, 'test_acc': 0.806}
{'fold': 9, 'epoch': 174, 'train_loss': 0.16438691046088935, 'val_loss': 0.9525925884246826, 'test_acc': 0.804}
{'fold': 9, 'epoch': 175, 'train_loss': 0.16785122707486153, 'val_loss': 0.7505028247833252, 'test_acc': 0.794}
{'fold': 9, 'epoch': 176, 'train_loss': 0.1718444949015975, 'val_loss': 0.848466157913208, 'test_acc': 0.8}
{'fold': 9, 'epoch': 177, 'train_loss': 0.16259946834295988, 'val_loss': 0.9771980533599853, 'test_acc': 0.802}
{'fold': 9, 'epoch': 178, 'train_loss': 0.16497004855424166, 'val_loss': 0.9453283004760742, 'test_acc': 0.8}
{'fold': 9, 'epoch': 179, 'train_loss': 0.16108744069933892, 'val_loss': 0.8917337799072266, 'test_acc': 0.804}
{'fold': 9, 'epoch': 180, 'train_loss': 0.15480712603777647, 'val_loss': 0.9120977096557618, 'test_acc': 0.798}
{'fold': 9, 'epoch': 181, 'train_loss': 0.17401625391095876, 'val_loss': 0.8829335803985596, 'test_acc': 0.798}
{'fold': 9, 'epoch': 182, 'train_loss': 0.18141450066119433, 'val_loss': 0.8294286308288574, 'test_acc': 0.8}
{'fold': 9, 'epoch': 183, 'train_loss': 0.164881893042475, 'val_loss': 0.8547161083221435, 'test_acc': 0.806}
{'fold': 9, 'epoch': 184, 'train_loss': 0.16367900263518095, 'val_loss': 0.8031676807403565, 'test_acc': 0.786}
{'fold': 9, 'epoch': 185, 'train_loss': 0.1681658861041069, 'val_loss': 0.8321901092529297, 'test_acc': 0.794}
{'fold': 9, 'epoch': 186, 'train_loss': 0.159377993773669, 'val_loss': 0.8839981346130371, 'test_acc': 0.804}
{'fold': 9, 'epoch': 187, 'train_loss': 0.1619876102730632, 'val_loss': 0.8234936103820801, 'test_acc': 0.802}
{'fold': 9, 'epoch': 188, 'train_loss': 0.15743211779743432, 'val_loss': 0.8592900314331055, 'test_acc': 0.8}
{'fold': 9, 'epoch': 189, 'train_loss': 0.16595490626990794, 'val_loss': 1.031779727935791, 'test_acc': 0.808}
{'fold': 9, 'epoch': 190, 'train_loss': 0.18663745492696762, 'val_loss': 0.8675319919586182, 'test_acc': 0.808}
{'fold': 9, 'epoch': 191, 'train_loss': 0.1599835295788944, 'val_loss': 0.9039674072265625, 'test_acc': 0.81}
{'fold': 9, 'epoch': 192, 'train_loss': 0.1607387143932283, 'val_loss': 0.8667120704650879, 'test_acc': 0.794}
{'fold': 9, 'epoch': 193, 'train_loss': 0.15871382178738713, 'val_loss': 0.898672179222107, 'test_acc': 0.796}
{'fold': 9, 'epoch': 194, 'train_loss': 0.14591773035004735, 'val_loss': 0.9349214353561401, 'test_acc': 0.802}
{'fold': 9, 'epoch': 195, 'train_loss': 0.14322126749902964, 'val_loss': 1.0223063869476319, 'test_acc': 0.808}
{'fold': 9, 'epoch': 196, 'train_loss': 0.1591823323443532, 'val_loss': 0.9651768608093262, 'test_acc': 0.808}
{'fold': 9, 'epoch': 197, 'train_loss': 0.15523332132026554, 'val_loss': 1.1256218280792236, 'test_acc': 0.808}
{'fold': 9, 'epoch': 198, 'train_loss': 0.16506613716483115, 'val_loss': 1.0798858318328857, 'test_acc': 0.808}
{'fold': 9, 'epoch': 199, 'train_loss': 0.15960569944232703, 'val_loss': 1.0486413764953613, 'test_acc': 0.802}
{'fold': 9, 'epoch': 200, 'train_loss': 0.16435624212026595, 'val_loss': 0.9133191165924073, 'test_acc': 0.806}
Val Loss: 0.4385, Test Accuracy: 0.799 ± 0.016, Duration: 533.576
Best result - 0.799 ± 0.016
--
IMDB-MULTI - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(89, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=32, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=3, bias=True)
  )
): 0.498 ± 0.029
MUTAG - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(7, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=160, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=2, bias=True)
  )
): 0.857 ± 0.087
IMDB-BINARY - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(136, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=160, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=2, bias=True)
  )
): 0.736 ± 0.041
REDDIT-BINARY - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(1, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=5760, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=2, bias=True)
  )
): 0.878 ± 0.026
DD - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(89, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=4512, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=2, bias=True)
  )
): 0.776 ± 0.021
NCI1 - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(37, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=352, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=2, bias=True)
  )
): 0.750 ± 0.019
PROTEINS - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(3, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=384, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=2, bias=True)
  )
): 0.731 ± 0.047
COLLAB - Classifier(
  (feature_extractor): GraphUNet(
    (down_convs): ModuleList(
      (0): GCNConv(492, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(48, 48)
    )
    (pools): ModuleList(
      (0): TopKPooling(48, ratio=0.9, multiplier=1.0)
      (1): TopKPooling(48, ratio=0.7, multiplier=1.0)
      (2): TopKPooling(48, ratio=0.6, multiplier=1.0)
      (3): TopKPooling(48, ratio=0.5, multiplier=1.0)
    )
    (bn_layers): ModuleList(
      (0): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (up_convs): ModuleList(
      (0): GCNConv(48, 48)
      (1): GCNConv(48, 48)
      (2): GCNConv(48, 48)
      (3): GCNConv(48, 48)
      (4): GCNConv(96, 97)
    )
    (drop): Dropout(p=0.3, inplace=False)
  )
  (readout): Conv1dReadout(
    (conv1d_p1): Conv1d(1, 16, kernel_size=(97,), stride=(97,))
    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv1d_p2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))
  )
  (mlp): MLPClassifier(
    (h1_weights): Linear(in_features=832, out_features=128, bias=True)
    (h2_weights): Linear(in_features=128, out_features=3, bias=True)
  )
): 0.799 ± 0.016

Process finished with exit code 0
