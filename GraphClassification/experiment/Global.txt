D:\Program\Anaconda\envs\pyg\python.exe F:/Project/BernNet/GraphClassification/main.py
--
IMDB-MULTI - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 1.1025672912597657, 'val_loss': 1.0755664825439453, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 2, 'train_loss': 1.0625924571355183, 'val_loss': 1.0682393646240234, 'test_acc': 0.36666666666666664}
{'fold': 9, 'epoch': 3, 'train_loss': 1.062273071606954, 'val_loss': 1.0149999491373698, 'test_acc': 0.43333333333333335}
{'fold': 9, 'epoch': 4, 'train_loss': 1.0143529828389486, 'val_loss': 1.0197823842366536, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 5, 'train_loss': 0.9932986291249594, 'val_loss': 0.9996326955159506, 'test_acc': 0.48}
{'fold': 9, 'epoch': 6, 'train_loss': 1.0008593734105429, 'val_loss': 1.00712952931722, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 7, 'train_loss': 0.9887729279200236, 'val_loss': 1.0131299463907877, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 8, 'train_loss': 0.998201359907786, 'val_loss': 1.04400452931722, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 9, 'train_loss': 1.002205163637797, 'val_loss': 1.0290627415974936, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 10, 'train_loss': 0.9870258649190267, 'val_loss': 1.0175143432617189, 'test_acc': 0.5}
{'fold': 9, 'epoch': 11, 'train_loss': 0.9774906762440999, 'val_loss': 1.0162204233805339, 'test_acc': 0.5}
{'fold': 9, 'epoch': 12, 'train_loss': 0.9633673016230265, 'val_loss': 1.0413721466064454, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 13, 'train_loss': 0.9802324295043945, 'val_loss': 1.072636884053548, 'test_acc': 0.5}
{'fold': 9, 'epoch': 14, 'train_loss': 0.9820889321962992, 'val_loss': 1.0732344309488933, 'test_acc': 0.52}
{'fold': 9, 'epoch': 15, 'train_loss': 0.9818986105918884, 'val_loss': 1.026390037536621, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 16, 'train_loss': 0.9869329229990641, 'val_loss': 1.069569320678711, 'test_acc': 0.48}
{'fold': 9, 'epoch': 17, 'train_loss': 0.975191950003306, 'val_loss': 1.154221560160319, 'test_acc': 0.5}
{'fold': 9, 'epoch': 18, 'train_loss': 0.977168148358663, 'val_loss': 1.0813970438639322, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 19, 'train_loss': 0.9644558358192444, 'val_loss': 1.0727560679117838, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 20, 'train_loss': 0.9616984168688456, 'val_loss': 1.2363501103719075, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 21, 'train_loss': 0.9553896085421244, 'val_loss': 1.1745735677083333, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 22, 'train_loss': 0.961986198425293, 'val_loss': 1.0898765309651692, 'test_acc': 0.5}
{'fold': 9, 'epoch': 23, 'train_loss': 0.9570207937558493, 'val_loss': 1.1261752065022785, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 24, 'train_loss': 0.952102608680725, 'val_loss': 1.1312355931599936, 'test_acc': 0.5}
{'fold': 9, 'epoch': 25, 'train_loss': 0.9436491934458414, 'val_loss': 1.2081409454345704, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 26, 'train_loss': 0.9402389272054037, 'val_loss': 1.2902474848429362, 'test_acc': 0.44666666666666666}
{'fold': 9, 'epoch': 27, 'train_loss': 0.936483523050944, 'val_loss': 1.1403114191691082, 'test_acc': 0.4266666666666667}
{'fold': 9, 'epoch': 28, 'train_loss': 0.9422279524803162, 'val_loss': 1.4245560709635416, 'test_acc': 0.52}
{'fold': 9, 'epoch': 29, 'train_loss': 0.927043571472168, 'val_loss': 1.2440665690104167, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 30, 'train_loss': 0.9435128021240234, 'val_loss': 1.2023080571492513, 'test_acc': 0.4066666666666667}
{'fold': 9, 'epoch': 31, 'train_loss': 0.9463847120602925, 'val_loss': 2.1233852895100913, 'test_acc': 0.43333333333333335}
{'fold': 9, 'epoch': 32, 'train_loss': 0.9613247179985046, 'val_loss': 1.1296473693847657, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 33, 'train_loss': 0.9664476044972737, 'val_loss': 1.0480066935221355, 'test_acc': 0.4666666666666667}
{'fold': 9, 'epoch': 34, 'train_loss': 0.9625028379758199, 'val_loss': 1.290567855834961, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 35, 'train_loss': 0.9388280987739563, 'val_loss': 1.1929949442545573, 'test_acc': 0.5}
{'fold': 9, 'epoch': 36, 'train_loss': 0.9447688706715902, 'val_loss': 1.2614309438069662, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 37, 'train_loss': 0.9304678392410278, 'val_loss': 1.4031104405721029, 'test_acc': 0.4066666666666667}
{'fold': 9, 'epoch': 38, 'train_loss': 0.9243216768900553, 'val_loss': 1.6691959635416667, 'test_acc': 0.48}
{'fold': 9, 'epoch': 39, 'train_loss': 0.921954402923584, 'val_loss': 1.362162233988444, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 40, 'train_loss': 0.9003512088457744, 'val_loss': 1.282134958902995, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 41, 'train_loss': 0.9024731961886088, 'val_loss': 1.394897486368815, 'test_acc': 0.5}
{'fold': 9, 'epoch': 42, 'train_loss': 0.8881611402829488, 'val_loss': 1.8169651285807291, 'test_acc': 0.5}
{'fold': 9, 'epoch': 43, 'train_loss': 0.8970182355244954, 'val_loss': 1.315539042154948, 'test_acc': 0.44666666666666666}
{'fold': 9, 'epoch': 44, 'train_loss': 0.904026448726654, 'val_loss': 2.041611099243164, 'test_acc': 0.5}
{'fold': 9, 'epoch': 45, 'train_loss': 0.9131024003028869, 'val_loss': 1.2711310577392578, 'test_acc': 0.5}
{'fold': 9, 'epoch': 46, 'train_loss': 0.9227143581708273, 'val_loss': 1.5811693064371746, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 47, 'train_loss': 0.9069027400016785, 'val_loss': 1.4838023376464844, 'test_acc': 0.52}
{'fold': 9, 'epoch': 48, 'train_loss': 0.8982327262560527, 'val_loss': 1.941495361328125, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 49, 'train_loss': 0.9073712786038717, 'val_loss': 1.638893814086914, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 50, 'train_loss': 0.9275602753957113, 'val_loss': 1.6090163930257162, 'test_acc': 0.4533333333333333}
{'fold': 9, 'epoch': 51, 'train_loss': 0.9115096751848857, 'val_loss': 1.4040201314290364, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 52, 'train_loss': 0.9167987211545309, 'val_loss': 1.3307592137654622, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 53, 'train_loss': 0.9237462321917216, 'val_loss': 1.286156260172526, 'test_acc': 0.5}
{'fold': 9, 'epoch': 54, 'train_loss': 0.897745574315389, 'val_loss': 1.6957923380533855, 'test_acc': 0.4266666666666667}
{'fold': 9, 'epoch': 55, 'train_loss': 0.8878973420461019, 'val_loss': 1.7484334818522136, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 56, 'train_loss': 0.8867729004224142, 'val_loss': 2.038009974161784, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 57, 'train_loss': 0.9822262891133626, 'val_loss': 1.4371547444661459, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 58, 'train_loss': 0.9531284379959106, 'val_loss': 1.4693433380126952, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 59, 'train_loss': 0.9297690876324971, 'val_loss': 1.418909174601237, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 60, 'train_loss': 0.9037800367673238, 'val_loss': 1.3545348358154297, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 61, 'train_loss': 0.9251536591847738, 'val_loss': 1.5445566177368164, 'test_acc': 0.5}
{'fold': 9, 'epoch': 62, 'train_loss': 0.8812367979685466, 'val_loss': 1.5858856709798177, 'test_acc': 0.46}
{'fold': 9, 'epoch': 63, 'train_loss': 0.8799285769462586, 'val_loss': 1.8751206080118814, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 64, 'train_loss': 0.8824217025438944, 'val_loss': 1.4833319218953451, 'test_acc': 0.52}
{'fold': 9, 'epoch': 65, 'train_loss': 0.8713212911287943, 'val_loss': 1.667744255065918, 'test_acc': 0.44666666666666666}
{'fold': 9, 'epoch': 66, 'train_loss': 0.8611526234944662, 'val_loss': 1.4982111358642578, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 67, 'train_loss': 0.9316440200805665, 'val_loss': 1.654435806274414, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 68, 'train_loss': 0.867978010972341, 'val_loss': 1.9438408025105793, 'test_acc': 0.5}
{'fold': 9, 'epoch': 69, 'train_loss': 0.8848192890485128, 'val_loss': 1.393558807373047, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 70, 'train_loss': 0.892198314666748, 'val_loss': 1.5606283315022786, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 71, 'train_loss': 0.8800504112243652, 'val_loss': 1.7327405548095702, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 72, 'train_loss': 0.8873064510027567, 'val_loss': 2.434803949991862, 'test_acc': 0.42}
{'fold': 9, 'epoch': 73, 'train_loss': 0.8715026505788167, 'val_loss': 2.4566044362386066, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 74, 'train_loss': 0.8634256847699483, 'val_loss': 2.764681078592936, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 75, 'train_loss': 0.8517617138226827, 'val_loss': 2.614265340169271, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 76, 'train_loss': 0.9893732929229736, 'val_loss': 7.753754590352377, 'test_acc': 0.5}
{'fold': 9, 'epoch': 77, 'train_loss': 1.0934965848922729, 'val_loss': 1.1750765355428059, 'test_acc': 0.36666666666666664}
{'fold': 9, 'epoch': 78, 'train_loss': 1.0227587469418844, 'val_loss': 1.095575917561849, 'test_acc': 0.3933333333333333}
{'fold': 9, 'epoch': 79, 'train_loss': 1.0133765776952108, 'val_loss': 1.0579728571573894, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 80, 'train_loss': 0.974520066579183, 'val_loss': 1.195798479715983, 'test_acc': 0.5}
{'fold': 9, 'epoch': 81, 'train_loss': 0.9617841784159342, 'val_loss': 1.1748645146687826, 'test_acc': 0.49333333333333335}
{'fold': 9, 'epoch': 82, 'train_loss': 0.9492946664492289, 'val_loss': 1.5211370213826498, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 83, 'train_loss': 0.9620871130625407, 'val_loss': 1.4000757217407227, 'test_acc': 0.5333333333333333}
{'fold': 9, 'epoch': 84, 'train_loss': 0.9229119364420573, 'val_loss': 1.6156912231445313, 'test_acc': 0.47333333333333333}
{'fold': 9, 'epoch': 85, 'train_loss': 0.9219205363591512, 'val_loss': 1.7057075627644858, 'test_acc': 0.43333333333333335}
{'fold': 9, 'epoch': 86, 'train_loss': 0.9218996548652649, 'val_loss': 1.5301405715942382, 'test_acc': 0.48}
{'fold': 9, 'epoch': 87, 'train_loss': 0.9521414041519165, 'val_loss': 1.7409724807739257, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 88, 'train_loss': 0.928976944287618, 'val_loss': 1.8502020899454752, 'test_acc': 0.5}
{'fold': 9, 'epoch': 89, 'train_loss': 0.9337703951199849, 'val_loss': 1.9137969462076823, 'test_acc': 0.5266666666666666}
{'fold': 9, 'epoch': 90, 'train_loss': 1.1289298979441325, 'val_loss': 1.7418378575642903, 'test_acc': 0.4866666666666667}
{'fold': 9, 'epoch': 91, 'train_loss': 0.963956647713979, 'val_loss': 1.320742696126302, 'test_acc': 0.48}
{'fold': 9, 'epoch': 92, 'train_loss': 0.954076939423879, 'val_loss': 1.5367871348063151, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 93, 'train_loss': 0.9400277256965637, 'val_loss': 1.8859837214152018, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 94, 'train_loss': 0.9319385250409444, 'val_loss': 1.8209397379557293, 'test_acc': 0.43333333333333335}
{'fold': 9, 'epoch': 95, 'train_loss': 0.9312123441696167, 'val_loss': 1.5488532129923502, 'test_acc': 0.5133333333333333}
{'fold': 9, 'epoch': 96, 'train_loss': 0.9056620891888937, 'val_loss': 1.4138116709391275, 'test_acc': 0.52}
{'fold': 9, 'epoch': 97, 'train_loss': 0.9107464790344239, 'val_loss': 1.4322256088256835, 'test_acc': 0.5}
{'fold': 9, 'epoch': 98, 'train_loss': 0.9046054339408874, 'val_loss': 1.4699797821044922, 'test_acc': 0.5066666666666667}
{'fold': 9, 'epoch': 99, 'train_loss': 0.9878174408276876, 'val_loss': 1.4227956771850585, 'test_acc': 0.4266666666666667}
{'fold': 9, 'epoch': 100, 'train_loss': 0.9096618167559306, 'val_loss': 1.446604232788086, 'test_acc': 0.38}
Val Loss: 0.9881, Test Accuracy: 0.473 ± 0.035, Duration: 11.378
Best result - 0.473 ± 0.035
--
MUTAG - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6762244042597318, 'val_loss': 0.6338638729519315, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6657873423475968, 'val_loss': 0.6592826843261719, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6599898808880856, 'val_loss': 0.6324697600470649, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6359784320781106, 'val_loss': 0.6684642367892795, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6984730362892151, 'val_loss': 0.6299461788601346, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6286984964420921, 'val_loss': 0.6207089953952365, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6244594203798395, 'val_loss': 0.6265304353502061, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6567435295958268, 'val_loss': 0.6066543261210123, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6108283620131644, 'val_loss': 0.5958014064364963, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 10, 'train_loss': 0.608578904678947, 'val_loss': 0.5966666009691026, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6005635041939584, 'val_loss': 0.5465350680881076, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5621058956572884, 'val_loss': 0.5527811050415039, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 13, 'train_loss': 0.5583676052720923, 'val_loss': 0.4749187363518609, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5238170325756073, 'val_loss': 0.4637990527682834, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5270473643353111, 'val_loss': 0.4418668746948242, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 16, 'train_loss': 0.5230605225814017, 'val_loss': 0.5377914640638564, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 17, 'train_loss': 0.49899255288274663, 'val_loss': 0.5501828723483615, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5787737338166488, 'val_loss': 0.5866381327311198, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5989160004415011, 'val_loss': 0.4995372560289171, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 20, 'train_loss': 0.5224315084909138, 'val_loss': 0.5027002758449979, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 21, 'train_loss': 0.511822593839545, 'val_loss': 0.5126163164774576, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5169805758877805, 'val_loss': 0.44652578565809464, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 23, 'train_loss': 0.6239901122293974, 'val_loss': 0.4430479208628337, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 24, 'train_loss': 0.4935682259107891, 'val_loss': 0.47815047370062935, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 25, 'train_loss': 0.500046570050089, 'val_loss': 0.5178592999776205, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5196166258109244, 'val_loss': 0.5324501991271973, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5208232653768439, 'val_loss': 0.5395749939812554, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5517661461704656, 'val_loss': 0.5435012711418999, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5250059679934853, 'val_loss': 0.5382438235812717, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5476398891524265, 'val_loss': 0.5519437789916992, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5095230450755671, 'val_loss': 0.5343877474466959, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 32, 'train_loss': 0.49941922802674144, 'val_loss': 0.59260008070204, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 33, 'train_loss': 0.582077660058674, 'val_loss': 0.5676548216078017, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5389019250869751, 'val_loss': 0.4791048897637261, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 35, 'train_loss': 0.49426496342608806, 'val_loss': 0.5770023663838705, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 36, 'train_loss': 0.6376486420631409, 'val_loss': 0.5159041086832682, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5628192832595423, 'val_loss': 0.4600280125935872, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5136000325805262, 'val_loss': 0.48339615927802193, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 39, 'train_loss': 0.49717749106256587, 'val_loss': 0.45660829544067383, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 40, 'train_loss': 0.50502001141247, 'val_loss': 0.4477699597676595, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 41, 'train_loss': 0.4740352160052249, 'val_loss': 0.4321754773457845, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 42, 'train_loss': 0.4765676416848835, 'val_loss': 0.43556732601589626, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 43, 'train_loss': 0.4941880608859815, 'val_loss': 0.4265570905473497, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 44, 'train_loss': 0.4729713499546051, 'val_loss': 0.4067971176571316, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 45, 'train_loss': 0.47458708913702713, 'val_loss': 0.4023146629333496, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 46, 'train_loss': 0.47970008536388997, 'val_loss': 0.4031514326731364, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 47, 'train_loss': 0.4726483570901971, 'val_loss': 0.44381189346313477, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 48, 'train_loss': 0.48933993201506765, 'val_loss': 0.47885380850897896, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 49, 'train_loss': 0.4909895721234773, 'val_loss': 0.47695080439249676, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 50, 'train_loss': 0.5041251213927018, 'val_loss': 0.45754575729370117, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 51, 'train_loss': 0.508781866023415, 'val_loss': 0.4207190407647027, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 52, 'train_loss': 0.49158716515490886, 'val_loss': 0.40671420097351074, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 53, 'train_loss': 0.45954908038440506, 'val_loss': 0.39461448457505965, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 54, 'train_loss': 0.4611293030412574, 'val_loss': 0.41314305199517143, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 55, 'train_loss': 0.5238027227552313, 'val_loss': 0.3879566192626953, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 56, 'train_loss': 0.46566638664195414, 'val_loss': 0.4220641454060872, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 57, 'train_loss': 0.49945138159551117, 'val_loss': 0.40962081485324436, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 58, 'train_loss': 0.471497705108241, 'val_loss': 0.4408676889207628, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 59, 'train_loss': 0.46658139322933395, 'val_loss': 0.4464137819078233, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 60, 'train_loss': 0.48732493425670426, 'val_loss': 0.43543680508931476, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 61, 'train_loss': 0.4633689350203464, 'val_loss': 0.40694109598795575, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 62, 'train_loss': 0.432773525777616, 'val_loss': 0.3959280120001899, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 63, 'train_loss': 0.4678306689387874, 'val_loss': 0.40542419751485187, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 64, 'train_loss': 0.4474729597568512, 'val_loss': 0.3990807798173692, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 65, 'train_loss': 0.44159192003701864, 'val_loss': 0.40173525280422634, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 66, 'train_loss': 0.4285817209043001, 'val_loss': 0.4049597316318088, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 67, 'train_loss': 0.42536353280669764, 'val_loss': 0.3946913348303901, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 68, 'train_loss': 0.4547988176345825, 'val_loss': 0.40912463929918075, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 69, 'train_loss': 0.41273085851418345, 'val_loss': 0.4115530120001899, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 70, 'train_loss': 0.43350079185084295, 'val_loss': 0.4079829321967231, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 71, 'train_loss': 0.4410627609805057, 'val_loss': 0.386113617155287, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 72, 'train_loss': 0.4235211783333829, 'val_loss': 0.34501801596747506, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 73, 'train_loss': 0.5049350936161844, 'val_loss': 0.388602336247762, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 74, 'train_loss': 0.40702533251360845, 'val_loss': 0.42126769489712185, 'test_acc': 0.7222222222222222}
{'fold': 9, 'epoch': 75, 'train_loss': 0.5098002490244413, 'val_loss': 0.4379977385203044, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 76, 'train_loss': 0.45842769428303365, 'val_loss': 0.44828160603841144, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 77, 'train_loss': 0.45386043034101786, 'val_loss': 0.44266936514112687, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 78, 'train_loss': 0.44644330049815933, 'val_loss': 0.45044883092244464, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 79, 'train_loss': 0.4445567915314122, 'val_loss': 0.4457344479031033, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 80, 'train_loss': 0.4544275026572378, 'val_loss': 0.4334132671356201, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 81, 'train_loss': 0.43881272014818695, 'val_loss': 0.42668869760301376, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 82, 'train_loss': 0.42317330052978114, 'val_loss': 0.43277377552456325, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 83, 'train_loss': 0.4104995915764256, 'val_loss': 0.4044441117180718, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 84, 'train_loss': 0.4259503530828576, 'val_loss': 0.38885463608635795, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 85, 'train_loss': 0.4255676347958414, 'val_loss': 0.3804696665869819, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 86, 'train_loss': 0.41913988872578267, 'val_loss': 0.39944161309136283, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 87, 'train_loss': 0.411123630247618, 'val_loss': 0.41760924127366805, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 88, 'train_loss': 0.4573976005378522, 'val_loss': 0.4510697258843316, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 89, 'train_loss': 0.4436451588806353, 'val_loss': 0.4475375281439887, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 90, 'train_loss': 0.40827321849371256, 'val_loss': 0.44541724522908527, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 91, 'train_loss': 0.49900585412979126, 'val_loss': 0.39206870396931964, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 92, 'train_loss': 0.4560947261358562, 'val_loss': 0.4892580244276259, 'test_acc': 0.5555555555555556}
{'fold': 9, 'epoch': 93, 'train_loss': 0.5071734409583243, 'val_loss': 0.4672693676418728, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 94, 'train_loss': 0.4903624355792999, 'val_loss': 0.4997628529866536, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 95, 'train_loss': 0.5301434021247061, 'val_loss': 0.5177542898390028, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 96, 'train_loss': 0.48891465444313853, 'val_loss': 0.48629167344835067, 'test_acc': 0.6111111111111112}
{'fold': 9, 'epoch': 97, 'train_loss': 0.47644204842416865, 'val_loss': 0.46965387132432723, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 98, 'train_loss': 0.44884041422291804, 'val_loss': 0.4298745526207818, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 99, 'train_loss': 0.4798393782816435, 'val_loss': 0.40490902794731987, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 100, 'train_loss': 0.4484281100724873, 'val_loss': 0.4100404580434163, 'test_acc': 0.6666666666666666}
Val Loss: 0.4439, Test Accuracy: 0.734 ± 0.095, Duration: 2.857
Best result - 0.734 ± 0.095
--
IMDB-BINARY - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.673761076927185, 'val_loss': 0.68978271484375, 'test_acc': 0.67}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6562250471115112, 'val_loss': 0.6075429916381836, 'test_acc': 0.7}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5552765011787415, 'val_loss': 0.5191164779663086, 'test_acc': 0.71}
{'fold': 9, 'epoch': 4, 'train_loss': 0.53224116563797, 'val_loss': 0.5016252517700195, 'test_acc': 0.65}
{'fold': 9, 'epoch': 5, 'train_loss': 0.49875775337219236, 'val_loss': 0.5009557723999023, 'test_acc': 0.67}
{'fold': 9, 'epoch': 6, 'train_loss': 0.4945872724056244, 'val_loss': 0.4747508239746094, 'test_acc': 0.76}
{'fold': 9, 'epoch': 7, 'train_loss': 0.4901267278194428, 'val_loss': 0.4544425201416016, 'test_acc': 0.72}
{'fold': 9, 'epoch': 8, 'train_loss': 0.4778223443031311, 'val_loss': 0.5027846908569336, 'test_acc': 0.66}
{'fold': 9, 'epoch': 9, 'train_loss': 0.4594391691684723, 'val_loss': 0.46895561218261717, 'test_acc': 0.69}
{'fold': 9, 'epoch': 10, 'train_loss': 0.4457552230358124, 'val_loss': 0.5257970428466797, 'test_acc': 0.66}
{'fold': 9, 'epoch': 11, 'train_loss': 0.44988622546195983, 'val_loss': 0.49181041717529295, 'test_acc': 0.72}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4242416000366211, 'val_loss': 0.5224967193603516, 'test_acc': 0.72}
{'fold': 9, 'epoch': 13, 'train_loss': 0.4257248544692993, 'val_loss': 0.49557601928710937, 'test_acc': 0.72}
{'fold': 9, 'epoch': 14, 'train_loss': 0.4373581600189209, 'val_loss': 0.5448180389404297, 'test_acc': 0.62}
{'fold': 9, 'epoch': 15, 'train_loss': 0.43196003675460815, 'val_loss': 0.5255241012573242, 'test_acc': 0.69}
{'fold': 9, 'epoch': 16, 'train_loss': 0.41312572836875916, 'val_loss': 0.5527862930297851, 'test_acc': 0.67}
{'fold': 9, 'epoch': 17, 'train_loss': 0.41124315857887267, 'val_loss': 0.589253044128418, 'test_acc': 0.72}
{'fold': 9, 'epoch': 18, 'train_loss': 0.3689772140979767, 'val_loss': 0.5804693603515625, 'test_acc': 0.68}
{'fold': 9, 'epoch': 19, 'train_loss': 0.3808927285671234, 'val_loss': 0.6317074966430664, 'test_acc': 0.73}
{'fold': 9, 'epoch': 20, 'train_loss': 0.3599305093288422, 'val_loss': 0.7417102813720703, 'test_acc': 0.7}
{'fold': 9, 'epoch': 21, 'train_loss': 0.3438016855716705, 'val_loss': 0.9857974243164063, 'test_acc': 0.72}
{'fold': 9, 'epoch': 22, 'train_loss': 0.39178176641464235, 'val_loss': 0.5783947372436523, 'test_acc': 0.7}
{'fold': 9, 'epoch': 23, 'train_loss': 0.3896980786323547, 'val_loss': 0.5649696731567383, 'test_acc': 0.68}
{'fold': 9, 'epoch': 24, 'train_loss': 0.39634896397590635, 'val_loss': 0.6880750274658203, 'test_acc': 0.66}
{'fold': 9, 'epoch': 25, 'train_loss': 0.36356220006942747, 'val_loss': 0.8377702331542969, 'test_acc': 0.72}
{'fold': 9, 'epoch': 26, 'train_loss': 0.3322844362258911, 'val_loss': 1.2961003112792968, 'test_acc': 0.7}
{'fold': 9, 'epoch': 27, 'train_loss': 0.36836735844612123, 'val_loss': 0.6409584045410156, 'test_acc': 0.68}
{'fold': 9, 'epoch': 28, 'train_loss': 0.3508089518547058, 'val_loss': 0.7090472412109375, 'test_acc': 0.65}
{'fold': 9, 'epoch': 29, 'train_loss': 0.33117748618125914, 'val_loss': 0.6879145050048828, 'test_acc': 0.66}
{'fold': 9, 'epoch': 30, 'train_loss': 0.34977715611457827, 'val_loss': 0.769677505493164, 'test_acc': 0.7}
{'fold': 9, 'epoch': 31, 'train_loss': 0.3220934474468231, 'val_loss': 0.8808922576904297, 'test_acc': 0.71}
{'fold': 9, 'epoch': 32, 'train_loss': 0.3093611717224121, 'val_loss': 0.8697286987304688, 'test_acc': 0.66}
{'fold': 9, 'epoch': 33, 'train_loss': 0.3152929627895355, 'val_loss': 0.8343936920166015, 'test_acc': 0.71}
{'fold': 9, 'epoch': 34, 'train_loss': 0.3021791636943817, 'val_loss': 1.1718407440185548, 'test_acc': 0.7}
{'fold': 9, 'epoch': 35, 'train_loss': 0.2980404543876648, 'val_loss': 0.940453872680664, 'test_acc': 0.71}
{'fold': 9, 'epoch': 36, 'train_loss': 0.30442075967788695, 'val_loss': 0.984092025756836, 'test_acc': 0.74}
{'fold': 9, 'epoch': 37, 'train_loss': 0.29304459810256955, 'val_loss': 1.273369598388672, 'test_acc': 0.64}
{'fold': 9, 'epoch': 38, 'train_loss': 0.2928831267356873, 'val_loss': 1.1512335205078126, 'test_acc': 0.72}
{'fold': 9, 'epoch': 39, 'train_loss': 0.293458132147789, 'val_loss': 1.138171157836914, 'test_acc': 0.66}
{'fold': 9, 'epoch': 40, 'train_loss': 0.2911410903930664, 'val_loss': 1.0625991821289062, 'test_acc': 0.69}
{'fold': 9, 'epoch': 41, 'train_loss': 0.3848460865020752, 'val_loss': 0.6102086639404297, 'test_acc': 0.68}
{'fold': 9, 'epoch': 42, 'train_loss': 0.3668388819694519, 'val_loss': 0.5694792175292969, 'test_acc': 0.76}
{'fold': 9, 'epoch': 43, 'train_loss': 0.34925543546676635, 'val_loss': 0.5767459106445313, 'test_acc': 0.69}
{'fold': 9, 'epoch': 44, 'train_loss': 0.32680309176445005, 'val_loss': 0.6065233230590821, 'test_acc': 0.71}
{'fold': 9, 'epoch': 45, 'train_loss': 0.3028958880901337, 'val_loss': 0.7302144622802734, 'test_acc': 0.71}
{'fold': 9, 'epoch': 46, 'train_loss': 0.2932973170280457, 'val_loss': 0.7169947814941406, 'test_acc': 0.68}
{'fold': 9, 'epoch': 47, 'train_loss': 0.2900551396608353, 'val_loss': 0.9386090087890625, 'test_acc': 0.63}
{'fold': 9, 'epoch': 48, 'train_loss': 0.31062376260757446, 'val_loss': 0.7271730041503907, 'test_acc': 0.79}
{'fold': 9, 'epoch': 49, 'train_loss': 0.29412820100784304, 'val_loss': 0.9813629913330079, 'test_acc': 0.66}
{'fold': 9, 'epoch': 50, 'train_loss': 0.3035434722900391, 'val_loss': 0.6952217864990234, 'test_acc': 0.63}
{'fold': 9, 'epoch': 51, 'train_loss': 0.3459330439567566, 'val_loss': 0.7009156036376953, 'test_acc': 0.69}
{'fold': 9, 'epoch': 52, 'train_loss': 0.3437082958221436, 'val_loss': 0.7997177124023438, 'test_acc': 0.7}
{'fold': 9, 'epoch': 53, 'train_loss': 0.31318334460258485, 'val_loss': 0.8241915893554688, 'test_acc': 0.74}
{'fold': 9, 'epoch': 54, 'train_loss': 0.30811859369277955, 'val_loss': 1.2944137573242187, 'test_acc': 0.71}
{'fold': 9, 'epoch': 55, 'train_loss': 0.3044986355304718, 'val_loss': 0.6789891815185547, 'test_acc': 0.71}
{'fold': 9, 'epoch': 56, 'train_loss': 0.343431077003479, 'val_loss': 0.950624771118164, 'test_acc': 0.7}
{'fold': 9, 'epoch': 57, 'train_loss': 0.4505950164794922, 'val_loss': 0.5313896942138672, 'test_acc': 0.71}
{'fold': 9, 'epoch': 58, 'train_loss': 0.3538353443145752, 'val_loss': 0.6758222961425782, 'test_acc': 0.72}
{'fold': 9, 'epoch': 59, 'train_loss': 0.3333529603481293, 'val_loss': 0.81958251953125, 'test_acc': 0.67}
{'fold': 9, 'epoch': 60, 'train_loss': 0.31136888682842256, 'val_loss': 1.0842528533935547, 'test_acc': 0.7}
{'fold': 9, 'epoch': 61, 'train_loss': 0.31407019615173337, 'val_loss': 1.162662811279297, 'test_acc': 0.74}
{'fold': 9, 'epoch': 62, 'train_loss': 0.3058777642250061, 'val_loss': 1.2429000854492187, 'test_acc': 0.7}
{'fold': 9, 'epoch': 63, 'train_loss': 0.30164092898368833, 'val_loss': 1.3274197387695312, 'test_acc': 0.74}
{'fold': 9, 'epoch': 64, 'train_loss': 0.27912938356399536, 'val_loss': 3.9233447265625, 'test_acc': 0.72}
{'fold': 9, 'epoch': 65, 'train_loss': 0.2613137686252594, 'val_loss': 3.347508850097656, 'test_acc': 0.73}
{'fold': 9, 'epoch': 66, 'train_loss': 0.3094215178489685, 'val_loss': 1.8774813842773437, 'test_acc': 0.69}
{'fold': 9, 'epoch': 67, 'train_loss': 0.27194289326667787, 'val_loss': 2.201474304199219, 'test_acc': 0.72}
{'fold': 9, 'epoch': 68, 'train_loss': 0.2612492799758911, 'val_loss': 2.489214324951172, 'test_acc': 0.68}
{'fold': 9, 'epoch': 69, 'train_loss': 0.2694913375377655, 'val_loss': 3.306806640625, 'test_acc': 0.7}
{'fold': 9, 'epoch': 70, 'train_loss': 0.26264453649520875, 'val_loss': 2.3811854553222656, 'test_acc': 0.68}
{'fold': 9, 'epoch': 71, 'train_loss': 0.266974184513092, 'val_loss': 1.2859994506835937, 'test_acc': 0.7}
{'fold': 9, 'epoch': 72, 'train_loss': 0.2555545580387115, 'val_loss': 1.8901502990722656, 'test_acc': 0.68}
{'fold': 9, 'epoch': 73, 'train_loss': 0.2676590085029602, 'val_loss': 2.3038668823242188, 'test_acc': 0.68}
{'fold': 9, 'epoch': 74, 'train_loss': 0.32110851764678955, 'val_loss': 0.6360965728759765, 'test_acc': 0.65}
{'fold': 9, 'epoch': 75, 'train_loss': 0.32055444836616515, 'val_loss': 0.8219858551025391, 'test_acc': 0.73}
{'fold': 9, 'epoch': 76, 'train_loss': 0.3009387481212616, 'val_loss': 1.0500545501708984, 'test_acc': 0.68}
{'fold': 9, 'epoch': 77, 'train_loss': 0.3050302678346634, 'val_loss': 0.9937928009033203, 'test_acc': 0.75}
{'fold': 9, 'epoch': 78, 'train_loss': 0.29097030401229856, 'val_loss': 1.143324432373047, 'test_acc': 0.73}
{'fold': 9, 'epoch': 79, 'train_loss': 0.2745287108421326, 'val_loss': 1.3469821166992189, 'test_acc': 0.68}
{'fold': 9, 'epoch': 80, 'train_loss': 0.2677928626537323, 'val_loss': 1.2101602935791016, 'test_acc': 0.69}
{'fold': 9, 'epoch': 81, 'train_loss': 0.26022666215896606, 'val_loss': 1.4185671997070313, 'test_acc': 0.7}
{'fold': 9, 'epoch': 82, 'train_loss': 0.2775228154659271, 'val_loss': 1.315587158203125, 'test_acc': 0.74}
{'fold': 9, 'epoch': 83, 'train_loss': 0.286344119310379, 'val_loss': 1.0133202362060547, 'test_acc': 0.68}
{'fold': 9, 'epoch': 84, 'train_loss': 0.2755753540992737, 'val_loss': 1.3205722045898438, 'test_acc': 0.71}
{'fold': 9, 'epoch': 85, 'train_loss': 0.2784331303834915, 'val_loss': 1.2148672485351562, 'test_acc': 0.7}
{'fold': 9, 'epoch': 86, 'train_loss': 0.28625197052955625, 'val_loss': 1.083020477294922, 'test_acc': 0.76}
{'fold': 9, 'epoch': 87, 'train_loss': 0.30690781235694886, 'val_loss': 0.9843988800048828, 'test_acc': 0.69}
{'fold': 9, 'epoch': 88, 'train_loss': 0.29430429220199583, 'val_loss': 0.8470608520507813, 'test_acc': 0.74}
{'fold': 9, 'epoch': 89, 'train_loss': 0.2900829446315765, 'val_loss': 1.6961451721191407, 'test_acc': 0.68}
{'fold': 9, 'epoch': 90, 'train_loss': 0.27841840565204623, 'val_loss': 1.473204345703125, 'test_acc': 0.74}
{'fold': 9, 'epoch': 91, 'train_loss': 0.26212625980377197, 'val_loss': 2.298420257568359, 'test_acc': 0.69}
{'fold': 9, 'epoch': 92, 'train_loss': 0.27040937304496765, 'val_loss': 3.360623474121094, 'test_acc': 0.69}
{'fold': 9, 'epoch': 93, 'train_loss': 0.2765566897392273, 'val_loss': 6.53042236328125, 'test_acc': 0.69}
{'fold': 9, 'epoch': 94, 'train_loss': 0.3466828966140747, 'val_loss': 3.4191018676757814, 'test_acc': 0.69}
{'fold': 9, 'epoch': 95, 'train_loss': 0.3223907792568207, 'val_loss': 0.6408200836181641, 'test_acc': 0.66}
{'fold': 9, 'epoch': 96, 'train_loss': 0.30506829857826234, 'val_loss': 1.017020492553711, 'test_acc': 0.72}
{'fold': 9, 'epoch': 97, 'train_loss': 0.29435197710990907, 'val_loss': 1.6387652587890624, 'test_acc': 0.74}
{'fold': 9, 'epoch': 98, 'train_loss': 0.3001136189699173, 'val_loss': 1.5147813415527345, 'test_acc': 0.77}
{'fold': 9, 'epoch': 99, 'train_loss': 0.30746917605400087, 'val_loss': 1.4323361206054688, 'test_acc': 0.7}
{'fold': 9, 'epoch': 100, 'train_loss': 0.3153533506393433, 'val_loss': 0.8671108245849609, 'test_acc': 0.75}
Val Loss: 0.4873, Test Accuracy: 0.731 ± 0.041, Duration: 14.345
Best result - 0.731 ± 0.041
--
REDDIT-BINARY - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 1.0335456442832947, 'val_loss': 0.6339959716796875, 'test_acc': 0.64}
{'fold': 9, 'epoch': 2, 'train_loss': 0.5967969560623169, 'val_loss': 0.5670738601684571, 'test_acc': 0.66}
{'fold': 9, 'epoch': 3, 'train_loss': 0.551526392698288, 'val_loss': 0.5435824489593506, 'test_acc': 0.705}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5495399761199952, 'val_loss': 0.5540688991546631, 'test_acc': 0.7}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5369015443325043, 'val_loss': 0.534301290512085, 'test_acc': 0.72}
{'fold': 9, 'epoch': 6, 'train_loss': 0.529813392162323, 'val_loss': 0.5055776119232178, 'test_acc': 0.715}
{'fold': 9, 'epoch': 7, 'train_loss': 0.5178883981704712, 'val_loss': 0.51162672996521, 'test_acc': 0.73}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5156230974197388, 'val_loss': 0.4649518013000488, 'test_acc': 0.76}
{'fold': 9, 'epoch': 9, 'train_loss': 0.507402468919754, 'val_loss': 0.4915535354614258, 'test_acc': 0.73}
{'fold': 9, 'epoch': 10, 'train_loss': 0.4877460980415344, 'val_loss': 0.42240999221801756, 'test_acc': 0.75}
{'fold': 9, 'epoch': 11, 'train_loss': 0.4803484642505646, 'val_loss': 0.3820661926269531, 'test_acc': 0.775}
{'fold': 9, 'epoch': 12, 'train_loss': 0.4555398857593536, 'val_loss': 0.41101237773895266, 'test_acc': 0.8}
{'fold': 9, 'epoch': 13, 'train_loss': 0.4558364272117615, 'val_loss': 0.4234815788269043, 'test_acc': 0.755}
{'fold': 9, 'epoch': 14, 'train_loss': 0.4616492581367493, 'val_loss': 0.6239638328552246, 'test_acc': 0.775}
{'fold': 9, 'epoch': 15, 'train_loss': 0.48937015533447265, 'val_loss': 0.48758917808532715, 'test_acc': 0.745}
{'fold': 9, 'epoch': 16, 'train_loss': 0.4702435946464539, 'val_loss': 0.423715763092041, 'test_acc': 0.79}
{'fold': 9, 'epoch': 17, 'train_loss': 0.4734895443916321, 'val_loss': 0.4546924877166748, 'test_acc': 0.77}
{'fold': 9, 'epoch': 18, 'train_loss': 0.4807072138786316, 'val_loss': 0.46553171157836915, 'test_acc': 0.76}
{'fold': 9, 'epoch': 19, 'train_loss': 0.4840342354774475, 'val_loss': 0.4071014785766602, 'test_acc': 0.795}
{'fold': 9, 'epoch': 20, 'train_loss': 0.4459778916835785, 'val_loss': 0.39183166980743406, 'test_acc': 0.795}
{'fold': 9, 'epoch': 21, 'train_loss': 0.41285647749900817, 'val_loss': 0.38707794189453126, 'test_acc': 0.785}
{'fold': 9, 'epoch': 22, 'train_loss': 0.4162194442749023, 'val_loss': 0.36142137050628664, 'test_acc': 0.805}
{'fold': 9, 'epoch': 23, 'train_loss': 0.4004845261573792, 'val_loss': 0.3357303524017334, 'test_acc': 0.835}
{'fold': 9, 'epoch': 24, 'train_loss': 0.3883832120895386, 'val_loss': 0.35561914920806886, 'test_acc': 0.815}
{'fold': 9, 'epoch': 25, 'train_loss': 0.39389909863471984, 'val_loss': 0.33609856605529786, 'test_acc': 0.845}
{'fold': 9, 'epoch': 26, 'train_loss': 0.39589048981666564, 'val_loss': 0.33737510204315185, 'test_acc': 0.835}
{'fold': 9, 'epoch': 27, 'train_loss': 0.38223945736885073, 'val_loss': 0.3644456958770752, 'test_acc': 0.815}
{'fold': 9, 'epoch': 28, 'train_loss': 0.3729095506668091, 'val_loss': 0.31295387744903563, 'test_acc': 0.82}
{'fold': 9, 'epoch': 29, 'train_loss': 0.37068776607513426, 'val_loss': 0.3559934711456299, 'test_acc': 0.82}
{'fold': 9, 'epoch': 30, 'train_loss': 0.34855472564697265, 'val_loss': 0.2996950387954712, 'test_acc': 0.865}
{'fold': 9, 'epoch': 31, 'train_loss': 0.3583478832244873, 'val_loss': 0.32233969688415526, 'test_acc': 0.85}
{'fold': 9, 'epoch': 32, 'train_loss': 0.3372375977039337, 'val_loss': 0.27481849193573, 'test_acc': 0.84}
{'fold': 9, 'epoch': 33, 'train_loss': 0.3543493139743805, 'val_loss': 0.3010257148742676, 'test_acc': 0.835}
{'fold': 9, 'epoch': 34, 'train_loss': 0.36243064761161803, 'val_loss': 0.35187621593475343, 'test_acc': 0.815}
{'fold': 9, 'epoch': 35, 'train_loss': 0.36447004973888397, 'val_loss': 0.2975814390182495, 'test_acc': 0.84}
{'fold': 9, 'epoch': 36, 'train_loss': 0.3397351050376892, 'val_loss': 0.3125793981552124, 'test_acc': 0.875}
{'fold': 9, 'epoch': 37, 'train_loss': 0.31941930890083314, 'val_loss': 0.29558528423309327, 'test_acc': 0.845}
{'fold': 9, 'epoch': 38, 'train_loss': 0.3206060242652893, 'val_loss': 0.3167362976074219, 'test_acc': 0.86}
{'fold': 9, 'epoch': 39, 'train_loss': 0.3060676538944244, 'val_loss': 0.2588715696334839, 'test_acc': 0.88}
{'fold': 9, 'epoch': 40, 'train_loss': 0.4163804626464844, 'val_loss': 0.3901133728027344, 'test_acc': 0.765}
{'fold': 9, 'epoch': 41, 'train_loss': 0.3648345077037811, 'val_loss': 0.30142446994781497, 'test_acc': 0.835}
{'fold': 9, 'epoch': 42, 'train_loss': 0.3211601173877716, 'val_loss': 0.28652855396270754, 'test_acc': 0.84}
{'fold': 9, 'epoch': 43, 'train_loss': 0.34898005723953246, 'val_loss': 0.3303028106689453, 'test_acc': 0.84}
{'fold': 9, 'epoch': 44, 'train_loss': 0.3251074683666229, 'val_loss': 0.2634692525863647, 'test_acc': 0.865}
{'fold': 9, 'epoch': 45, 'train_loss': 0.3142870903015137, 'val_loss': 0.2532598829269409, 'test_acc': 0.865}
{'fold': 9, 'epoch': 46, 'train_loss': 0.2994722545146942, 'val_loss': 0.2724110507965088, 'test_acc': 0.885}
{'fold': 9, 'epoch': 47, 'train_loss': 0.29746928334236145, 'val_loss': 0.24748860359191893, 'test_acc': 0.875}
{'fold': 9, 'epoch': 48, 'train_loss': 0.2756921970844269, 'val_loss': 0.2661437463760376, 'test_acc': 0.87}
{'fold': 9, 'epoch': 49, 'train_loss': 0.3000773859024048, 'val_loss': 0.310390362739563, 'test_acc': 0.825}
{'fold': 9, 'epoch': 50, 'train_loss': 0.34946380734443666, 'val_loss': 0.2887454652786255, 'test_acc': 0.875}
{'fold': 9, 'epoch': 51, 'train_loss': 0.2991871702671051, 'val_loss': 0.26748085021972656, 'test_acc': 0.895}
{'fold': 9, 'epoch': 52, 'train_loss': 0.28636471390724183, 'val_loss': 0.23542014598846436, 'test_acc': 0.905}
{'fold': 9, 'epoch': 53, 'train_loss': 0.2871205282211304, 'val_loss': 0.2351771640777588, 'test_acc': 0.9}
{'fold': 9, 'epoch': 54, 'train_loss': 0.2791273373365402, 'val_loss': 0.22458961486816406, 'test_acc': 0.875}
{'fold': 9, 'epoch': 55, 'train_loss': 0.2724470829963684, 'val_loss': 0.22313225269317627, 'test_acc': 0.88}
{'fold': 9, 'epoch': 56, 'train_loss': 0.2698089063167572, 'val_loss': 0.21753471374511718, 'test_acc': 0.895}
{'fold': 9, 'epoch': 57, 'train_loss': 0.26782883524894713, 'val_loss': 0.20672430992126464, 'test_acc': 0.915}
{'fold': 9, 'epoch': 58, 'train_loss': 0.30666967153549196, 'val_loss': 0.29675238609313964, 'test_acc': 0.855}
{'fold': 9, 'epoch': 59, 'train_loss': 0.33339163422584533, 'val_loss': 0.24589237689971924, 'test_acc': 0.89}
{'fold': 9, 'epoch': 60, 'train_loss': 0.3004636514186859, 'val_loss': 0.23333417415618896, 'test_acc': 0.905}
{'fold': 9, 'epoch': 61, 'train_loss': 0.27439050912857055, 'val_loss': 0.22934659481048583, 'test_acc': 0.89}
{'fold': 9, 'epoch': 62, 'train_loss': 0.2701576316356659, 'val_loss': 0.20837796211242676, 'test_acc': 0.865}
{'fold': 9, 'epoch': 63, 'train_loss': 0.29346819162368776, 'val_loss': 0.25359511375427246, 'test_acc': 0.835}
{'fold': 9, 'epoch': 64, 'train_loss': 0.29104760169982913, 'val_loss': 0.24212010383605956, 'test_acc': 0.88}
{'fold': 9, 'epoch': 65, 'train_loss': 0.29112615406513215, 'val_loss': 0.20864855766296386, 'test_acc': 0.905}
{'fold': 9, 'epoch': 66, 'train_loss': 0.25877304792404177, 'val_loss': 0.21342945098876953, 'test_acc': 0.9}
{'fold': 9, 'epoch': 67, 'train_loss': 0.2751748609542847, 'val_loss': 0.20638680934906006, 'test_acc': 0.89}
{'fold': 9, 'epoch': 68, 'train_loss': 0.26442726016044615, 'val_loss': 0.20399184226989747, 'test_acc': 0.895}
{'fold': 9, 'epoch': 69, 'train_loss': 0.2550831639766693, 'val_loss': 0.20648804187774658, 'test_acc': 0.915}
{'fold': 9, 'epoch': 70, 'train_loss': 0.2569407045841217, 'val_loss': 0.22668080806732177, 'test_acc': 0.875}
{'fold': 9, 'epoch': 71, 'train_loss': 0.36967700600624087, 'val_loss': 0.3193770408630371, 'test_acc': 0.8}
{'fold': 9, 'epoch': 72, 'train_loss': 0.3116650724411011, 'val_loss': 0.24775999546051025, 'test_acc': 0.885}
{'fold': 9, 'epoch': 73, 'train_loss': 0.29527497887611387, 'val_loss': 0.20832051753997802, 'test_acc': 0.9}
{'fold': 9, 'epoch': 74, 'train_loss': 0.26973352193832395, 'val_loss': 0.18334648609161378, 'test_acc': 0.905}
{'fold': 9, 'epoch': 75, 'train_loss': 0.2848381006717682, 'val_loss': 0.22577741622924805, 'test_acc': 0.9}
{'fold': 9, 'epoch': 76, 'train_loss': 0.2808192610740662, 'val_loss': 0.19700948715209962, 'test_acc': 0.9}
{'fold': 9, 'epoch': 77, 'train_loss': 0.2641983777284622, 'val_loss': 0.20594573259353638, 'test_acc': 0.875}
{'fold': 9, 'epoch': 78, 'train_loss': 0.2691605842113495, 'val_loss': 0.17591180324554442, 'test_acc': 0.89}
{'fold': 9, 'epoch': 79, 'train_loss': 0.26359170079231264, 'val_loss': 0.18427330017089844, 'test_acc': 0.89}
{'fold': 9, 'epoch': 80, 'train_loss': 0.24151186466217042, 'val_loss': 0.17381920337677, 'test_acc': 0.885}
{'fold': 9, 'epoch': 81, 'train_loss': 0.25590086936950684, 'val_loss': 0.2252359676361084, 'test_acc': 0.87}
{'fold': 9, 'epoch': 82, 'train_loss': 0.2592086935043335, 'val_loss': 0.19934205532073976, 'test_acc': 0.895}
{'fold': 9, 'epoch': 83, 'train_loss': 0.24083582639694215, 'val_loss': 0.18232399463653565, 'test_acc': 0.88}
{'fold': 9, 'epoch': 84, 'train_loss': 0.24449704766273497, 'val_loss': 0.1897969102859497, 'test_acc': 0.89}
{'fold': 9, 'epoch': 85, 'train_loss': 0.24926054120063781, 'val_loss': 0.17508827209472655, 'test_acc': 0.89}
{'fold': 9, 'epoch': 86, 'train_loss': 0.24249873518943788, 'val_loss': 0.2099967622756958, 'test_acc': 0.89}
{'fold': 9, 'epoch': 87, 'train_loss': 0.23655327320098876, 'val_loss': 0.20961612224578857, 'test_acc': 0.885}
{'fold': 9, 'epoch': 88, 'train_loss': 0.26175395369529725, 'val_loss': 0.21152823448181152, 'test_acc': 0.895}
{'fold': 9, 'epoch': 89, 'train_loss': 0.24471739292144776, 'val_loss': 0.17493975162506104, 'test_acc': 0.9}
{'fold': 9, 'epoch': 90, 'train_loss': 0.2318751958012581, 'val_loss': 0.21291005611419678, 'test_acc': 0.905}
{'fold': 9, 'epoch': 91, 'train_loss': 0.2244496738910675, 'val_loss': 0.17099183559417724, 'test_acc': 0.94}
{'fold': 9, 'epoch': 92, 'train_loss': 0.21063047647476196, 'val_loss': 0.17148268938064576, 'test_acc': 0.91}
{'fold': 9, 'epoch': 93, 'train_loss': 0.22165652573108674, 'val_loss': 0.21830327987670897, 'test_acc': 0.89}
{'fold': 9, 'epoch': 94, 'train_loss': 0.22563813328742982, 'val_loss': 0.1597610330581665, 'test_acc': 0.9}
{'fold': 9, 'epoch': 95, 'train_loss': 0.22666151881217955, 'val_loss': 0.1666971969604492, 'test_acc': 0.915}
{'fold': 9, 'epoch': 96, 'train_loss': 0.21397708237171173, 'val_loss': 0.16541045665740967, 'test_acc': 0.905}
{'fold': 9, 'epoch': 97, 'train_loss': 0.22830598652362824, 'val_loss': 0.18065183162689208, 'test_acc': 0.925}
{'fold': 9, 'epoch': 98, 'train_loss': 0.20226019024848937, 'val_loss': 0.19387391090393066, 'test_acc': 0.89}
{'fold': 9, 'epoch': 99, 'train_loss': 0.23968405425548553, 'val_loss': 0.17629278659820558, 'test_acc': 0.905}
{'fold': 9, 'epoch': 100, 'train_loss': 0.21390866219997406, 'val_loss': 0.16112853050231934, 'test_acc': 0.915}
Val Loss: 0.2867, Test Accuracy: 0.883 ± 0.023, Duration: 35.254
Best result - 0.883 ± 0.023
--
DD - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.684158896995803, 'val_loss': 0.6771055694319245, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6844626362040892, 'val_loss': 0.6783685276650975, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6822095816418275, 'val_loss': 0.6769654363648504, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6800270514973139, 'val_loss': 0.6771421514005742, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6799079553555634, 'val_loss': 0.677235334347456, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6795614614325055, 'val_loss': 0.6769611326038328, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6786244976318488, 'val_loss': 0.6769534380008013, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6776062522904348, 'val_loss': 0.6769778911884015, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6791531423390922, 'val_loss': 0.677072508722289, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6763515068312823, 'val_loss': 0.677109612358941, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6798426650338254, 'val_loss': 0.6777728480151576, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 12, 'train_loss': 0.6798670099953473, 'val_loss': 0.6769536336263021, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 13, 'train_loss': 0.6804785435482607, 'val_loss': 0.6769450261042669, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 14, 'train_loss': 0.6812993257732715, 'val_loss': 0.6770824856228299, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 15, 'train_loss': 0.678665004544339, 'val_loss': 0.6778584667760083, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 16, 'train_loss': 0.6787421713441105, 'val_loss': 0.6771305442875267, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 17, 'train_loss': 0.6787223421921165, 'val_loss': 0.6770992442073985, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 18, 'train_loss': 0.6787243727910317, 'val_loss': 0.6769618498973358, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 19, 'train_loss': 0.6793293983249341, 'val_loss': 0.6769832382854234, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 20, 'train_loss': 0.6779008548138505, 'val_loss': 0.6771226540589944, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 21, 'train_loss': 0.6793705972574525, 'val_loss': 0.6770049527160122, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 22, 'train_loss': 0.679288634809397, 'val_loss': 0.677309085161258, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 23, 'train_loss': 0.6791892122414153, 'val_loss': 0.6772987170097156, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 24, 'train_loss': 0.6780005117594186, 'val_loss': 0.6769894330929487, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 25, 'train_loss': 0.6782535466097169, 'val_loss': 0.6769548073793069, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 26, 'train_loss': 0.6790592064291744, 'val_loss': 0.6770907018938636, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 27, 'train_loss': 0.6778023636947244, 'val_loss': 0.6771486722506009, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 28, 'train_loss': 0.679033702712948, 'val_loss': 0.6772427681164864, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 29, 'train_loss': 0.6798469333325402, 'val_loss': 0.6769754784738916, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 30, 'train_loss': 0.67835612923412, 'val_loss': 0.6771881886017628, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 31, 'train_loss': 0.679131348254317, 'val_loss': 0.6772694383930956, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 32, 'train_loss': 0.6791428388175318, 'val_loss': 0.6769719572148771, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 33, 'train_loss': 0.6786433630070444, 'val_loss': 0.676955329047309, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 34, 'train_loss': 0.6790388933682846, 'val_loss': 0.676985846625434, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 35, 'train_loss': 0.6776428869215109, 'val_loss': 0.6769818036984174, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 36, 'train_loss': 0.678745341503014, 'val_loss': 0.6769984970744859, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 37, 'train_loss': 0.6781219314720671, 'val_loss': 0.6769654363648504, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 38, 'train_loss': 0.6784682597144175, 'val_loss': 0.6770397740551549, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 39, 'train_loss': 0.6786651479995857, 'val_loss': 0.6769649799053485, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 40, 'train_loss': 0.6784233834783909, 'val_loss': 0.6769521338307959, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 41, 'train_loss': 0.6797658669746528, 'val_loss': 0.6770710089267828, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 42, 'train_loss': 0.6785143926992254, 'val_loss': 0.6771310007470286, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 43, 'train_loss': 0.6789121789447332, 'val_loss': 0.6769610021868323, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 44, 'train_loss': 0.6791015348191989, 'val_loss': 0.6769718267978766, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 45, 'train_loss': 0.6782967347209736, 'val_loss': 0.6770013010399973, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 46, 'train_loss': 0.6784739837808124, 'val_loss': 0.6770443386501737, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 47, 'train_loss': 0.6782454464395168, 'val_loss': 0.6770028008355035, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 48, 'train_loss': 0.6784115211438324, 'val_loss': 0.6770011054144965, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 49, 'train_loss': 0.6788873955354853, 'val_loss': 0.6771735166892027, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 50, 'train_loss': 0.6786647489515402, 'val_loss': 0.6769904764289529, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 51, 'train_loss': 0.6786875148950997, 'val_loss': 0.6770751170622997, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 52, 'train_loss': 0.6783190733295376, 'val_loss': 0.6769731309678819, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 53, 'train_loss': 0.6789257283938133, 'val_loss': 0.677030253614116, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 54, 'train_loss': 0.6786240278664282, 'val_loss': 0.6769778911884015, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 55, 'train_loss': 0.6784888415013329, 'val_loss': 0.6770266671466012, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 56, 'train_loss': 0.6786199474738817, 'val_loss': 0.6770231458875868, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 57, 'train_loss': 0.6784167380656226, 'val_loss': 0.6769844120384282, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 58, 'train_loss': 0.6784930390826727, 'val_loss': 0.6770584236862313, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 59, 'train_loss': 0.6784573247877218, 'val_loss': 0.6770056048010149, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 60, 'train_loss': 0.6783567656904964, 'val_loss': 0.6772944784571981, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 61, 'train_loss': 0.6790012919296653, 'val_loss': 0.6771203717614851, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 62, 'train_loss': 0.6780498088416407, 'val_loss': 0.6770309709076189, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 63, 'train_loss': 0.6782665586067458, 'val_loss': 0.6769518077882946, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 64, 'train_loss': 0.6788729641397121, 'val_loss': 0.6769521338307959, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 65, 'train_loss': 0.6782720685005188, 'val_loss': 0.6769537640433027, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 66, 'train_loss': 0.6783318671129518, 'val_loss': 0.6769834991194245, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 67, 'train_loss': 0.6784387776407145, 'val_loss': 0.6770513811682024, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 68, 'train_loss': 0.6779586581860558, 'val_loss': 0.6770395132211539, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 69, 'train_loss': 0.6782017269376981, 'val_loss': 0.6769559159238114, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 70, 'train_loss': 0.6780505018719172, 'val_loss': 0.6770929841913729, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 71, 'train_loss': 0.6795364638506356, 'val_loss': 0.6771223932249933, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 72, 'train_loss': 0.6790403077157877, 'val_loss': 0.6770863329243456, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 73, 'train_loss': 0.6791373359954963, 'val_loss': 0.6772367689344618, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 74, 'train_loss': 0.6784030582945225, 'val_loss': 0.6769626976078392, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 75, 'train_loss': 0.6780777129076295, 'val_loss': 0.6769608717698318, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 76, 'train_loss': 0.6791583814863431, 'val_loss': 0.6770001272869925, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 77, 'train_loss': 0.6783980525146096, 'val_loss': 0.6769635453183427, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 78, 'train_loss': 0.6791111705666881, 'val_loss': 0.6772440070779915, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 79, 'train_loss': 0.6784134022260117, 'val_loss': 0.6772217709794004, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 80, 'train_loss': 0.6783626786733078, 'val_loss': 0.6770011054144965, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 81, 'train_loss': 0.6785286927627305, 'val_loss': 0.6769617194803352, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 82, 'train_loss': 0.6784330576153125, 'val_loss': 0.6769667405348557, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 83, 'train_loss': 0.6781493940595853, 'val_loss': 0.6769759349333935, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 84, 'train_loss': 0.6788464087550923, 'val_loss': 0.6771213498889891, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 85, 'train_loss': 0.6784889223211903, 'val_loss': 0.6771143073709602, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 86, 'train_loss': 0.6785210916551493, 'val_loss': 0.6770823552058294, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 87, 'train_loss': 0.6785524507700387, 'val_loss': 0.6771390866010617, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 88, 'train_loss': 0.6784410042277838, 'val_loss': 0.676999018742488, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 89, 'train_loss': 0.6783404057308778, 'val_loss': 0.6769570896768162, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 90, 'train_loss': 0.6783273876723597, 'val_loss': 0.6769667405348557, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 91, 'train_loss': 0.6783905786983038, 'val_loss': 0.676993149977464, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 92, 'train_loss': 0.6784640692048154, 'val_loss': 0.6769520034137954, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 93, 'train_loss': 0.6784615395432811, 'val_loss': 0.6769623063568376, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 94, 'train_loss': 0.6784665069337619, 'val_loss': 0.6769767826438969, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 95, 'train_loss': 0.6786282830319162, 'val_loss': 0.6769816732814169, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 96, 'train_loss': 0.678556423066026, 'val_loss': 0.6769557855068109, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 97, 'train_loss': 0.6784100057715077, 'val_loss': 0.6769740438868856, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 98, 'train_loss': 0.6783951318870156, 'val_loss': 0.6770799424913194, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 99, 'train_loss': 0.6784278225090544, 'val_loss': 0.6770434257311698, 'test_acc': 0.5897435897435898}
{'fold': 9, 'epoch': 100, 'train_loss': 0.6783819360248113, 'val_loss': 0.6770865937583467, 'test_acc': 0.5897435897435898}
Val Loss: 0.6361, Test Accuracy: 0.644 ± 0.067, Duration: 20.110
Best result - 0.644 ± 0.067
--
NCI1 - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6986079777244234, 'val_loss': 0.6932297309819799, 'test_acc': 0.49878345498783455}
{'fold': 9, 'epoch': 2, 'train_loss': 0.6916009583612428, 'val_loss': 0.6776055895209022, 'test_acc': 0.5474452554744526}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6841700583188783, 'val_loss': 0.642562764114417, 'test_acc': 0.5912408759124088}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6742959051526666, 'val_loss': 0.6565288928883499, 'test_acc': 0.5790754257907542}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6719982436973683, 'val_loss': 0.6415822244908688, 'test_acc': 0.5936739659367397}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6613804448550055, 'val_loss': 0.6475937929176646, 'test_acc': 0.5985401459854015}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6659574985794198, 'val_loss': 0.6532353774764532, 'test_acc': 0.6058394160583942}
{'fold': 9, 'epoch': 8, 'train_loss': 0.6586600655186785, 'val_loss': 0.6459061049486889, 'test_acc': 0.5693430656934306}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6364966707798106, 'val_loss': 0.6212410126289312, 'test_acc': 0.6374695863746959}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6351676191726741, 'val_loss': 0.6144589101601111, 'test_acc': 0.6374695863746959}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6412482573458168, 'val_loss': 0.6251808152581654, 'test_acc': 0.6472019464720195}
{'fold': 9, 'epoch': 12, 'train_loss': 0.631942266820411, 'val_loss': 0.6122774114864006, 'test_acc': 0.6058394160583942}
{'fold': 9, 'epoch': 13, 'train_loss': 0.6245980950167579, 'val_loss': 0.6065550337742714, 'test_acc': 0.6277372262773723}
{'fold': 9, 'epoch': 14, 'train_loss': 0.633459757714376, 'val_loss': 0.6224330428743015, 'test_acc': 0.6301703163017032}
{'fold': 9, 'epoch': 15, 'train_loss': 0.6301535589851602, 'val_loss': 0.6262189349988951, 'test_acc': 0.6399026763990268}
{'fold': 9, 'epoch': 16, 'train_loss': 0.6275297238008819, 'val_loss': 0.6156084241658232, 'test_acc': 0.6423357664233577}
{'fold': 9, 'epoch': 17, 'train_loss': 0.622137518984848, 'val_loss': 0.6118410672004495, 'test_acc': 0.6593673965936739}
{'fold': 9, 'epoch': 18, 'train_loss': 0.6504745291967462, 'val_loss': 0.6358625082493988, 'test_acc': 0.5742092457420924}
{'fold': 9, 'epoch': 19, 'train_loss': 0.6298067590035952, 'val_loss': 0.617426229509414, 'test_acc': 0.610705596107056}
{'fold': 9, 'epoch': 20, 'train_loss': 0.6297271766511773, 'val_loss': 0.6117556681018096, 'test_acc': 0.6131386861313869}
{'fold': 9, 'epoch': 21, 'train_loss': 0.6230999241490144, 'val_loss': 0.586664914504745, 'test_acc': 0.6788321167883211}
{'fold': 9, 'epoch': 22, 'train_loss': 0.6219273883930958, 'val_loss': 0.6023392178426403, 'test_acc': 0.6690997566909975}
{'fold': 9, 'epoch': 23, 'train_loss': 0.6661545460241555, 'val_loss': 0.5886467007824975, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 24, 'train_loss': 0.6189444907680335, 'val_loss': 0.5798265545327588, 'test_acc': 0.6715328467153284}
{'fold': 9, 'epoch': 25, 'train_loss': 0.6493950084468164, 'val_loss': 4.31300766102589, 'test_acc': 0.6374695863746959}
{'fold': 9, 'epoch': 26, 'train_loss': 0.6238885353661512, 'val_loss': 3.80330082969944, 'test_acc': 0.6739659367396593}
{'fold': 9, 'epoch': 27, 'train_loss': 0.6111273342095442, 'val_loss': 3.5588378395767397, 'test_acc': 0.6545012165450121}
{'fold': 9, 'epoch': 28, 'train_loss': 0.6089389332889641, 'val_loss': 3.482659848067012, 'test_acc': 0.6642335766423357}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5931326471396027, 'val_loss': 4.788929902144012, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5871613713076514, 'val_loss': 4.120413002886622, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 31, 'train_loss': 0.5877818249147884, 'val_loss': 5.204445068563568, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5809689531071053, 'val_loss': 5.049908561428098, 'test_acc': 0.6690997566909975}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5740465633480508, 'val_loss': 5.383352971134975, 'test_acc': 0.6861313868613139}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5771763933836108, 'val_loss': 5.0617995946656755, 'test_acc': 0.6472019464720195}
{'fold': 9, 'epoch': 35, 'train_loss': 0.6084356248523777, 'val_loss': 4.373103403987096, 'test_acc': 0.6861313868613139}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5895086574728472, 'val_loss': 6.071334931682206, 'test_acc': 0.7055961070559611}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5767697258297254, 'val_loss': 7.2114007304764725, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5560173245822136, 'val_loss': 4.46136148596622, 'test_acc': 0.6934306569343066}
{'fold': 9, 'epoch': 39, 'train_loss': 0.578253019755194, 'val_loss': 2.8239562459235645, 'test_acc': 0.6399026763990268}
{'fold': 9, 'epoch': 40, 'train_loss': 0.5761499612290784, 'val_loss': 2.6727182847740005, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 41, 'train_loss': 0.6051899892280281, 'val_loss': 0.5694507891244261, 'test_acc': 0.7007299270072993}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5988385541015588, 'val_loss': 0.5530365389338955, 'test_acc': 0.7007299270072993}
{'fold': 9, 'epoch': 43, 'train_loss': 0.5646091668420175, 'val_loss': 0.5423765576958947, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 44, 'train_loss': 0.5563472581895889, 'val_loss': 0.551825917840294, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 45, 'train_loss': 0.5741691792388322, 'val_loss': 0.5660522349559478, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 46, 'train_loss': 0.5684442012559469, 'val_loss': 0.5538615809159847, 'test_acc': 0.6934306569343066}
{'fold': 9, 'epoch': 47, 'train_loss': 0.5616229672501557, 'val_loss': 0.5635668784742518, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 48, 'train_loss': 0.5458529429134081, 'val_loss': 0.5426485706709887, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 49, 'train_loss': 0.5437493817359572, 'val_loss': 0.5623890489267317, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 50, 'train_loss': 0.5550076659868524, 'val_loss': 0.5491350689073549, 'test_acc': 0.7031630170316302}
{'fold': 9, 'epoch': 51, 'train_loss': 0.5420527568408753, 'val_loss': 0.5435269070367743, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 52, 'train_loss': 0.5431679337854223, 'val_loss': 0.5558143114521555, 'test_acc': 0.7153284671532847}
{'fold': 9, 'epoch': 53, 'train_loss': 0.5414268043789551, 'val_loss': 0.5292081368810649, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 54, 'train_loss': 0.5436014524341499, 'val_loss': 0.5677740881332806, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 55, 'train_loss': 0.5571558021570935, 'val_loss': 0.5715279544356966, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 56, 'train_loss': 0.5372014084871668, 'val_loss': 0.5237465693712815, 'test_acc': 0.6958637469586375}
{'fold': 9, 'epoch': 57, 'train_loss': 0.540600027408623, 'val_loss': 0.5396071663738167, 'test_acc': 0.708029197080292}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5272281600611053, 'val_loss': 0.5806186170183539, 'test_acc': 0.6642335766423357}
{'fold': 9, 'epoch': 59, 'train_loss': 0.5596822691659857, 'val_loss': 0.5650216425132287, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 60, 'train_loss': 0.5474693428570917, 'val_loss': 0.5478158147955753, 'test_acc': 0.6934306569343066}
{'fold': 9, 'epoch': 61, 'train_loss': 0.5446405489079273, 'val_loss': 0.5463880552862682, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 62, 'train_loss': 0.5353934466113719, 'val_loss': 0.5396403663059801, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 63, 'train_loss': 0.5323636754440855, 'val_loss': 0.572071722824208, 'test_acc': 0.6885644768856448}
{'fold': 9, 'epoch': 64, 'train_loss': 0.5270205989951345, 'val_loss': 0.5638489201121086, 'test_acc': 0.683698296836983}
{'fold': 9, 'epoch': 65, 'train_loss': 0.557458394852868, 'val_loss': 0.5312513991864058, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 66, 'train_loss': 0.5289197424902533, 'val_loss': 0.5581523983437939, 'test_acc': 0.7007299270072993}
{'fold': 9, 'epoch': 67, 'train_loss': 0.5284279071501572, 'val_loss': 0.5529898715425292, 'test_acc': 0.7055961070559611}
{'fold': 9, 'epoch': 68, 'train_loss': 0.5273033651702306, 'val_loss': 0.5786534144640549, 'test_acc': 0.6593673965936739}
{'fold': 9, 'epoch': 69, 'train_loss': 0.5255851452658066, 'val_loss': 0.5333040706142602, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 70, 'train_loss': 0.5242918167091054, 'val_loss': 0.5490380493683826, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 71, 'train_loss': 0.527196021555694, 'val_loss': 0.535339225527724, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 72, 'train_loss': 0.5361950604875012, 'val_loss': 0.6030808052007299, 'test_acc': 0.6593673965936739}
{'fold': 9, 'epoch': 73, 'train_loss': 0.5282583712371306, 'val_loss': 0.5625592832727734, 'test_acc': 0.6909975669099757}
{'fold': 9, 'epoch': 74, 'train_loss': 0.527969201985937, 'val_loss': 0.5455408629999834, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 75, 'train_loss': 0.510724255928448, 'val_loss': 0.5364014887751744, 'test_acc': 0.7274939172749392}
{'fold': 9, 'epoch': 76, 'train_loss': 0.5149259551308161, 'val_loss': 0.5532331907546143, 'test_acc': 0.7226277372262774}
{'fold': 9, 'epoch': 77, 'train_loss': 0.529577695540268, 'val_loss': 0.5581122535278618, 'test_acc': 0.681265206812652}
{'fold': 9, 'epoch': 78, 'train_loss': 0.537397958791459, 'val_loss': 0.563202043519403, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 79, 'train_loss': 0.5263676061102364, 'val_loss': 0.5570857519070888, 'test_acc': 0.7372262773722628}
{'fold': 9, 'epoch': 80, 'train_loss': 0.5213260159005214, 'val_loss': 0.5746207109623002, 'test_acc': 0.7007299270072993}
{'fold': 9, 'epoch': 81, 'train_loss': 0.5145839035075946, 'val_loss': 0.538416010909997, 'test_acc': 0.7420924574209246}
{'fold': 9, 'epoch': 82, 'train_loss': 0.519027334060112, 'val_loss': 0.5185982687919969, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 83, 'train_loss': 0.5146169952522519, 'val_loss': 0.5587987273278898, 'test_acc': 0.6982968369829684}
{'fold': 9, 'epoch': 84, 'train_loss': 0.5152232897107618, 'val_loss': 0.5449538985018022, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 85, 'train_loss': 0.5012205663678709, 'val_loss': 0.5549791711960396, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 86, 'train_loss': 0.49684472806262275, 'val_loss': 0.5382393653665436, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 87, 'train_loss': 0.4981329993609964, 'val_loss': 0.5523486497048334, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 88, 'train_loss': 0.4974223256401192, 'val_loss': 0.5315501011201065, 'test_acc': 0.7055961070559611}
{'fold': 9, 'epoch': 89, 'train_loss': 0.4954155705270976, 'val_loss': 0.5666621502878603, 'test_acc': 0.7104622871046229}
{'fold': 9, 'epoch': 90, 'train_loss': 0.49845035653334757, 'val_loss': 0.5525637137048726, 'test_acc': 0.7201946472019465}
{'fold': 9, 'epoch': 91, 'train_loss': 0.49083035335923636, 'val_loss': 0.5381025513883345, 'test_acc': 0.7396593673965937}
{'fold': 9, 'epoch': 92, 'train_loss': 0.4912850019995604, 'val_loss': 0.5447267894327206, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 93, 'train_loss': 0.49200892883495695, 'val_loss': 0.5472197474644422, 'test_acc': 0.7177615571776156}
{'fold': 9, 'epoch': 94, 'train_loss': 0.4818953053794638, 'val_loss': 0.5311418055327849, 'test_acc': 0.7347931873479319}
{'fold': 9, 'epoch': 95, 'train_loss': 0.4886617363224354, 'val_loss': 0.551674415885387, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 96, 'train_loss': 0.47945676827372713, 'val_loss': 0.5476212605942775, 'test_acc': 0.7299270072992701}
{'fold': 9, 'epoch': 97, 'train_loss': 0.4845798468067698, 'val_loss': 0.561514434443193, 'test_acc': 0.7055961070559611}
{'fold': 9, 'epoch': 98, 'train_loss': 0.5062814840000042, 'val_loss': 0.5732226336959505, 'test_acc': 0.732360097323601}
{'fold': 9, 'epoch': 99, 'train_loss': 0.500299864731856, 'val_loss': 0.6009050912230555, 'test_acc': 0.7128953771289538}
{'fold': 9, 'epoch': 100, 'train_loss': 0.490679865625943, 'val_loss': 0.5728801300345836, 'test_acc': 0.7396593673965937}
Val Loss: 0.5291, Test Accuracy: 0.734 ± 0.036, Duration: 39.306
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Best result - 0.734 ± 0.036
--
PROTEINS - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.6974223648792699, 'val_loss': 0.6744005357896959, 'test_acc': 0.5945945945945946}
{'fold': 9, 'epoch': 2, 'train_loss': 0.670007856539738, 'val_loss': 0.6727806984841287, 'test_acc': 0.6216216216216216}
{'fold': 9, 'epoch': 3, 'train_loss': 0.6517396285611505, 'val_loss': 0.6007392127234656, 'test_acc': 0.6126126126126126}
{'fold': 9, 'epoch': 4, 'train_loss': 0.6376704739534226, 'val_loss': 0.672855686497044, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 5, 'train_loss': 0.6227881502355924, 'val_loss': 0.5619213001148121, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 6, 'train_loss': 0.6092210636797176, 'val_loss': 0.6570952819274353, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 7, 'train_loss': 0.6252562522085428, 'val_loss': 0.5588787181957348, 'test_acc': 0.7837837837837838}
{'fold': 9, 'epoch': 8, 'train_loss': 0.5999125061613141, 'val_loss': 0.5903787011498803, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 9, 'train_loss': 0.6281596380050736, 'val_loss': 0.5895144488360431, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 10, 'train_loss': 0.6128620261161282, 'val_loss': 0.5556914527137, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 11, 'train_loss': 0.6100742422236605, 'val_loss': 0.5610816886833122, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 12, 'train_loss': 0.5924000234983853, 'val_loss': 0.5459679612168321, 'test_acc': 0.7747747747747747}
{'fold': 9, 'epoch': 13, 'train_loss': 0.5821132386306052, 'val_loss': 0.5574427767916843, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 14, 'train_loss': 0.5957736738201745, 'val_loss': 0.5487367440988352, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 15, 'train_loss': 0.5753772386196085, 'val_loss': 0.5397935472093187, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 16, 'train_loss': 0.569423764843732, 'val_loss': 0.5335726007684931, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 17, 'train_loss': 0.5744969804011344, 'val_loss': 0.5636837589848149, 'test_acc': 0.6576576576576577}
{'fold': 9, 'epoch': 18, 'train_loss': 0.5824886334330412, 'val_loss': 0.5308349540641716, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 19, 'train_loss': 0.5844609061074176, 'val_loss': 0.5569146646035684, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 20, 'train_loss': 0.5806522495818861, 'val_loss': 0.5835448256484023, 'test_acc': 0.6396396396396397}
{'fold': 9, 'epoch': 21, 'train_loss': 0.5833714156841188, 'val_loss': 0.5346650132187852, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 22, 'train_loss': 0.5589586120395682, 'val_loss': 0.556986800185195, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 23, 'train_loss': 0.5772472287535534, 'val_loss': 0.526211437878308, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 24, 'train_loss': 0.5545063890458224, 'val_loss': 0.5310428722484691, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 25, 'train_loss': 0.5734403871259036, 'val_loss': 0.540798840222058, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 26, 'train_loss': 0.5673313808494679, 'val_loss': 0.5424071990691863, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 27, 'train_loss': 0.5571439395314782, 'val_loss': 0.5367380090661951, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 28, 'train_loss': 0.5637449351892996, 'val_loss': 0.523600672816371, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 29, 'train_loss': 0.5568547050827146, 'val_loss': 0.5243801769909558, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 30, 'train_loss': 0.5368151705540658, 'val_loss': 0.4804963464135522, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 31, 'train_loss': 0.53561780237991, 'val_loss': 0.4991798400878906, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 32, 'train_loss': 0.5532392844741727, 'val_loss': 0.5106449299030476, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 33, 'train_loss': 0.5587776426380598, 'val_loss': 0.4992210456916878, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 34, 'train_loss': 0.5713784785985144, 'val_loss': 0.5449841129887212, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 35, 'train_loss': 0.5607189023334169, 'val_loss': 0.5408416266913887, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 36, 'train_loss': 0.5658310812330406, 'val_loss': 0.5107218424479166, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 37, 'train_loss': 0.5447899592176966, 'val_loss': 0.5330159299008481, 'test_acc': 0.7657657657657657}
{'fold': 9, 'epoch': 38, 'train_loss': 0.5508418919395249, 'val_loss': 0.5264790165531743, 'test_acc': 0.6486486486486487}
{'fold': 9, 'epoch': 39, 'train_loss': 0.575518811591948, 'val_loss': 0.5127660046826612, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 40, 'train_loss': 0.558547884928257, 'val_loss': 0.5080411412694432, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 41, 'train_loss': 0.5440025914263913, 'val_loss': 0.5040891492688978, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 42, 'train_loss': 0.5457593517672734, 'val_loss': 0.491617185575468, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 43, 'train_loss': 0.5292387675623568, 'val_loss': 0.5026013142353779, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 44, 'train_loss': 0.5149933902502862, 'val_loss': 0.49381785349802926, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 45, 'train_loss': 0.5231962266862058, 'val_loss': 0.4681515392956433, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 46, 'train_loss': 0.5244456021205076, 'val_loss': 0.5258273906535931, 'test_acc': 0.6846846846846847}
{'fold': 9, 'epoch': 47, 'train_loss': 0.5268328065422649, 'val_loss': 0.549405828252569, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 48, 'train_loss': 0.5705146859791945, 'val_loss': 0.5296250420647699, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 49, 'train_loss': 0.5752078094733952, 'val_loss': 0.4982377816964914, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 50, 'train_loss': 0.5865184219865552, 'val_loss': 0.5262024338180954, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 51, 'train_loss': 0.5666781689315264, 'val_loss': 0.4920529889630842, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 52, 'train_loss': 0.5577088466664624, 'val_loss': 0.528481354584565, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 53, 'train_loss': 0.5652245331961164, 'val_loss': 0.46137292535455376, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 54, 'train_loss': 0.5716499119629095, 'val_loss': 0.4774846257390203, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 55, 'train_loss': 0.5392583066097949, 'val_loss': 0.4814090900592976, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 56, 'train_loss': 0.5352008013947377, 'val_loss': 0.4843031393515097, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 57, 'train_loss': 0.5239860131483688, 'val_loss': 0.4805132548014323, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 58, 'train_loss': 0.5084115264793037, 'val_loss': 0.48219292443077844, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 59, 'train_loss': 0.5218894084294637, 'val_loss': 0.5065346107826577, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 60, 'train_loss': 0.546720426358224, 'val_loss': 0.49217715564074815, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 61, 'train_loss': 0.5540394013043071, 'val_loss': 0.5035563288508235, 'test_acc': 0.7477477477477478}
{'fold': 9, 'epoch': 62, 'train_loss': 0.5483654378908117, 'val_loss': 0.49130352123363596, 'test_acc': 0.7567567567567568}
{'fold': 9, 'epoch': 63, 'train_loss': 0.5431698686479853, 'val_loss': 0.518063278885575, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 64, 'train_loss': 0.5304844398824989, 'val_loss': 0.5215366810291737, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 65, 'train_loss': 0.5399849172660665, 'val_loss': 0.5217892758481137, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 66, 'train_loss': 0.5315612686335973, 'val_loss': 0.4932656159272065, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 67, 'train_loss': 0.5304216196641376, 'val_loss': 0.5305759326831715, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 68, 'train_loss': 0.526453796393676, 'val_loss': 0.5127262424778294, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 69, 'train_loss': 0.5021495454506708, 'val_loss': 0.5319006636336043, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 70, 'train_loss': 0.5112651215926833, 'val_loss': 0.5115712827390378, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 71, 'train_loss': 0.5074417108772312, 'val_loss': 0.5204222739279807, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 72, 'train_loss': 0.5302238450307236, 'val_loss': 0.48539771690024985, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 73, 'train_loss': 0.510873357521832, 'val_loss': 0.47195145890519424, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 74, 'train_loss': 0.5051747373191329, 'val_loss': 0.4908964827254012, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 75, 'train_loss': 0.5035932362414102, 'val_loss': 0.49908447265625, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 76, 'train_loss': 0.48626568428461264, 'val_loss': 0.49049741727811796, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 77, 'train_loss': 0.47505671505039654, 'val_loss': 0.4931191452988633, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 78, 'train_loss': 0.5020625464175018, 'val_loss': 0.45922762209230716, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 79, 'train_loss': 0.4993476182322711, 'val_loss': 0.4491190867381053, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 80, 'train_loss': 0.48332885646927104, 'val_loss': 0.5065564336003484, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 81, 'train_loss': 0.5000560172612953, 'val_loss': 0.5289873002885698, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 82, 'train_loss': 0.4651969206654263, 'val_loss': 0.5018982071060318, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 83, 'train_loss': 0.47439183901857446, 'val_loss': 0.5210074347418707, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 84, 'train_loss': 0.4660843817473261, 'val_loss': 0.5075522757865287, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 85, 'train_loss': 0.5116930129016958, 'val_loss': 0.5212532593323304, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 86, 'train_loss': 0.5331122738745077, 'val_loss': 0.520245732487859, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 87, 'train_loss': 0.5071516442379165, 'val_loss': 0.517511763014235, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 88, 'train_loss': 0.48149186677135336, 'val_loss': 0.5028040086900866, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 89, 'train_loss': 0.480364223923346, 'val_loss': 0.5120264689127604, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 90, 'train_loss': 0.48368275319419457, 'val_loss': 0.4746732282208967, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 91, 'train_loss': 0.47860040578376567, 'val_loss': 0.5304710456916878, 'test_acc': 0.6756756756756757}
{'fold': 9, 'epoch': 92, 'train_loss': 0.48579555602721225, 'val_loss': 0.5094683191797755, 'test_acc': 0.7297297297297297}
{'fold': 9, 'epoch': 93, 'train_loss': 0.4725758647410289, 'val_loss': 0.6190498283317497, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 94, 'train_loss': 0.4998393749147152, 'val_loss': 0.47646472690341707, 'test_acc': 0.6666666666666666}
{'fold': 9, 'epoch': 95, 'train_loss': 0.4911549271959247, 'val_loss': 0.511953439798441, 'test_acc': 0.7387387387387387}
{'fold': 9, 'epoch': 96, 'train_loss': 0.4758943062438708, 'val_loss': 0.48915021054379576, 'test_acc': 0.7117117117117117}
{'fold': 9, 'epoch': 97, 'train_loss': 0.4659235114869312, 'val_loss': 0.47337423788534627, 'test_acc': 0.7027027027027027}
{'fold': 9, 'epoch': 98, 'train_loss': 0.4498206715190451, 'val_loss': 0.472970945341093, 'test_acc': 0.7207207207207207}
{'fold': 9, 'epoch': 99, 'train_loss': 0.45651890121726474, 'val_loss': 0.46646685213656036, 'test_acc': 0.6936936936936937}
{'fold': 9, 'epoch': 100, 'train_loss': 0.48928528274885064, 'val_loss': 0.5265893678407412, 'test_acc': 0.6846846846846847}
Val Loss: 0.5257, Test Accuracy: 0.707 ± 0.043, Duration: 10.375
Best result - 0.707 ± 0.043
--
COLLAB - GlobalAttentionNet
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\data\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
D:\Program\Anaconda\envs\pyg\lib\site-packages\torch_geometric\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
{'fold': 9, 'epoch': 1, 'train_loss': 0.9541112022399902, 'val_loss': 0.719381591796875, 'test_acc': 0.648}
{'fold': 9, 'epoch': 2, 'train_loss': 0.659256356716156, 'val_loss': 0.5835323944091797, 'test_acc': 0.71}
{'fold': 9, 'epoch': 3, 'train_loss': 0.5791232204437256, 'val_loss': 0.5466948013305664, 'test_acc': 0.732}
{'fold': 9, 'epoch': 4, 'train_loss': 0.5672232918739318, 'val_loss': 0.5352169723510742, 'test_acc': 0.726}
{'fold': 9, 'epoch': 5, 'train_loss': 0.5410197169780732, 'val_loss': 0.5017553100585938, 'test_acc': 0.75}
{'fold': 9, 'epoch': 6, 'train_loss': 0.5078520956039428, 'val_loss': 0.5011426467895508, 'test_acc': 0.742}
{'fold': 9, 'epoch': 7, 'train_loss': 0.4899733221530914, 'val_loss': 0.5755094680786133, 'test_acc': 0.724}
{'fold': 9, 'epoch': 8, 'train_loss': 0.47652225255966185, 'val_loss': 0.4963425369262695, 'test_acc': 0.74}
{'fold': 9, 'epoch': 9, 'train_loss': 0.4742033076286316, 'val_loss': 0.5132112884521485, 'test_acc': 0.776}
{'fold': 9, 'epoch': 10, 'train_loss': 0.45107177448272706, 'val_loss': 0.5037862243652343, 'test_acc': 0.726}
{'fold': 9, 'epoch': 11, 'train_loss': 0.4457365572452545, 'val_loss': 0.5008829879760742, 'test_acc': 0.784}
{'fold': 9, 'epoch': 12, 'train_loss': 0.42886585760116575, 'val_loss': 0.5206977157592774, 'test_acc': 0.76}
{'fold': 9, 'epoch': 13, 'train_loss': 0.4305949740409851, 'val_loss': 0.5063846435546875, 'test_acc': 0.772}
{'fold': 9, 'epoch': 14, 'train_loss': 0.428799870967865, 'val_loss': 0.4752054710388184, 'test_acc': 0.79}
{'fold': 9, 'epoch': 15, 'train_loss': 0.38710507869720456, 'val_loss': 0.5617425689697265, 'test_acc': 0.804}
{'fold': 9, 'epoch': 16, 'train_loss': 0.37307868456840515, 'val_loss': 0.6440793571472168, 'test_acc': 0.794}
{'fold': 9, 'epoch': 17, 'train_loss': 0.36071135902404783, 'val_loss': 0.4766917037963867, 'test_acc': 0.796}
{'fold': 9, 'epoch': 18, 'train_loss': 0.3498760859966278, 'val_loss': 0.5411571388244629, 'test_acc': 0.808}
{'fold': 9, 'epoch': 19, 'train_loss': 0.3518783190250397, 'val_loss': 0.487659797668457, 'test_acc': 0.816}
{'fold': 9, 'epoch': 20, 'train_loss': 0.31525109958648684, 'val_loss': 0.6576084213256836, 'test_acc': 0.804}
{'fold': 9, 'epoch': 21, 'train_loss': 0.33210696864128114, 'val_loss': 0.5602393798828125, 'test_acc': 0.8}
{'fold': 9, 'epoch': 22, 'train_loss': 0.2975357794761658, 'val_loss': 0.6113849945068359, 'test_acc': 0.786}
{'fold': 9, 'epoch': 23, 'train_loss': 0.3115402793884277, 'val_loss': 0.5910845260620117, 'test_acc': 0.778}
{'fold': 9, 'epoch': 24, 'train_loss': 0.2950431592464447, 'val_loss': 0.6992182159423828, 'test_acc': 0.81}
{'fold': 9, 'epoch': 25, 'train_loss': 0.29698073863983154, 'val_loss': 0.8092457122802734, 'test_acc': 0.806}
{'fold': 9, 'epoch': 26, 'train_loss': 0.2920032560825348, 'val_loss': 0.8067319412231445, 'test_acc': 0.784}
{'fold': 9, 'epoch': 27, 'train_loss': 0.26406899523735045, 'val_loss': 0.6972049789428711, 'test_acc': 0.794}
{'fold': 9, 'epoch': 28, 'train_loss': 0.29370038998126985, 'val_loss': 0.7273223037719727, 'test_acc': 0.806}
{'fold': 9, 'epoch': 29, 'train_loss': 0.2939905436038971, 'val_loss': 0.5718906784057617, 'test_acc': 0.824}
{'fold': 9, 'epoch': 30, 'train_loss': 0.2548026683330536, 'val_loss': 0.580371353149414, 'test_acc': 0.808}
{'fold': 9, 'epoch': 31, 'train_loss': 0.2749486998319626, 'val_loss': 0.7149169464111328, 'test_acc': 0.8}
{'fold': 9, 'epoch': 32, 'train_loss': 0.2492527551651001, 'val_loss': 0.5922517471313477, 'test_acc': 0.816}
{'fold': 9, 'epoch': 33, 'train_loss': 0.24089820218086241, 'val_loss': 0.6600613479614258, 'test_acc': 0.8}
{'fold': 9, 'epoch': 34, 'train_loss': 0.2413286302089691, 'val_loss': 0.607069450378418, 'test_acc': 0.784}
{'fold': 9, 'epoch': 35, 'train_loss': 0.25909678399562835, 'val_loss': 0.6139508438110352, 'test_acc': 0.798}
{'fold': 9, 'epoch': 36, 'train_loss': 0.23921426117420197, 'val_loss': 0.6209143524169922, 'test_acc': 0.804}
{'fold': 9, 'epoch': 37, 'train_loss': 0.24050084209442138, 'val_loss': 0.6516497573852539, 'test_acc': 0.794}
{'fold': 9, 'epoch': 38, 'train_loss': 0.22989326393604279, 'val_loss': 0.6005211257934571, 'test_acc': 0.792}
{'fold': 9, 'epoch': 39, 'train_loss': 0.22260313212871552, 'val_loss': 0.6235735778808593, 'test_acc': 0.79}
{'fold': 9, 'epoch': 40, 'train_loss': 0.24664737010002136, 'val_loss': 0.5850230331420898, 'test_acc': 0.814}
{'fold': 9, 'epoch': 41, 'train_loss': 0.23508747959136964, 'val_loss': 0.5920253143310547, 'test_acc': 0.796}
{'fold': 9, 'epoch': 42, 'train_loss': 0.24055929541587828, 'val_loss': 0.6676091918945313, 'test_acc': 0.788}
{'fold': 9, 'epoch': 43, 'train_loss': 0.20531488704681397, 'val_loss': 0.8794290771484375, 'test_acc': 0.786}
{'fold': 9, 'epoch': 44, 'train_loss': 0.18220588493347167, 'val_loss': 0.9917013549804687, 'test_acc': 0.812}
{'fold': 9, 'epoch': 45, 'train_loss': 0.16025875508785248, 'val_loss': 0.9770612182617188, 'test_acc': 0.786}
{'fold': 9, 'epoch': 46, 'train_loss': 0.21738815498352052, 'val_loss': 0.87541552734375, 'test_acc': 0.802}
{'fold': 9, 'epoch': 47, 'train_loss': 0.19942752647399903, 'val_loss': 1.1783909912109376, 'test_acc': 0.796}
{'fold': 9, 'epoch': 48, 'train_loss': 0.20784309101104737, 'val_loss': 0.7591878662109375, 'test_acc': 0.816}
{'fold': 9, 'epoch': 49, 'train_loss': 0.19525659954547883, 'val_loss': 0.8031662521362305, 'test_acc': 0.81}
{'fold': 9, 'epoch': 50, 'train_loss': 0.18995898151397705, 'val_loss': 1.1976139602661133, 'test_acc': 0.766}
{'fold': 9, 'epoch': 51, 'train_loss': 0.2770336494445801, 'val_loss': 0.6705034637451172, 'test_acc': 0.806}
{'fold': 9, 'epoch': 52, 'train_loss': 0.2623885982632637, 'val_loss': 0.961160873413086, 'test_acc': 0.766}
{'fold': 9, 'epoch': 53, 'train_loss': 0.4849528770446777, 'val_loss': 0.6374184722900391, 'test_acc': 0.776}
{'fold': 9, 'epoch': 54, 'train_loss': 0.3222892382144928, 'val_loss': 0.660979751586914, 'test_acc': 0.782}
{'fold': 9, 'epoch': 55, 'train_loss': 0.2700572001934052, 'val_loss': 0.6530180587768555, 'test_acc': 0.792}
{'fold': 9, 'epoch': 56, 'train_loss': 0.23005715703964233, 'val_loss': 0.7557291107177735, 'test_acc': 0.81}
{'fold': 9, 'epoch': 57, 'train_loss': 0.21233861768245696, 'val_loss': 0.7781610641479492, 'test_acc': 0.806}
{'fold': 9, 'epoch': 58, 'train_loss': 0.17127670276165008, 'val_loss': 0.779284423828125, 'test_acc': 0.804}
{'fold': 9, 'epoch': 59, 'train_loss': 0.17837165319919587, 'val_loss': 1.0257381973266602, 'test_acc': 0.788}
{'fold': 9, 'epoch': 60, 'train_loss': 0.18549378192424773, 'val_loss': 0.7728990325927735, 'test_acc': 0.766}
{'fold': 9, 'epoch': 61, 'train_loss': 0.18372801768779753, 'val_loss': 0.7685761489868164, 'test_acc': 0.782}
{'fold': 9, 'epoch': 62, 'train_loss': 0.1612280639410019, 'val_loss': 1.1612938842773437, 'test_acc': 0.764}
{'fold': 9, 'epoch': 63, 'train_loss': 0.23492620253562926, 'val_loss': 0.7944800491333008, 'test_acc': 0.758}
{'fold': 9, 'epoch': 64, 'train_loss': 0.19716049486398696, 'val_loss': 0.8072970428466797, 'test_acc': 0.794}
{'fold': 9, 'epoch': 65, 'train_loss': 0.19036198681592942, 'val_loss': 0.8513779830932617, 'test_acc': 0.78}
{'fold': 9, 'epoch': 66, 'train_loss': 0.15536313009262084, 'val_loss': 0.9175184631347656, 'test_acc': 0.768}
{'fold': 9, 'epoch': 67, 'train_loss': 0.13514644920825958, 'val_loss': 0.9541855010986328, 'test_acc': 0.776}
{'fold': 9, 'epoch': 68, 'train_loss': 0.13982983088493348, 'val_loss': 1.0041362915039063, 'test_acc': 0.78}
{'fold': 9, 'epoch': 69, 'train_loss': 0.1728537327647209, 'val_loss': 1.0017334594726564, 'test_acc': 0.768}
{'fold': 9, 'epoch': 70, 'train_loss': 0.16756402784585953, 'val_loss': 0.8448540420532227, 'test_acc': 0.792}
{'fold': 9, 'epoch': 71, 'train_loss': 0.12834147191047668, 'val_loss': 1.2264674224853516, 'test_acc': 0.776}
{'fold': 9, 'epoch': 72, 'train_loss': 0.14712316250801086, 'val_loss': 0.933807861328125, 'test_acc': 0.782}
{'fold': 9, 'epoch': 73, 'train_loss': 0.1484327493906021, 'val_loss': 0.8658518447875977, 'test_acc': 0.814}
{'fold': 9, 'epoch': 74, 'train_loss': 0.13629537558555602, 'val_loss': 0.9976184005737305, 'test_acc': 0.76}
{'fold': 9, 'epoch': 75, 'train_loss': 0.13796628701686858, 'val_loss': 1.4153314971923827, 'test_acc': 0.758}
{'fold': 9, 'epoch': 76, 'train_loss': 0.14674115812778474, 'val_loss': 1.1570477447509766, 'test_acc': 0.794}
{'fold': 9, 'epoch': 77, 'train_loss': 0.1091764919757843, 'val_loss': 1.3561654357910156, 'test_acc': 0.768}
{'fold': 9, 'epoch': 78, 'train_loss': 0.1076750855743885, 'val_loss': 1.4224840393066407, 'test_acc': 0.756}
{'fold': 9, 'epoch': 79, 'train_loss': 0.12671337723731996, 'val_loss': 1.3692086334228515, 'test_acc': 0.78}
{'fold': 9, 'epoch': 80, 'train_loss': 0.12339698469638824, 'val_loss': 1.117301803588867, 'test_acc': 0.792}
{'fold': 9, 'epoch': 81, 'train_loss': 0.12132645171880722, 'val_loss': 0.9419604034423829, 'test_acc': 0.776}
{'fold': 9, 'epoch': 82, 'train_loss': 0.10943212501704692, 'val_loss': 1.1408838958740235, 'test_acc': 0.784}
{'fold': 9, 'epoch': 83, 'train_loss': 0.10286527946591377, 'val_loss': 1.166693634033203, 'test_acc': 0.778}
{'fold': 9, 'epoch': 84, 'train_loss': 0.18244696962833404, 'val_loss': 1.250225513458252, 'test_acc': 0.752}
{'fold': 9, 'epoch': 85, 'train_loss': 0.1906101815700531, 'val_loss': 0.7578801803588867, 'test_acc': 0.764}
{'fold': 9, 'epoch': 86, 'train_loss': 0.13781712126731874, 'val_loss': 1.0478102188110352, 'test_acc': 0.778}
{'fold': 9, 'epoch': 87, 'train_loss': 0.12886430925130843, 'val_loss': 0.9092653274536133, 'test_acc': 0.786}
{'fold': 9, 'epoch': 88, 'train_loss': 0.13200898510217668, 'val_loss': 1.040123275756836, 'test_acc': 0.798}
{'fold': 9, 'epoch': 89, 'train_loss': 0.10651758635044098, 'val_loss': 1.3114417419433593, 'test_acc': 0.782}
{'fold': 9, 'epoch': 90, 'train_loss': 0.11114566969871521, 'val_loss': 1.233837677001953, 'test_acc': 0.784}
{'fold': 9, 'epoch': 91, 'train_loss': 0.1077433305978775, 'val_loss': 1.3273618774414062, 'test_acc': 0.766}
{'fold': 9, 'epoch': 92, 'train_loss': 0.09987911796569825, 'val_loss': 1.2407448272705077, 'test_acc': 0.796}
{'fold': 9, 'epoch': 93, 'train_loss': 0.13490613543987273, 'val_loss': 1.170766082763672, 'test_acc': 0.776}
{'fold': 9, 'epoch': 94, 'train_loss': 0.21792307543754577, 'val_loss': 0.9620473022460938, 'test_acc': 0.776}
{'fold': 9, 'epoch': 95, 'train_loss': 0.16436075007915496, 'val_loss': 1.0201253051757813, 'test_acc': 0.768}
{'fold': 9, 'epoch': 96, 'train_loss': 0.13691697096824645, 'val_loss': 1.0811426391601562, 'test_acc': 0.794}
{'fold': 9, 'epoch': 97, 'train_loss': 0.12001028874143958, 'val_loss': 1.3659851989746095, 'test_acc': 0.786}
{'fold': 9, 'epoch': 98, 'train_loss': 0.10404425692558289, 'val_loss': 1.3515117645263672, 'test_acc': 0.788}
{'fold': 9, 'epoch': 99, 'train_loss': 0.08880635035037994, 'val_loss': 1.546417724609375, 'test_acc': 0.774}
{'fold': 9, 'epoch': 100, 'train_loss': 0.10315787327289581, 'val_loss': 1.5436773376464843, 'test_acc': 0.776}
Val Loss: 0.4795, Test Accuracy: 0.787 ± 0.020, Duration: 133.477
Best result - 0.787 ± 0.020
--
IMDB-MULTI - GlobalAttentionNet: 0.473 ± 0.035
MUTAG - GlobalAttentionNet: 0.734 ± 0.095
IMDB-BINARY - GlobalAttentionNet: 0.731 ± 0.041
REDDIT-BINARY - GlobalAttentionNet: 0.883 ± 0.023
DD - GlobalAttentionNet: 0.644 ± 0.067
NCI1 - GlobalAttentionNet: 0.734 ± 0.036
PROTEINS - GlobalAttentionNet: 0.707 ± 0.043
COLLAB - GlobalAttentionNet: 0.787 ± 0.020

Process finished with exit code 0
